{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Predicting Heart Disease Using Decision Trees and Causal Forest (R)\n",
    "\n",
    "This notebook implements:\n",
    "1. Classification tree for heart disease prediction\n",
    "2. Causal forest analysis for treatment effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Predicting Heart Disease Using a Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "library(rpart)\n",
    "library(rpart.plot)\n",
    "library(caret)\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(randomForest)\n",
    "library(pheatmap)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Cleaning (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "column_names <- c('age', 'sex', 'cp', 'restbp', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'hd')\n",
    "df <- read.csv('../input/processed.cleveland.data', header = FALSE, col.names = column_names, na.strings = '?')\n",
    "\n",
    "cat(sprintf(\"Original dataset shape: %d rows, %d columns\\n\", nrow(df), ncol(df)))\n",
    "cat(\"\\nMissing values:\\n\")\n",
    "print(colSums(is.na(df)))\n",
    "\n",
    "# Remove missing values\n",
    "df <- na.omit(df)\n",
    "cat(sprintf(\"\\nDataset shape after removing missing values: %d rows, %d columns\\n\", nrow(df), ncol(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary variable y (1 if heart disease, 0 otherwise)\n",
    "df$y <- as.factor(ifelse(df$hd > 0, 1, 0))\n",
    "\n",
    "cat(\"Distribution of heart disease:\\n\")\n",
    "print(table(df$y))\n",
    "cat(sprintf(\"\\nPercentage with heart disease: %.2f%%\\n\", mean(df$y == 1) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical variables and convert to factors\n",
    "categorical_vars <- c('sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal')\n",
    "\n",
    "for (var in categorical_vars) {\n",
    "  df[[var]] <- as.factor(df[[var]])\n",
    "}\n",
    "\n",
    "# Create dummy variables\n",
    "# Using model.matrix to create dummy variables\n",
    "formula_str <- paste(\"~ \", paste(categorical_vars, collapse = \" + \"), \"- 1\")\n",
    "dummies <- model.matrix(as.formula(formula_str), data = df)\n",
    "\n",
    "# Combine with continuous variables\n",
    "continuous_vars <- c('age', 'restbp', 'chol', 'thalach', 'oldpeak')\n",
    "df_encoded <- cbind(df[continuous_vars], dummies, y = df$y, hd = df$hd)\n",
    "\n",
    "cat(sprintf(\"Dataset shape after creating dummy variables: %d rows, %d columns\\n\", nrow(df_encoded), ncol(df_encoded)))\n",
    "cat(\"\\nColumn names:\\n\")\n",
    "print(colnames(df_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X <- df_encoded[, !(colnames(df_encoded) %in% c('y', 'hd'))]\n",
    "y <- df_encoded$y\n",
    "\n",
    "cat(sprintf(\"Features shape: %d rows, %d columns\\n\", nrow(X), ncol(X)))\n",
    "cat(sprintf(\"Target length: %d\\n\", length(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Analysis (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1 point) Split data and plot classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "set.seed(123)\n",
    "train_index <- createDataPartition(y, p = 0.7, list = FALSE)\n",
    "X_train <- X[train_index, ]\n",
    "X_test <- X[-train_index, ]\n",
    "y_train <- y[train_index]\n",
    "y_test <- y[-train_index]\n",
    "\n",
    "cat(sprintf(\"Training set size: %d\\n\", nrow(X_train)))\n",
    "cat(sprintf(\"Test set size: %d\\n\", nrow(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train initial classification tree (without pruning)\n",
    "train_data <- cbind(X_train, y = y_train)\n",
    "tree_model <- rpart(y ~ ., data = train_data, method = \"class\", control = rpart.control(cp = 0))\n",
    "\n",
    "# Plot the tree\n",
    "png('../output/initial_tree.png', width = 2000, height = 1000, res = 150)\n",
    "rpart.plot(tree_model, type = 4, extra = 101, under = TRUE, cex = 0.8, \n",
    "           box.palette = \"RdYlGn\", shadow.col = \"gray\", main = \"Initial Classification Tree (Unpruned)\")\n",
    "dev.off()\n",
    "\n",
    "cat(sprintf(\"Tree depth: %d\\n\", max(tree_model$cptable[, \"nsplit\"])))\n",
    "cat(sprintf(\"Number of leaves: %d\\n\", sum(tree_model$frame$var == \"<leaf>\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2 points) Plot confusion matrix and interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test set\n",
    "y_pred <- predict(tree_model, newdata = X_test, type = \"class\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm <- confusionMatrix(y_pred, y_test)\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm_table <- as.data.frame(cm$table)\n",
    "png('../output/confusion_matrix_initial.png', width = 800, height = 600, res = 100)\n",
    "ggplot(data = cm_table, aes(x = Reference, y = Prediction, fill = Freq)) +\n",
    "  geom_tile() +\n",
    "  geom_text(aes(label = Freq), size = 8) +\n",
    "  scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n",
    "  scale_x_discrete(labels = c(\"Does not have HD\", \"Has HD\")) +\n",
    "  scale_y_discrete(labels = c(\"Does not have HD\", \"Has HD\")) +\n",
    "  labs(title = sprintf(\"Confusion Matrix - Initial Tree\\nAccuracy: %.4f\", cm$overall['Accuracy']),\n",
    "       x = \"Actual\", y = \"Predicted\") +\n",
    "  theme_minimal() +\n",
    "  theme(plot.title = element_text(hjust = 0.5, size = 14),\n",
    "        axis.text = element_text(size = 10))\n",
    "dev.off()\n",
    "\n",
    "cat(sprintf(\"\\nTest Accuracy: %.4f\\n\", cm$overall['Accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Initial Confusion Matrix:**\n",
    "- The initial tree may show overfitting characteristics with high training accuracy but lower test accuracy\n",
    "- True Positives: Correctly identified patients with heart disease\n",
    "- True Negatives: Correctly identified patients without heart disease\n",
    "- False Positives: Patients incorrectly classified as having heart disease (Type I error)\n",
    "- False Negatives: Patients incorrectly classified as not having heart disease (Type II error - more concerning in medical diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1.5 points) Fix overfitting using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 50 alpha (cp) values equally spaced on a logarithmic scale between e^-10 and 0.05\n",
    "alphas <- 10^seq(-10, log10(0.05), length.out = 50)\n",
    "cat(sprintf(\"Alpha range: %.10f to %.4f\\n\", min(alphas), max(alphas)))\n",
    "cat(sprintf(\"Number of alphas: %d\\n\", length(alphas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 4-fold cross-validation to select optimal alpha\n",
    "set.seed(123)\n",
    "folds <- createFolds(y_train, k = 4)\n",
    "\n",
    "cv_scores <- sapply(alphas, function(alpha) {\n",
    "  fold_accuracies <- sapply(folds, function(fold) {\n",
    "    train_fold <- train_data[-fold, ]\n",
    "    val_fold <- train_data[fold, ]\n",
    "    \n",
    "    tree_cv <- rpart(y ~ ., data = train_fold, method = \"class\", \n",
    "                     control = rpart.control(cp = alpha))\n",
    "    pred_cv <- predict(tree_cv, newdata = val_fold, type = \"class\")\n",
    "    mean(pred_cv == val_fold$y)\n",
    "  })\n",
    "  mean(fold_accuracies)\n",
    "})\n",
    "\n",
    "optimal_idx <- which.max(cv_scores)\n",
    "optimal_alpha <- alphas[optimal_idx]\n",
    "optimal_cv_score <- cv_scores[optimal_idx]\n",
    "\n",
    "cat(sprintf(\"Optimal alpha: %.10f\\n\", optimal_alpha))\n",
    "cat(sprintf(\"Best CV accuracy: %.4f\\n\", optimal_cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1.5 points) Plot Inaccuracy Rate (1 - Accuracy) against alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate inaccuracy rate\n",
    "inaccuracy_rates <- 1 - cv_scores\n",
    "\n",
    "# Plot inaccuracy rate vs alpha\n",
    "png('../output/inaccuracy_vs_alpha.png', width = 1200, height = 600, res = 100)\n",
    "plot_df <- data.frame(alpha = alphas, inaccuracy = inaccuracy_rates)\n",
    "ggplot(plot_df, aes(x = alpha, y = inaccuracy)) +\n",
    "  geom_line(linewidth = 1, color = \"steelblue\") +\n",
    "  geom_point(size = 2, color = \"steelblue\") +\n",
    "  geom_vline(xintercept = optimal_alpha, linetype = \"dashed\", color = \"red\", linewidth = 1) +\n",
    "  annotate(\"text\", x = optimal_alpha, y = max(inaccuracy_rates), \n",
    "           label = sprintf(\"Optimal α = %.6f\", optimal_alpha), hjust = -0.1, color = \"red\") +\n",
    "  scale_x_log10() +\n",
    "  labs(title = \"Inaccuracy Rate vs Alpha (4-fold Cross-Validation)\",\n",
    "       x = \"Alpha (log scale)\",\n",
    "       y = \"Inaccuracy Rate (1 - Accuracy)\") +\n",
    "  theme_minimal() +\n",
    "  theme(plot.title = element_text(hjust = 0.5, size = 14))\n",
    "dev.off()\n",
    "\n",
    "cat(sprintf(\"Minimum inaccuracy rate: %.4f\\n\", min(inaccuracy_rates)))\n",
    "cat(sprintf(\"Maximum inaccuracy rate: %.4f\\n\", max(inaccuracy_rates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2 points) Plot optimal tree and confusion matrix with interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train tree with optimal alpha\n",
    "tree_optimal <- rpart(y ~ ., data = train_data, method = \"class\", \n",
    "                      control = rpart.control(cp = optimal_alpha))\n",
    "\n",
    "# Plot optimal tree\n",
    "png('../output/optimal_tree.png', width = 2000, height = 1000, res = 150)\n",
    "rpart.plot(tree_optimal, type = 4, extra = 101, under = TRUE, cex = 0.8,\n",
    "           box.palette = \"RdYlGn\", shadow.col = \"gray\",\n",
    "           main = sprintf(\"Optimal Classification Tree (α = %.6f)\", optimal_alpha))\n",
    "dev.off()\n",
    "\n",
    "cat(sprintf(\"Optimal tree depth: %d\\n\", max(tree_optimal$cptable[, \"nsplit\"])))\n",
    "cat(sprintf(\"Optimal number of leaves: %d\\n\", sum(tree_optimal$frame$var == \"<leaf>\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions with optimal tree\n",
    "y_pred_optimal <- predict(tree_optimal, newdata = X_test, type = \"class\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_optimal <- confusionMatrix(y_pred_optimal, y_test)\n",
    "print(cm_optimal)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm_optimal_table <- as.data.frame(cm_optimal$table)\n",
    "png('../output/confusion_matrix_optimal.png', width = 800, height = 600, res = 100)\n",
    "ggplot(data = cm_optimal_table, aes(x = Reference, y = Prediction, fill = Freq)) +\n",
    "  geom_tile() +\n",
    "  geom_text(aes(label = Freq), size = 8) +\n",
    "  scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n",
    "  scale_x_discrete(labels = c(\"Does not have HD\", \"Has HD\")) +\n",
    "  scale_y_discrete(labels = c(\"Does not have HD\", \"Has HD\")) +\n",
    "  labs(title = sprintf(\"Confusion Matrix - Optimal Tree (α = %.6f)\\nAccuracy: %.4f\", \n",
    "                       optimal_alpha, cm_optimal$overall['Accuracy']),\n",
    "       x = \"Actual\", y = \"Predicted\") +\n",
    "  theme_minimal() +\n",
    "  theme(plot.title = element_text(hjust = 0.5, size = 14),\n",
    "        axis.text = element_text(size = 10))\n",
    "dev.off()\n",
    "\n",
    "cat(sprintf(\"\\nOptimal Test Accuracy: %.4f\\n\", cm_optimal$overall['Accuracy']))\n",
    "cat(sprintf(\"Sensitivity (True Positive Rate): %.4f\\n\", cm_optimal$byClass['Sensitivity']))\n",
    "cat(sprintf(\"Specificity (True Negative Rate): %.4f\\n\", cm_optimal$byClass['Specificity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation and Discussion:**\n",
    "\n",
    "1. **Tree Complexity**: The optimal tree with regularization (α) is simpler than the initial unpruned tree, reducing overfitting.\n",
    "\n",
    "2. **Performance Comparison**: \n",
    "   - The pruned tree may have slightly lower training accuracy but better generalization on test data\n",
    "   - The cross-validation process helped select an alpha that balances bias and variance\n",
    "\n",
    "3. **Clinical Implications**:\n",
    "   - Sensitivity measures the ability to correctly identify patients with heart disease\n",
    "   - Specificity measures the ability to correctly identify patients without heart disease\n",
    "   - In medical diagnosis, high sensitivity is often preferred to avoid missing cases (minimize false negatives)\n",
    "\n",
    "4. **Model Insights**: \n",
    "   - The tree reveals which features are most important for heart disease prediction\n",
    "   - The pruning process removed splits that didn't significantly improve accuracy\n",
    "   - The optimal model provides interpretable decision rules for clinical use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Causal Forest Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (0.5 points) Create binary treatment variable T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset random seed\n",
    "set.seed(123)\n",
    "\n",
    "# Create binary treatment variable (random assignment)\n",
    "df$T <- rbinom(nrow(df), 1, 0.5)\n",
    "\n",
    "cat(\"Treatment distribution:\\n\")\n",
    "print(table(df$T))\n",
    "cat(sprintf(\"\\nProportion treated: %.4f\\n\", mean(df$T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 point) Create outcome variable Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate outcome variable Y based on the specified formula\n",
    "# Y = (1 + 0.05*age + 0.3*sex + 0.2*restbp) * T + 0.5*oldpeak + ε\n",
    "# where ε ~ N(0, 1)\n",
    "\n",
    "epsilon <- rnorm(nrow(df), 0, 1)\n",
    "df$Y <- (1 + 0.05 * df$age + 0.3 * as.numeric(as.character(df$sex)) + 0.2 * df$restbp) * df$T + \n",
    "        0.5 * df$oldpeak + epsilon\n",
    "\n",
    "cat(\"Outcome variable Y statistics:\\n\")\n",
    "print(summary(df$Y))\n",
    "cat(sprintf(\"\\nMean Y for treated: %.4f\\n\", mean(df$Y[df$T == 1])))\n",
    "cat(sprintf(\"Mean Y for control: %.4f\\n\", mean(df$Y[df$T == 0])))\n",
    "cat(sprintf(\"Raw difference: %.4f\\n\", mean(df$Y[df$T == 1]) - mean(df$Y[df$T == 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 point) Calculate treatment effect using OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS regression: Y ~ T\n",
    "ols_model <- lm(Y ~ T, data = df)\n",
    "ols_summary <- summary(ols_model)\n",
    "\n",
    "cat(\"OLS Regression Results: Y ~ T\\n\")\n",
    "cat(\"=================================================\\n\")\n",
    "print(ols_summary)\n",
    "\n",
    "treatment_effect_ols <- coef(ols_model)['T']\n",
    "cat(sprintf(\"\\nTreatment Effect (β_T): %.4f\\n\", treatment_effect_ols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2 points) Use Random Forest to estimate causal effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for causal forest\n",
    "covariates <- c('age', 'sex', 'cp', 'restbp', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal')\n",
    "\n",
    "# Create data with treatment and covariates\n",
    "rf_data <- df[, c(covariates, 'T')]\n",
    "for (var in covariates) {\n",
    "  if (is.factor(rf_data[[var]])) {\n",
    "    rf_data[[var]] <- as.numeric(as.character(rf_data[[var]]))\n",
    "  }\n",
    "}\n",
    "\n",
    "# Add interaction terms\n",
    "for (var in covariates) {\n",
    "  rf_data[[paste0('T_x_', var)]] <- rf_data$T * rf_data[[var]]\n",
    "}\n",
    "\n",
    "# Fit Random Forest\n",
    "set.seed(123)\n",
    "rf_model <- randomForest(x = rf_data, y = df$Y, ntree = 100, maxnodes = NULL, nodesize = 5)\n",
    "\n",
    "# Predict outcomes under treatment and control\n",
    "rf_treated <- rf_data\n",
    "rf_treated$T <- 1\n",
    "for (var in covariates) {\n",
    "  rf_treated[[paste0('T_x_', var)]] <- rf_treated[[var]]\n",
    "}\n",
    "\n",
    "rf_control <- rf_data\n",
    "rf_control$T <- 0\n",
    "for (var in covariates) {\n",
    "  rf_control[[paste0('T_x_', var)]] <- 0\n",
    "}\n",
    "\n",
    "Y_pred_treated <- predict(rf_model, newdata = rf_treated)\n",
    "Y_pred_control <- predict(rf_model, newdata = rf_control)\n",
    "\n",
    "# Individual treatment effects\n",
    "df$ITE <- Y_pred_treated - Y_pred_control\n",
    "\n",
    "cat(\"Random Forest Causal Effects Estimation\\n\")\n",
    "cat(\"=================================================\\n\")\n",
    "cat(sprintf(\"Average Treatment Effect (ATE): %.4f\\n\", mean(df$ITE)))\n",
    "cat(sprintf(\"Standard Deviation of ITE: %.4f\\n\", sd(df$ITE)))\n",
    "cat(sprintf(\"Min ITE: %.4f\\n\", min(df$ITE)))\n",
    "cat(sprintf(\"Max ITE: %.4f\\n\", max(df$ITE)))\n",
    "\n",
    "# Plot distribution of treatment effects\n",
    "png('../output/ite_distribution.png', width = 1000, height = 600, res = 100)\n",
    "ggplot(data.frame(ITE = df$ITE), aes(x = ITE)) +\n",
    "  geom_histogram(bins = 30, fill = \"steelblue\", color = \"black\", alpha = 0.7) +\n",
    "  geom_vline(xintercept = mean(df$ITE), linetype = \"dashed\", color = \"red\", linewidth = 1) +\n",
    "  annotate(\"text\", x = mean(df$ITE), y = Inf, \n",
    "           label = sprintf(\"Mean ITE = %.4f\", mean(df$ITE)), \n",
    "           vjust = 2, hjust = -0.1, color = \"red\") +\n",
    "  labs(title = \"Distribution of Individual Treatment Effects\",\n",
    "       x = \"Individual Treatment Effect\",\n",
    "       y = \"Frequency\") +\n",
    "  theme_minimal() +\n",
    "  theme(plot.title = element_text(hjust = 0.5, size = 14))\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2 points) Plot representative tree with max_depth=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a single decision tree with maxdepth=2\n",
    "tree_rf_data <- cbind(rf_data, Y = df$Y)\n",
    "tree_model_rf <- rpart(Y ~ ., data = tree_rf_data, method = \"anova\", \n",
    "                       control = rpart.control(maxdepth = 2, minsplit = 10, cp = 0))\n",
    "\n",
    "# Plot the tree\n",
    "png('../output/representative_tree.png', width = 2000, height = 1000, res = 150)\n",
    "rpart.plot(tree_model_rf, type = 4, extra = 101, under = TRUE, cex = 0.8,\n",
    "           box.palette = \"RdYlGn\", shadow.col = \"gray\",\n",
    "           main = \"Representative Tree (max_depth=2) for Treatment Effect Heterogeneity\")\n",
    "dev.off()\n",
    "\n",
    "cat(sprintf(\"Tree depth: %d\\n\", max(tree_model_rf$cptable[, \"nsplit\"])))\n",
    "cat(sprintf(\"Number of leaves: %d\\n\", sum(tree_model_rf$frame$var == \"<leaf>\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Representative Tree:**\n",
    "\n",
    "This shallow tree (max_depth=2) reveals the most important heterogeneous treatment effects:\n",
    "- The tree shows which patient characteristics lead to different treatment effects\n",
    "- Each split represents a key decision point that differentiates treatment response\n",
    "- Leaf nodes show the predicted outcome for patients in that subgroup\n",
    "- The interaction terms (T_x_*) capture how treatment effects vary by patient characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.5 points) Feature importance visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from Random Forest\n",
    "importance_df <- data.frame(\n",
    "  feature = names(rf_model$importance[, 1]),\n",
    "  importance = rf_model$importance[, 1]\n",
    ") %>% arrange(desc(importance))\n",
    "\n",
    "# Plot top 15 most important features\n",
    "png('../output/feature_importance.png', width = 1200, height = 800, res = 100)\n",
    "top_features <- head(importance_df, 15)\n",
    "ggplot(top_features, aes(x = reorder(feature, importance), y = importance)) +\n",
    "  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n",
    "  coord_flip() +\n",
    "  labs(title = \"Top 15 Feature Importances (Random Forest)\",\n",
    "       x = \"Feature\",\n",
    "       y = \"Importance\") +\n",
    "  theme_minimal() +\n",
    "  theme(plot.title = element_text(hjust = 0.5, size = 14))\n",
    "dev.off()\n",
    "\n",
    "cat(\"\\nTop 10 Most Important Features:\\n\")\n",
    "print(head(importance_df, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2 points) Covariate distribution by treatment effect terciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize covariates\n",
    "covariate_data <- df[, covariates]\n",
    "for (var in covariates) {\n",
    "  if (is.factor(covariate_data[[var]])) {\n",
    "    covariate_data[[var]] <- as.numeric(as.character(covariate_data[[var]]))\n",
    "  }\n",
    "}\n",
    "\n",
    "standardized_covariates <- scale(covariate_data)\n",
    "standardized_df <- as.data.frame(standardized_covariates)\n",
    "\n",
    "# Divide predicted treatment effects into terciles\n",
    "df$ITE_tercile <- cut(df$ITE, breaks = quantile(df$ITE, probs = c(0, 1/3, 2/3, 1)), \n",
    "                      labels = c('Low', 'Medium', 'High'), include.lowest = TRUE)\n",
    "\n",
    "cat(\"Treatment Effect Terciles:\\n\")\n",
    "print(tapply(df$ITE, df$ITE_tercile, summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean of each standardized covariate within each tercile\n",
    "standardized_df$tercile <- df$ITE_tercile\n",
    "\n",
    "tercile_means <- standardized_df %>%\n",
    "  group_by(tercile) %>%\n",
    "  summarise(across(all_of(covariates), mean, na.rm = TRUE)) %>%\n",
    "  as.data.frame()\n",
    "\n",
    "rownames(tercile_means) <- tercile_means$tercile\n",
    "tercile_means <- tercile_means[, -1]\n",
    "\n",
    "# Create heatmap\n",
    "png('../output/terciles_heatmap.png', width = 1400, height = 600, res = 100)\n",
    "pheatmap(tercile_means, \n",
    "         cluster_rows = FALSE, \n",
    "         cluster_cols = FALSE,\n",
    "         display_numbers = TRUE,\n",
    "         number_format = \"%.2f\",\n",
    "         color = colorRampPalette(c(\"blue\", \"white\", \"red\"))(50),\n",
    "         breaks = seq(-2, 2, length.out = 51),\n",
    "         main = \"Mean Standardized Covariates by Predicted Treatment Effect Terciles\",\n",
    "         fontsize = 10,\n",
    "         fontsize_number = 8)\n",
    "dev.off()\n",
    "\n",
    "cat(\"\\nMean Standardized Covariates by Tercile:\\n\")\n",
    "print(tercile_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Tercile Analysis:**\n",
    "\n",
    "This heatmap shows how patient characteristics differ across treatment effect terciles:\n",
    "\n",
    "- **Low tercile**: Patients with lowest predicted treatment effects\n",
    "- **Medium tercile**: Patients with moderate predicted treatment effects  \n",
    "- **High tercile**: Patients with highest predicted treatment effects\n",
    "\n",
    "The color intensity indicates how each covariate's mean differs from zero (the population mean after standardization):\n",
    "- Red colors indicate above-average values for that tercile\n",
    "- Blue colors indicate below-average values for that tercile\n",
    "\n",
    "This analysis helps identify which patient characteristics are associated with higher or lower treatment effects, informing targeted intervention strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "\n",
    "### Part 1: Classification Tree\n",
    "- Successfully built and pruned a classification tree for heart disease prediction\n",
    "- Used cross-validation to find optimal complexity parameter (alpha)\n",
    "- Achieved reasonable accuracy while maintaining interpretability\n",
    "\n",
    "### Part 2: Causal Forest\n",
    "- Estimated heterogeneous treatment effects using Random Forest\n",
    "- Identified key characteristics associated with treatment response\n",
    "- Visualized treatment effect heterogeneity across patient subgroups\n",
    "\n",
    "All figures have been saved to the `../output/` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
