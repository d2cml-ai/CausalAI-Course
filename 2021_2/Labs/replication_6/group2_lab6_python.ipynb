{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36ca9e4",
   "metadata": {},
   "source": [
    "## Workgroup 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f261a94",
   "metadata": {},
   "source": [
    "Members:\n",
    "* Diego Gómez\n",
    "* Alexander Pacheco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9593c41",
   "metadata": {},
   "source": [
    "## 2. Debiased Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8e42b2",
   "metadata": {},
   "source": [
    "In this section, will use the DML algorithm we have learned. You can use the R and Python scripts from the labs as guides.\n",
    "For this task you will use the data from The Testing Convergence Hypothesis Lab (Barro-Lee growth data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d987bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "from sklearn import preprocessing\n",
    "import patsy\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import hdmpy\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fee3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV, ElasticNetCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "import itertools\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "from itertools import compress\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb3685",
   "metadata": {},
   "source": [
    "# Debiased Machine Learning (Python script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b374a4",
   "metadata": {},
   "source": [
    "We provide an additional empirical example of partialling-out with Lasso to estimate the regression coefficient $\\beta_1$ in the high-dimensional linear regression model:\n",
    "\n",
    "   Y = $\\beta_1$ D +  $\\beta_2$'W + $\\epsilon$\n",
    "\n",
    "Specifically, we are interested in how the rates at which economies of different countries grow ($Y$) are related to the initial wealth levels in each country ($D$) controlling for country's institutional, educational, and other similar characteristics ($W$).\n",
    "\n",
    "The relationship is captured by $\\beta_1$, the speed of convergence/divergence, which measures the speed at which poor countries catch up $(\\beta_1< 0)$ or fall behind $(\\beta_1> 0)$ rich countries, after controlling for $W$. Our inference question here is: do poor countries grow faster than rich countries, controlling for educational and other characteristics? In other words, is the speed of convergence negative: $ \\beta_1 <0?$ This is the Convergence Hypothesis predicted by the Solow Growth Model. This is a structural economic model. Under some strong assumptions, that we won't state here, the predictive exercise we are doing here can be given causal interpretation.\n",
    "\n",
    "The outcome $Y$ is the realized annual growth rate of a country's wealth (Gross Domestic Product per capita). The target regressor ($D$) is the initial level of the country's wealth. The target parameter $\\beta_1$ is the speed of convergence, which measures the speed at which poor countries catch up with rich countries. The controls ($W$) include measures of education levels, quality of institutions, trade openness, and political stability in the country."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64237512",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aa569e",
   "metadata": {},
   "source": [
    "We use the data set GrowthData which is included in the package hdm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc5ba33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Outcome',\n",
       " 'intercept',\n",
       " 'gdpsh465',\n",
       " 'bmp1l',\n",
       " 'freeop',\n",
       " 'freetar',\n",
       " 'h65',\n",
       " 'hm65',\n",
       " 'hf65',\n",
       " 'p65',\n",
       " 'pm65',\n",
       " 'pf65',\n",
       " 's65',\n",
       " 'sm65',\n",
       " 'sf65',\n",
       " 'fert65',\n",
       " 'mort65',\n",
       " 'lifee065',\n",
       " 'gpop1',\n",
       " 'fert1',\n",
       " 'mort1',\n",
       " 'invsh41',\n",
       " 'geetot1',\n",
       " 'geerec1',\n",
       " 'gde1',\n",
       " 'govwb1',\n",
       " 'govsh41',\n",
       " 'gvxdxe41',\n",
       " 'high65',\n",
       " 'highm65',\n",
       " 'highf65',\n",
       " 'highc65',\n",
       " 'highcm65',\n",
       " 'highcf65',\n",
       " 'human65',\n",
       " 'humanm65',\n",
       " 'humanf65',\n",
       " 'hyr65',\n",
       " 'hyrm65',\n",
       " 'hyrf65',\n",
       " 'no65',\n",
       " 'nom65',\n",
       " 'nof65',\n",
       " 'pinstab1',\n",
       " 'pop65',\n",
       " 'worker65',\n",
       " 'pop1565',\n",
       " 'pop6565',\n",
       " 'sec65',\n",
       " 'secm65',\n",
       " 'secf65',\n",
       " 'secc65',\n",
       " 'seccm65',\n",
       " 'seccf65',\n",
       " 'syr65',\n",
       " 'syrm65',\n",
       " 'syrf65',\n",
       " 'teapri65',\n",
       " 'teasec65',\n",
       " 'ex1',\n",
       " 'im1',\n",
       " 'xr65',\n",
       " 'tot1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We downloaded the data that the author used\n",
    "growth_read = pyreadr.read_r(\"../data/GrowthData.RData\")\n",
    "\n",
    "# Extracting the data frame from rdata_read\n",
    "growth = growth_read[ 'GrowthData' ]\n",
    "list(growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37033eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 63)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "growth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67862935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>intercept</th>\n",
       "      <th>gdpsh465</th>\n",
       "      <th>bmp1l</th>\n",
       "      <th>freeop</th>\n",
       "      <th>freetar</th>\n",
       "      <th>h65</th>\n",
       "      <th>hm65</th>\n",
       "      <th>hf65</th>\n",
       "      <th>p65</th>\n",
       "      <th>...</th>\n",
       "      <th>seccf65</th>\n",
       "      <th>syr65</th>\n",
       "      <th>syrm65</th>\n",
       "      <th>syrf65</th>\n",
       "      <th>teapri65</th>\n",
       "      <th>teasec65</th>\n",
       "      <th>ex1</th>\n",
       "      <th>im1</th>\n",
       "      <th>xr65</th>\n",
       "      <th>tot1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.024336</td>\n",
       "      <td>1</td>\n",
       "      <td>6.591674</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.153491</td>\n",
       "      <td>0.043888</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.010</td>\n",
       "      <td>47.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.348</td>\n",
       "      <td>-0.014727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100473</td>\n",
       "      <td>1</td>\n",
       "      <td>6.829794</td>\n",
       "      <td>0.6141</td>\n",
       "      <td>0.313509</td>\n",
       "      <td>0.061827</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.067</td>\n",
       "      <td>57.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.005750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067051</td>\n",
       "      <td>1</td>\n",
       "      <td>8.895082</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.204244</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.201</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>18.14</td>\n",
       "      <td>2.573</td>\n",
       "      <td>2.478</td>\n",
       "      <td>2.667</td>\n",
       "      <td>26.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>1.082</td>\n",
       "      <td>-0.010040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064089</td>\n",
       "      <td>1</td>\n",
       "      <td>7.565275</td>\n",
       "      <td>0.1997</td>\n",
       "      <td>0.248714</td>\n",
       "      <td>0.036270</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.051</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.424</td>\n",
       "      <td>27.8</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>6.625</td>\n",
       "      <td>-0.002195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027930</td>\n",
       "      <td>1</td>\n",
       "      <td>7.162397</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.299252</td>\n",
       "      <td>0.037367</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.229</td>\n",
       "      <td>34.5</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.003283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outcome  intercept  gdpsh465   bmp1l    freeop   freetar    h65   hm65  \\\n",
       "0 -0.024336          1  6.591674  0.2837  0.153491  0.043888  0.007  0.013   \n",
       "1  0.100473          1  6.829794  0.6141  0.313509  0.061827  0.019  0.032   \n",
       "2  0.067051          1  8.895082  0.0000  0.204244  0.009186  0.260  0.325   \n",
       "3  0.064089          1  7.565275  0.1997  0.248714  0.036270  0.061  0.070   \n",
       "4  0.027930          1  7.162397  0.1740  0.299252  0.037367  0.017  0.027   \n",
       "\n",
       "    hf65   p65  ...  seccf65  syr65  syrm65  syrf65  teapri65  teasec65  \\\n",
       "0  0.001  0.29  ...     0.04  0.033   0.057   0.010      47.6      17.3   \n",
       "1  0.007  0.91  ...     0.64  0.173   0.274   0.067      57.1      18.0   \n",
       "2  0.201  1.00  ...    18.14  2.573   2.478   2.667      26.5      20.7   \n",
       "3  0.051  1.00  ...     2.63  0.438   0.453   0.424      27.8      22.7   \n",
       "4  0.007  0.82  ...     2.11  0.257   0.287   0.229      34.5      17.6   \n",
       "\n",
       "      ex1     im1   xr65      tot1  \n",
       "0  0.0729  0.0667  0.348 -0.014727  \n",
       "1  0.0940  0.1438  0.525  0.005750  \n",
       "2  0.1741  0.1750  1.082 -0.010040  \n",
       "3  0.1265  0.1496  6.625 -0.002195  \n",
       "4  0.1211  0.1308  2.500  0.003283  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "growth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe01e57",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8228011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e5dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################  Find Variable Names from Dataset ########################\n",
    "\n",
    "def varlist( df = None, type_dataframe = [ 'numeric' , 'categorical' , 'string' ],  pattern = \"\", exclude = None ):\n",
    "    varrs = []\n",
    "    \n",
    "    if ('numeric' in type_dataframe):\n",
    "        varrs = varrs + df.columns[ df.apply( is_numeric_dtype , axis = 0 ).to_list() ].tolist()\n",
    "    \n",
    "    if ('categorical' in type_dataframe):\n",
    "        varrs = varrs + df.columns[ df.apply( is_categorical_dtype , axis = 0 ).to_list() ].tolist()\n",
    "    \n",
    "    if ('string' in type_dataframe):\n",
    "        varrs = varrs + df.columns[ df.apply( is_string_dtype , axis = 0 ).to_list() ].tolist()\n",
    "    \n",
    "    grepl_result = np.array( [ re.search( pattern , variable ) is not None for variable in df.columns.to_list() ] )\n",
    "    \n",
    "    if exclude is None:\n",
    "        result = list(compress( varrs, grepl_result ) )\n",
    "    \n",
    "    else:\n",
    "        varrs_excluded = np.array( [var in exclude for var in varrs ] )\n",
    "        and_filter = np.logical_and( ~varrs_excluded ,  grepl_result )\n",
    "        result = list(compress( varrs, and_filter ) )\n",
    "    \n",
    "    return result   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cdd43f",
   "metadata": {},
   "source": [
    "We now define some variables: n, the treatment variable, the outcome variable and the matrix $Z$ that includes the control variables (country characterisitics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6bd18cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of observations\n",
    "n = growth.shape[0]\n",
    "\n",
    "# Treatment Variable\n",
    "d = \"gdpsh465\"   \n",
    "\n",
    "# Outcome Variable\n",
    "y = \"Outcome\" \n",
    "\n",
    "# Treatment Variable\n",
    "D = growth[ f'{d}']\n",
    "\n",
    "# Outcome Variable\n",
    "Y = growth[ f'{y}']\n",
    "\n",
    "# Controls matrix Z\n",
    "Z = growth.drop(['Outcome','intercept', 'gdpsh465'], 1 )\n",
    "\n",
    "Z.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551b0b18",
   "metadata": {},
   "source": [
    "We notice that we have 60 control variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90200a4e",
   "metadata": {},
   "source": [
    "Now we define our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41fb1758",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([Y, D, Z], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f85f3",
   "metadata": {},
   "source": [
    "## 1. OLS without including the country characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a3bd15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025   -0.010810\n",
      "0.975]    0.013444\n",
      "Name: gdpsh465, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Coef.       0.001317\n",
       "Std.Err.    0.006102\n",
       "t           0.215777\n",
       "P>|t|       0.829661\n",
       "[0.025     -0.010810\n",
       "0.975]      0.013444\n",
       "Name: gdpsh465, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"Outcome ~ gdpsh465\"\n",
    "baseline_ols = smf.ols(model , data=data).fit()\n",
    "baseline_ols_table = baseline_ols.summary2().tables[1]\n",
    "print( baseline_ols_table.iloc[ 1 , 4:] )\n",
    "baseline_ols_table.iloc[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d606554",
   "metadata": {},
   "source": [
    "The estimated coefficient is $0.001317$ with the confidence interval ranging from -0.01 to 0.01 and it seems not to be significant without controlling for X (P>|t| = 0.829661)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269dc975",
   "metadata": {},
   "source": [
    "## 2. OLS including the country characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c925231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the variables\n",
    "y = 'Outcome'\n",
    "\n",
    "data_columns = list(data)\n",
    "no_relev_col = ['Outocome', 'gdpsh465']\n",
    "\n",
    "z = [col for col in data_columns if col not in no_relev_col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4ae7eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_formula = \"Outcome\" + ' ~ ' + 'gdpsh465 + ' + ' + '.join( Z.columns.to_list() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a0b5898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025   -0.070600\n",
      "0.975]    0.051844\n",
      "Name: gdpsh465, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Coef.      -0.009378\n",
       "Std.Err.    0.029888\n",
       "t          -0.313774\n",
       "P>|t|       0.756019\n",
       "[0.025     -0.070600\n",
       "0.975]      0.051844\n",
       "Name: gdpsh465, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_ols = smf.ols( control_formula , data=data).fit()\n",
    "control_ols_table = control_ols.summary2().tables[1]\n",
    "print( control_ols_table.iloc[ 1 , 4:] )\n",
    "control_ols_table.iloc[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843f88ce",
   "metadata": {},
   "source": [
    "After controlling with country characteristics, we find now a negative coefficient $-0.009378$ but it is also no significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd87149",
   "metadata": {
    "papermill": {
     "duration": 0.022083,
     "end_time": "2021-02-13T17:30:40.902070",
     "exception": false,
     "start_time": "2021-02-13T17:30:40.879987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DML algorithm\n",
    "\n",
    "Here we perform inference of the predictive coefficient $\\beta$ in our partially linear statistical model, \n",
    "\n",
    "$$\n",
    "Y = D\\beta + g(Z) + \\epsilon, \\quad E (\\epsilon | D, Z) = 0,\n",
    "$$\n",
    "\n",
    "using the **double machine learning** approach. \n",
    "\n",
    "For $\\tilde Y = Y- E(Y|Z)$ and $\\tilde D= D- E(D|Z)$, we can write\n",
    "$$\n",
    "\\tilde Y = \\alpha \\tilde D + \\epsilon, \\quad E (\\epsilon |\\tilde D) =0.\n",
    "$$\n",
    "\n",
    "Using cross-fitting, we employ modern regression methods\n",
    "to build estimators $\\hat \\ell(Z)$ and $\\hat m(Z)$ of $\\ell(Z):=E(Y|Z)$ and $m(Z):=E(D|Z)$ to obtain the estimates of the residualized quantities:\n",
    "\n",
    "$$\n",
    "\\tilde Y_i = Y_i  - \\hat \\ell (Z_i),   \\quad \\tilde D_i = D_i - \\hat m(Z_i), \\quad \\text{ for each } i = 1,\\dots,n.\n",
    "$$\n",
    "\n",
    "Finally, using ordinary least squares of $\\tilde Y_i$ on $\\tilde D_i$, we obtain the \n",
    "estimate of $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a8cb53",
   "metadata": {
    "papermill": {
     "duration": 0.021101,
     "end_time": "2021-02-13T17:30:40.944373",
     "exception": false,
     "start_time": "2021-02-13T17:30:40.923272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following algorithm comsumes $Y, D, Z$, and a machine learning method for learning the residuals $\\tilde Y$ and $\\tilde D$, where the residuals are obtained by cross-validation (cross-fitting). Then, it prints the estimated coefficient $\\beta$ and the corresponding standard error from the final OLS regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f10fffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DML2_for_PLM(z, d, y, dreg, yreg, nfold):\n",
    "    \n",
    "    # Num ob observations\n",
    "    nobs = z.shape[0]\n",
    "    \n",
    "    # Define folds indices \n",
    "    list_1 = [*range(0, nfold, 1)]*nobs\n",
    "    sample = np.random.choice(nobs,nobs, replace=False).tolist()\n",
    "    foldid = [list_1[index] for index in sample]\n",
    "\n",
    "    # Create split function(similar to R)\n",
    "    def split(x, f):\n",
    "        count = max(f) + 1\n",
    "        return tuple( list(itertools.compress(x, (el == i for el in f))) for i in range(count) ) \n",
    "\n",
    "    # Split observation indices into folds \n",
    "    list_2 = [*range(0, nobs, 1)]\n",
    "    I = split(list_2, foldid)\n",
    "    \n",
    "    # Create array to save errors \n",
    "    dtil = np.zeros( len(z) ).reshape( len(z) , 1 )\n",
    "    ytil = np.zeros( len(z) ).reshape( len(z) , 1 )\n",
    "    \n",
    "    # loop to save results\n",
    "    for b in range(0,len(I)):\n",
    "    \n",
    "        # Split data - index to keep are in mask as booleans\n",
    "        include_idx = set(I[b])  #Here should go I[b] Set is more efficient, but doesn't reorder your elements if that is desireable\n",
    "        mask = np.array([(i in include_idx) for i in range(len(z))])\n",
    "\n",
    "        # Lasso regression, excluding folds selected \n",
    "        dfit = dreg(z[~mask,], d[~mask,])\n",
    "        yfit = yreg(z[~mask,], y[~mask,])\n",
    "\n",
    "        # predict estimates using the \n",
    "        dhat = dfit.predict( z[mask,] )\n",
    "        yhat = yfit.predict( z[mask,] )\n",
    "\n",
    "        # save errors  \n",
    "        dtil[mask] =  d[mask,] - dhat.reshape( len(I[b]) , 1 )\n",
    "        ytil[mask] = y[mask,] - yhat.reshape( len(I[b]) , 1 )\n",
    "        print(b, \" \")\n",
    "    \n",
    "    # Create dataframe \n",
    "    data_2 = pd.DataFrame(np.concatenate( ( ytil, dtil ), axis = 1), columns = ['ytil','dtil'])\n",
    "   \n",
    "    model = \"ytil ~ dtil\"\n",
    "    baseline_ols = smf.ols(model , data = data_2 ).fit()\n",
    "    coef_est = baseline_ols.summary2().tables[1]['Coef.']['dtil']\n",
    "    se = baseline_ols.summary2().tables[1]['Std.Err.']['dtil']\n",
    "    \n",
    "    Final_result = { 'coef_est' : coef_est , 'se' : se , 'dtil' : dtil , 'ytil' : ytil }\n",
    "\n",
    "    print(\"Coefficient is {}, SE is equal to {}\".format(coef_est, se))\n",
    "    \n",
    "    return Final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2184f530",
   "metadata": {},
   "source": [
    "Let us, construct the input matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e423ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create main variables\n",
    "Y = data['Outcome']\n",
    "D = data['gdpsh465']\n",
    "Z = data.drop(['Outcome', 'gdpsh465'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f51b6294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70bd3e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd668f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 60)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e26a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as matrix\n",
    "y = Y.to_numpy().reshape( len(Y) , 1 )\n",
    "d = D.to_numpy().reshape( len(Y) , 1 )\n",
    "z = Z.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4e5f1",
   "metadata": {},
   "source": [
    "In the following, we apply the DML approach with the differnt versions of lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e845b3c",
   "metadata": {},
   "source": [
    "## 3. DML using Lasso to predict y and d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6b5d0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7778654724637054, tolerance: 0.006216004653469967\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01391384759414357, tolerance: 2.1959795148727455e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9055924402765264, tolerance: 0.006643320002424726\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011024161470358528, tolerance: 2.0287278863590325e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6868759298520788, tolerance: 0.0066687808840224195\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013664220556114536, tolerance: 1.922419906793233e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6580435120806764, tolerance: 0.006258785543145696\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014779268612623941, tolerance: 2.1762131201069167e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7756018526088616, tolerance: 0.00620209953254593\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012809047297724314, tolerance: 2.0781916952411566e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8110571934703186, tolerance: 0.0065237480850823416\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012447859843825092, tolerance: 2.1563683769338432e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8368773579371298, tolerance: 0.006461977078727087\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01536811695016267, tolerance: 2.1919538468219694e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8921564062050188, tolerance: 0.006663693771840058\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n",
      "1  \n",
      "2  \n",
      "3  \n",
      "4  \n",
      "5  \n",
      "6  \n",
      "7  \n",
      "8  \n",
      "9  \n",
      "Coefficient is 0.01854906811333555, SE is equal to 0.010472091220130372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012383961392374365, tolerance: 2.001665167647239e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7443438793407297, tolerance: 0.006720580888482781\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013111002981625569, tolerance: 2.1713417963181847e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8150320194822325, tolerance: 0.00590056618121169\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014710115130287275, tolerance: 2.145745753029275e-05\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "def dreg(z,d):\n",
    "    alpha=0.00000001\n",
    "    result = linear_model.Lasso(alpha = alpha).fit(z, d)\n",
    "    return result\n",
    "\n",
    "def yreg(z,y):\n",
    "    alpha=0.00000001\n",
    "    result = linear_model.Lasso(alpha = alpha).fit(z, y)\n",
    "    return result\n",
    "\n",
    "DML2_lasso = DML2_for_PLM(z, d, y, dreg, yreg, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c11b90",
   "metadata": {},
   "source": [
    "## 4. DML using Post-Lasso to predict y and d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a2a5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lasso_post:\n",
    "    \n",
    "    def __init__(self, alpha ):\n",
    "        self.alpha = alpha\n",
    "\n",
    "        \n",
    "    def fit( self, X, Y ):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        lasso = linear_model.Lasso( alpha = self.alpha ).fit( X , Y )\n",
    "        model = SelectFromModel( lasso , prefit = True )\n",
    "        X_new = model.transform( X )\n",
    "        # Gettin indices from columns which has variance for regression\n",
    "        index_X = model.get_support()\n",
    "        \n",
    "        self.index = index_X\n",
    "        new_x = X[ : ,  index_X ]\n",
    "        \n",
    "        lasso2 = linear_model.Lasso( alpha = self.alpha ).fit( new_x , Y )\n",
    "        self.model = lasso2\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict( self , X ):\n",
    "        \n",
    "        dropped_X = X[ : , self.index ]\n",
    "        \n",
    "        predictions = self.model.predict( dropped_X )\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3839b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9488262887411388, tolerance: 0.006664271160822951\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9709080550705614, tolerance: 0.006664271160822951\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013405826767078004, tolerance: 2.0850857836082115e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013621729243037457, tolerance: 2.0850857836082115e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7228558111371131, tolerance: 0.006736473489221311\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7486548617580858, tolerance: 0.006736473489221311\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012599617348736141, tolerance: 1.7925481225905253e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012723036210331582, tolerance: 1.7925481225905253e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8283998242842235, tolerance: 0.006321590958028735\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8484105717762098, tolerance: 0.006321590958028735\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013018074805522405, tolerance: 2.2566653089278187e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013408166946601041, tolerance: 2.2566653089278187e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7549948435147351, tolerance: 0.006154993730629483\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7508168625087916, tolerance: 0.006154993730629483\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014964942483549931, tolerance: 2.3267649795873873e-05\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n",
      "1  \n",
      "2  \n",
      "3  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01512597733311275, tolerance: 2.3267649795873873e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8709141967812717, tolerance: 0.006131709440067548\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8722102689585127, tolerance: 0.006131709440067548\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013528675678223905, tolerance: 2.2085799427345298e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013989225189295827, tolerance: 2.2085799427345298e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7401049808923905, tolerance: 0.006459008449219329\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7654693319504872, tolerance: 0.006459008449219329\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01374218770116497, tolerance: 2.1918636653194454e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014730870368935955, tolerance: 2.1918636653194454e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7168315692532539, tolerance: 0.006735324312037333\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7120579651673313, tolerance: 0.006735324312037333\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010618766196411993, tolerance: 2.099665005169894e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01134503549664096, tolerance: 2.099665005169894e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8640160305013702, tolerance: 0.0064309750710534\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  \n",
      "5  \n",
      "6  \n",
      "7  \n",
      "8  \n",
      "9  \n",
      "Coefficient is 0.01676965127907394, SE is equal to 0.013054251609344222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.864967972336677, tolerance: 0.0064309750710534\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012020658215445477, tolerance: 2.0801225369550993e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012591538597985707, tolerance: 2.0801225369550993e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7019908501022797, tolerance: 0.006537965121951793\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7066534983093722, tolerance: 0.006537965121951793\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013790662131355902, tolerance: 1.8165370962404847e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014003338828475233, tolerance: 1.8165370962404847e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7686800354097577, tolerance: 0.006065446831240327\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.764579099293217, tolerance: 0.006065446831240327\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01117810033375765, tolerance: 2.2054118637102603e-05\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011186191893439171, tolerance: 2.2054118637102603e-05\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "def dreg(z,d):\n",
    "    alpha=0.00000001\n",
    "    result = Lasso_post( alpha = alpha ).fit( z , d )\n",
    "    return result\n",
    "\n",
    "def yreg( z , y ):\n",
    "    alpha = 0.00000001\n",
    "    result = Lasso_post( alpha = alpha ).fit( z , y )\n",
    "    return result\n",
    "\n",
    "DML2_lasso_post = DML2_for_PLM(z, d, y, dreg, yreg, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62587ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48fbf127",
   "metadata": {},
   "source": [
    "## 5. DML using Random Forest to predict y and d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0eeac9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03c26588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 60)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd9277d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \n",
      "Coefficient is -0.028341543504056824, SE is equal to 0.011312729595461932\n"
     ]
    }
   ],
   "source": [
    "#DML with Random Forest:\n",
    "def dreg(z,d):\n",
    "    result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 60 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, d )\n",
    "    return result\n",
    "\n",
    "def yreg(z,y):\n",
    "    result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 60 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, y )\n",
    "    return result\n",
    "\n",
    "DML2_RF = DML2_for_PLM(z, d, y, dreg, yreg, 2)   # set to 2 due to computation time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16439983",
   "metadata": {},
   "source": [
    "## 6. Run the best method i.e. the best combination of methods to predict y and d."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a193c92a",
   "metadata": {},
   "source": [
    "We define the DML_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92335568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n",
      "1  \n",
      "Coefficient is -0.09201383622019393, SE is equal to 0.012557869958406437\n"
     ]
    }
   ],
   "source": [
    "#DML with OLS:\n",
    "def dreg(z,d):\n",
    "    result = LinearRegression().fit( z, d )\n",
    "    return result\n",
    "\n",
    "def yreg(z,y):\n",
    "    result = LinearRegression().fit( z, y )\n",
    "    return result\n",
    "\n",
    "DML2_ols = DML2_for_PLM(z, d, y, dreg, yreg, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5739bc2a",
   "metadata": {},
   "source": [
    "To be able to find the best method, we will find RMSE for predicting D and Y, and see which of the methods works better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbcd5ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DML2_ols</th>\n",
       "      <th>DML2_lasso</th>\n",
       "      <th>DML2_lasso_post</th>\n",
       "      <th>DML2_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSEY</th>\n",
       "      <td>0.092477</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSED</th>\n",
       "      <td>0.139480</td>\n",
       "      <td>0.019442</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.024032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DML2_ols  DML2_lasso  DML2_lasso_post   DML2_RF\n",
       "RMSEY  0.092477    0.001877         0.002521  0.001061\n",
       "RMSED  0.139480    0.019442         0.000181  0.024032"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods = [DML2_ols, DML2_lasso, DML2_lasso_post, DML2_RF]\n",
    "mods_name = [\"DML2_ols\", \"DML2_lasso\", \"DML2_lasso_post\", 'DML2_RF']\n",
    "\n",
    "def mdl( model , model_name ):\n",
    "    \n",
    "    RMSEY = np.sqrt( np.mean( model[ 'ytil' ] ) ** 2 ) # I have some doubts about these equations...we have to recheck\n",
    "    RMSED = np.sqrt( np.mean( model[ 'dtil' ] ) ** 2 ) # I have some doubts about these equations...we have to recheck\n",
    "    \n",
    "    result = pd.DataFrame( { model_name : [ RMSEY , RMSED ]} , index = [ 'RMSEY' , 'RMSED' ])\n",
    "    return result\n",
    "\n",
    "RES = [ mdl( model , name ) for model, name in zip( mods , mods_name ) ]\n",
    "    \n",
    "\n",
    "pr_Res = pd.concat( RES, axis = 1)\n",
    "\n",
    "pr_Res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b72e2a",
   "metadata": {},
   "source": [
    "To verifie that the function has no errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6e5906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(DML2_lasso_post[ 'ytil' ] == 0)[0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440f25d",
   "metadata": {},
   "source": [
    "The table above indicates that the best method for predicting Y is Random Forest and for predicting D is Post-Lasso. We can deduce this by looking at the RMSE that we find when predicting both Y and D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7640d448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9140421434122824, tolerance: 0.006184685815434688\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9185506500339666, tolerance: 0.006184685815434688\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7805636139905683, tolerance: 0.006360018491833337\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7883316158313166, tolerance: 0.006360018491833337\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6979816826173604, tolerance: 0.006278816399322124\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7079061015044291, tolerance: 0.006278816399322124\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8445678532836901, tolerance: 0.0064007578003460784\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8438196052194487, tolerance: 0.0064007578003460784\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8468412091878886, tolerance: 0.006637710425582769\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8638384682103415, tolerance: 0.006637710425582769\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7604219364580868, tolerance: 0.00672331422768211\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8095113633478314, tolerance: 0.00672331422768211\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.706775687711322, tolerance: 0.006508127642301257\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7095035089180801, tolerance: 0.006508127642301257\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8091243492190013, tolerance: 0.006357485791347617\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8217755351295928, tolerance: 0.006357485791347617\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9122755368943093, tolerance: 0.006443867699468521\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9312012955005959, tolerance: 0.006443867699468521\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7220964702820466, tolerance: 0.006359042560623478\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7446474902587041, tolerance: 0.006359042560623478\n",
      "  positive)\n",
      "C:\\Users\\Hp\\.conda\\envs\\r-tutorial\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9  \n",
      "Coefficient is -0.00022232796994351068, SE is equal to 0.011012257199274032\n"
     ]
    }
   ],
   "source": [
    "#DML with the BEST:\n",
    "def dreg(z,d):\n",
    "    alpha=0.00000001\n",
    "    result = Lasso_post( alpha = alpha ).fit( z , d )\n",
    "    return result\n",
    "\n",
    "def yreg(z,y):\n",
    "    result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 60 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, y )\n",
    "    return result\n",
    "\n",
    "DML2_best = DML2_for_PLM(z, d, y, dreg, yreg, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8773dc2b",
   "metadata": {},
   "source": [
    "## 7. Show your results in a table as we did in the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1897cbd",
   "metadata": {},
   "source": [
    "Now, we can show our results in the next table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d4b080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = np.zeros( ( 6 , 2 ))\n",
    "table[ 0 , 0] = baseline_ols_table.iloc[ 1 , 0 ]\n",
    "table[ 1 , 0] = control_ols_table.iloc[ 1 , 0 ]\n",
    "table[ 2 , 0] = DML2_lasso['coef_est']\n",
    "table[ 3 , 0] = DML2_lasso_post['coef_est']\n",
    "table[ 4 , 0] = DML2_RF['coef_est']\n",
    "table[ 5 , 0] = DML2_best['coef_est']\n",
    "table[ 0 , 1] = baseline_ols_table.iloc[ 1 , 1 ]\n",
    "table[ 1 , 1] = control_ols_table.iloc[ 1 , 1 ]\n",
    "table[ 2 , 1] = DML2_lasso['se']\n",
    "table[ 3 , 1] = DML2_lasso_post['se']\n",
    "table[ 4 , 1] = DML2_RF['se']\n",
    "table[ 5 , 1] = DML2_best['se']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dde8a4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Standard Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline OLS</th>\n",
       "      <td>0.00132</td>\n",
       "      <td>0.00610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Least Squares with controls</th>\n",
       "      <td>-0.00938</td>\n",
       "      <td>0.02989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.01855</td>\n",
       "      <td>0.01047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post-Lasso</th>\n",
       "      <td>0.01677</td>\n",
       "      <td>0.01305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>-0.02834</td>\n",
       "      <td>0.01131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best</th>\n",
       "      <td>-0.00022</td>\n",
       "      <td>0.01101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Estimate  Standard Error\n",
       "Baseline OLS                  0.00132         0.00610\n",
       "Least Squares with controls  -0.00938         0.02989\n",
       "Lasso                         0.01855         0.01047\n",
       "Post-Lasso                    0.01677         0.01305\n",
       "Random Forest                -0.02834         0.01131\n",
       "Best                         -0.00022         0.01101"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame( table , index = [ \"Baseline OLS\", \"Least Squares with controls\", \"Lasso\", \\\n",
    "             \"Post-Lasso\", \"Random Forest\", \"Best\" ] , \\\n",
    "            columns = [\"Estimate\",\"Standard Error\"] )\n",
    "table.round( 5 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
