{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd48986",
   "metadata": {},
   "source": [
    "# Workgroup 6 - Group 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08f490a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "from sklearn import preprocessing\n",
    "import patsy\n",
    "import keras\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import hdmpy\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV, ElasticNetCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "import itertools\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "from itertools import compress\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58678c8",
   "metadata": {},
   "source": [
    "In this case, we test the convergence hypothesis proposed by Solow-Swan. We propose the following model:\n",
    "\n",
    "  $$\n",
    "  Y = \\beta_1 D +  \\beta_2'X + \\epsilon.\n",
    "  $$\n",
    "  \n",
    "Where $Y$ is the growth rate of a certain country, $D$ is the initial wealth level of said country, and $X$ is a set of control variables related to each country's institutional, educational, and similar characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa80c079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>intercept</th>\n",
       "      <th>gdpsh465</th>\n",
       "      <th>bmp1l</th>\n",
       "      <th>freeop</th>\n",
       "      <th>freetar</th>\n",
       "      <th>h65</th>\n",
       "      <th>hm65</th>\n",
       "      <th>hf65</th>\n",
       "      <th>p65</th>\n",
       "      <th>...</th>\n",
       "      <th>seccf65</th>\n",
       "      <th>syr65</th>\n",
       "      <th>syrm65</th>\n",
       "      <th>syrf65</th>\n",
       "      <th>teapri65</th>\n",
       "      <th>teasec65</th>\n",
       "      <th>ex1</th>\n",
       "      <th>im1</th>\n",
       "      <th>xr65</th>\n",
       "      <th>tot1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.024336</td>\n",
       "      <td>1</td>\n",
       "      <td>6.591674</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.153491</td>\n",
       "      <td>0.043888</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.010</td>\n",
       "      <td>47.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.348</td>\n",
       "      <td>-0.014727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100473</td>\n",
       "      <td>1</td>\n",
       "      <td>6.829794</td>\n",
       "      <td>0.6141</td>\n",
       "      <td>0.313509</td>\n",
       "      <td>0.061827</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.067</td>\n",
       "      <td>57.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.005750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067051</td>\n",
       "      <td>1</td>\n",
       "      <td>8.895082</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.204244</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.201</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>18.14</td>\n",
       "      <td>2.573</td>\n",
       "      <td>2.478</td>\n",
       "      <td>2.667</td>\n",
       "      <td>26.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>1.082</td>\n",
       "      <td>-0.010040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064089</td>\n",
       "      <td>1</td>\n",
       "      <td>7.565275</td>\n",
       "      <td>0.1997</td>\n",
       "      <td>0.248714</td>\n",
       "      <td>0.036270</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.051</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.424</td>\n",
       "      <td>27.8</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>6.625</td>\n",
       "      <td>-0.002195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027930</td>\n",
       "      <td>1</td>\n",
       "      <td>7.162397</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.299252</td>\n",
       "      <td>0.037367</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.229</td>\n",
       "      <td>34.5</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.003283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.031196</td>\n",
       "      <td>1</td>\n",
       "      <td>8.991064</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.371898</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.98</td>\n",
       "      <td>...</td>\n",
       "      <td>11.41</td>\n",
       "      <td>2.226</td>\n",
       "      <td>2.494</td>\n",
       "      <td>1.971</td>\n",
       "      <td>27.5</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.4407</td>\n",
       "      <td>0.4257</td>\n",
       "      <td>2.529</td>\n",
       "      <td>-0.011883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.034096</td>\n",
       "      <td>1</td>\n",
       "      <td>8.025189</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.296437</td>\n",
       "      <td>0.013615</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.362</td>\n",
       "      <td>20.2</td>\n",
       "      <td>15.7</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.2201</td>\n",
       "      <td>25.553</td>\n",
       "      <td>-0.039080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.046900</td>\n",
       "      <td>1</td>\n",
       "      <td>9.030137</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.265778</td>\n",
       "      <td>0.008629</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.237</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>25.64</td>\n",
       "      <td>2.727</td>\n",
       "      <td>2.664</td>\n",
       "      <td>2.788</td>\n",
       "      <td>20.4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.3238</td>\n",
       "      <td>0.3134</td>\n",
       "      <td>4.152</td>\n",
       "      <td>0.005175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.039773</td>\n",
       "      <td>1</td>\n",
       "      <td>8.865312</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.282939</td>\n",
       "      <td>0.005048</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.139</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10.76</td>\n",
       "      <td>1.888</td>\n",
       "      <td>1.920</td>\n",
       "      <td>1.860</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1845</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.029551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.040642</td>\n",
       "      <td>1</td>\n",
       "      <td>8.912339</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.150366</td>\n",
       "      <td>0.024377</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>24.40</td>\n",
       "      <td>3.051</td>\n",
       "      <td>3.235</td>\n",
       "      <td>2.875</td>\n",
       "      <td>18.5</td>\n",
       "      <td>29.1</td>\n",
       "      <td>0.1876</td>\n",
       "      <td>0.2007</td>\n",
       "      <td>0.886</td>\n",
       "      <td>-0.036482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outcome  intercept  gdpsh465   bmp1l    freeop   freetar    h65   hm65  \\\n",
       "0  -0.024336          1  6.591674  0.2837  0.153491  0.043888  0.007  0.013   \n",
       "1   0.100473          1  6.829794  0.6141  0.313509  0.061827  0.019  0.032   \n",
       "2   0.067051          1  8.895082  0.0000  0.204244  0.009186  0.260  0.325   \n",
       "3   0.064089          1  7.565275  0.1997  0.248714  0.036270  0.061  0.070   \n",
       "4   0.027930          1  7.162397  0.1740  0.299252  0.037367  0.017  0.027   \n",
       "..       ...        ...       ...     ...       ...       ...    ...    ...   \n",
       "85  0.031196          1  8.991064  0.0000  0.371898  0.014586  0.255  0.336   \n",
       "86  0.034096          1  8.025189  0.0050  0.296437  0.013615  0.108  0.117   \n",
       "87  0.046900          1  9.030137  0.0000  0.265778  0.008629  0.288  0.337   \n",
       "88  0.039773          1  8.865312  0.0000  0.282939  0.005048  0.188  0.236   \n",
       "89  0.040642          1  8.912339  0.0000  0.150366  0.024377  0.257  0.338   \n",
       "\n",
       "     hf65   p65  ...  seccf65  syr65  syrm65  syrf65  teapri65  teasec65  \\\n",
       "0   0.001  0.29  ...     0.04  0.033   0.057   0.010      47.6      17.3   \n",
       "1   0.007  0.91  ...     0.64  0.173   0.274   0.067      57.1      18.0   \n",
       "2   0.201  1.00  ...    18.14  2.573   2.478   2.667      26.5      20.7   \n",
       "3   0.051  1.00  ...     2.63  0.438   0.453   0.424      27.8      22.7   \n",
       "4   0.007  0.82  ...     2.11  0.257   0.287   0.229      34.5      17.6   \n",
       "..    ...   ...  ...      ...    ...     ...     ...       ...       ...   \n",
       "85  0.170  0.98  ...    11.41  2.226   2.494   1.971      27.5      15.9   \n",
       "86  0.093  1.00  ...     1.95  0.510   0.694   0.362      20.2      15.7   \n",
       "87  0.237  1.00  ...    25.64  2.727   2.664   2.788      20.4       9.4   \n",
       "88  0.139  1.00  ...    10.76  1.888   1.920   1.860      20.0      16.0   \n",
       "89  0.215  1.00  ...    24.40  3.051   3.235   2.875      18.5      29.1   \n",
       "\n",
       "       ex1     im1    xr65      tot1  \n",
       "0   0.0729  0.0667   0.348 -0.014727  \n",
       "1   0.0940  0.1438   0.525  0.005750  \n",
       "2   0.1741  0.1750   1.082 -0.010040  \n",
       "3   0.1265  0.1496   6.625 -0.002195  \n",
       "4   0.1211  0.1308   2.500  0.003283  \n",
       "..     ...     ...     ...       ...  \n",
       "85  0.4407  0.4257   2.529 -0.011883  \n",
       "86  0.1669  0.2201  25.553 -0.039080  \n",
       "87  0.3238  0.3134   4.152  0.005175  \n",
       "88  0.1845  0.1940   0.452 -0.029551  \n",
       "89  0.1876  0.2007   0.886 -0.036482  \n",
       "\n",
       "[90 rows x 63 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Data\n",
    "rdata = pyreadr.read_r(\"data/GrowthData.RData\")\n",
    "data = rdata['GrowthData']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce17dd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-44840a64cdaa>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X = data.drop('Outcome', 1)\n"
     ]
    }
   ],
   "source": [
    "#Defining Variables\n",
    "Y = data['Outcome']\n",
    "X = data.drop('Outcome', 1)\n",
    "D = data[['intercept', 'gdpsh465']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf3360",
   "metadata": {},
   "source": [
    "## OLS without covariates\n",
    "***\n",
    "We estimate a model of the outcome variable just on the treatment variable (initial wealth). That is:\n",
    "\n",
    " $$\n",
    "  Y = \\beta_1 D  + \\epsilon.\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb3f275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025   -0.010810\n",
      "0.975]    0.013444\n",
      "Name: gdpsh465, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Coef.       0.001317\n",
       "Std.Err.    0.006102\n",
       "t           0.215777\n",
       "P>|t|       0.829661\n",
       "[0.025     -0.010810\n",
       "0.975]      0.013444\n",
       "Name: gdpsh465, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLS w/o controls\n",
    "model = \"Outcome ~ gdpsh465\"\n",
    "baseline_ols = smf.ols(model , data=data).fit()\n",
    "baseline_ols_table = baseline_ols.summary2().tables[1]\n",
    "print( baseline_ols_table.iloc[ 1 , 4:] )\n",
    "baseline_ols_table.iloc[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ba4e5",
   "metadata": {},
   "source": [
    "## OLS with Covariates\n",
    "Now we estimate de model as initially proposed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01373665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025   -0.070600\n",
      "0.975]    0.051844\n",
      "Name: gdpsh465, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Coef.      -0.009378\n",
       "Std.Err.    0.029888\n",
       "t          -0.313774\n",
       "P>|t|       0.756019\n",
       "[0.025     -0.070600\n",
       "0.975]      0.051844\n",
       "Name: gdpsh465, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLS with controls\n",
    "y = 'Outcome'\n",
    "\n",
    "data_columns = list(data)\n",
    "no_relev_col = ['Outcome',  'gdpsh465']\n",
    "\n",
    "# This gives us: new_list = ['carrot' , 'lemon']\n",
    "z = [col for col in data_columns if col not in no_relev_col]\n",
    "\n",
    "control_formula = \"Outcome\" + ' ~ ' + 'gdpsh465 + ' + ' + '.join( z )\n",
    "\n",
    "\n",
    "control_ols = smf.ols( control_formula , data=data).fit()\n",
    "control_ols_table = control_ols.summary2().tables[1]\n",
    "print( control_ols_table.iloc[ 1 , 4:] )\n",
    "control_ols_table.iloc[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6212bde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef.</th>\n",
       "      <th>Std.Err.</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OLS - W/O controls</th>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.006102</td>\n",
       "      <td>0.215777</td>\n",
       "      <td>0.829661</td>\n",
       "      <td>-0.01081</td>\n",
       "      <td>0.013444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLS - With controls</th>\n",
       "      <td>-0.009378</td>\n",
       "      <td>0.029888</td>\n",
       "      <td>-0.313774</td>\n",
       "      <td>0.756019</td>\n",
       "      <td>-0.07060</td>\n",
       "      <td>0.051844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Coef.  Std.Err.         t     P>|t|   [0.025    0.975]\n",
       "OLS - W/O controls   0.001317  0.006102  0.215777  0.829661 -0.01081  0.013444\n",
       "OLS - With controls -0.009378  0.029888 -0.313774  0.756019 -0.07060  0.051844"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_res    = baseline_ols_table.loc[['gdpsh465'], :]\n",
    "control_res = control_ols_table.loc[['gdpsh465'], :]\n",
    "\n",
    "new_indexes = ['OLS - W/O controls', 'OLS - With controls']\n",
    "\n",
    "table_ols = raw_res.append(control_res)\n",
    "\n",
    "table_ols.index = new_indexes\n",
    "table_ols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2fd747",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "We notice that both OLS estimations give no significant results. That is because we have $90$ countries, but $63$ control variables, which means we have a relatively large number of variables for a relatively small number of observations ($\\frac{p}{n}$ not small), therefore the OLS method performs poorly, with or without covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0893821b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 63)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412618dc",
   "metadata": {},
   "source": [
    "## DML using Lasso\n",
    "***\n",
    "First we define the DML function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f9d7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DML2_for_PLM(z, d, y, dreg, yreg, nfold):\n",
    "    \n",
    "    # Num ob observations\n",
    "    nobs = z.shape[0]\n",
    "    \n",
    "    # Define folds indices \n",
    "    list_1 = [*range(0, nfold, 1)]*nobs\n",
    "    sample = np.random.choice(nobs,nobs, replace=False).tolist()\n",
    "    foldid = [list_1[index] for index in sample]\n",
    "\n",
    "    # Create split function(similar to R)\n",
    "    def split(x, f):\n",
    "        count = max(f) + 1\n",
    "        return tuple( list(itertools.compress(x, (el == i for el in f))) for i in range(count) ) \n",
    "\n",
    "    # Split observation indices into folds \n",
    "    list_2 = [*range(0, nobs, 1)]\n",
    "    I = split(list_2, foldid)\n",
    "    \n",
    "    # Create array to save errors \n",
    "    dtil = np.zeros( len(z) ).reshape( len(z) , 1 )\n",
    "    ytil = np.zeros( len(z) ).reshape( len(z) , 1 )\n",
    "    \n",
    "    # loop to save results\n",
    "    for b in range(0,len(I)):\n",
    "    \n",
    "        # Split data - index to keep are in mask as booleans\n",
    "        include_idx = set(I[b])  #Here should go I[b] Set is more efficient, but doesn't reorder your elements if that is desireable\n",
    "        mask = np.array([(i in include_idx) for i in range(len(z))])\n",
    "\n",
    "        # Lasso regression, excluding folds selected \n",
    "        dfit = dreg(z[~mask,], d[~mask,])\n",
    "        yfit = yreg(z[~mask,], y[~mask,])\n",
    "\n",
    "        # predict estimates using the \n",
    "        dhat = dfit.predict( z[mask,] )\n",
    "        yhat = yfit.predict( z[mask,] )\n",
    "\n",
    "        # save errors  \n",
    "        dtil[mask] =  d[mask,] - dhat.reshape( len(I[b]) , 1 )\n",
    "        ytil[mask] = y[mask,] - yhat.reshape( len(I[b]) , 1 )\n",
    "        print(b, \" \")\n",
    "    \n",
    "    # Create dataframe \n",
    "    data_2 = pd.DataFrame(np.concatenate( ( ytil, dtil ), axis = 1), columns = ['ytil','dtil'])\n",
    "   \n",
    "    # OLS clustering at the County level\n",
    "    model = \"ytil ~ dtil\"\n",
    "    baseline_ols = smf.ols(model , data = data_2 ).fit()\n",
    "    coef_est = baseline_ols.summary2().tables[1]['Coef.']['dtil']\n",
    "    se = baseline_ols.summary2().tables[1]['Std.Err.']['dtil']\n",
    "    \n",
    "    Final_result = { 'coef_est' : coef_est , 'se' : se , 'dtil' : dtil , 'ytil' : ytil }\n",
    "\n",
    "    print(\"Coefficient is {}, SE is equal to {}\".format(coef_est, se))\n",
    "    \n",
    "    return Final_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "662d9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['Outcome']\n",
    "D = data['gdpsh465']\n",
    "X = data.drop(['Outcome', 'gdpsh465'], axis=1)\n",
    "#CLU = data['CountyCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ed1deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as matrix\n",
    "y = Y.to_numpy().reshape( len(Y) , 1 )\n",
    "d = D.to_numpy().reshape( len(Y) , 1 )\n",
    "x = X.to_numpy()\n",
    "#clu = clu.to_numpy().reshape( len(Y) , 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f98d14b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n",
      "1  \n",
      "2  \n",
      "3  \n",
      "4  \n",
      "5  \n",
      "6  \n",
      "7  \n",
      "8  \n",
      "9  \n",
      "Coefficient is 0.015364284846020522, SE is equal to 0.013084632901594081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8819039484553006, tolerance: 0.0066002110963832555\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011572455203789687, tolerance: 1.9481138701417832e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7086931138131208, tolerance: 0.006359872444937687\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014065662923596983, tolerance: 1.969159013396203e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8855105775532558, tolerance: 0.006775483268235553\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013791876939050903, tolerance: 2.23960805667636e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7535501603572013, tolerance: 0.005724454825236598\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012108505172154577, tolerance: 2.260032132088288e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7359002995904326, tolerance: 0.006472982337771558\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01432221153698192, tolerance: 2.0306143536067155e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8584737225648902, tolerance: 0.0062157412200874035\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01176067836829196, tolerance: 2.0592402565668807e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9791194114373435, tolerance: 0.00637300665130604\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01207550735859933, tolerance: 2.0956628496086016e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7907698982960184, tolerance: 0.006641190379700703\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01427307653715482, tolerance: 2.241401351192286e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8329494692103567, tolerance: 0.006501148922141253\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01366140804452632, tolerance: 2.0296380428480774e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8165972910475241, tolerance: 0.0065685921620545545\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014690709851243955, tolerance: 2.196564724579454e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "def dreg(x,d):\n",
    "    alpha=0.00000001\n",
    "    result = linear_model.Lasso(alpha = alpha).fit(x, d)\n",
    "    return result\n",
    "\n",
    "def yreg(x,y):\n",
    "    alpha=0.00000001\n",
    "    result = linear_model.Lasso(alpha = alpha).fit(x, y)\n",
    "    return result\n",
    "\n",
    "DML2_lasso = DML2_for_PLM(x, d, y, dreg, yreg, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c625cfc",
   "metadata": {},
   "source": [
    "## DML using Post-Lasso\n",
    "***\n",
    "Now we will perform the DML algorithm in a post-lasso context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7af7d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lasso_post:\n",
    "    \n",
    "    def __init__(self, alpha ):\n",
    "        self.alpha = alpha\n",
    "\n",
    "        \n",
    "    def fit( self, X, Y ):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        lasso = linear_model.Lasso( alpha = self.alpha ).fit( X , Y )\n",
    "        model = SelectFromModel( lasso , prefit = True )\n",
    "        X_new = model.transform( X )\n",
    "        # Gettin indices from columns which has variance for regression\n",
    "        index_X = model.get_support()\n",
    "        \n",
    "        self.index = index_X\n",
    "        new_x = X[ : ,  index_X ]\n",
    "        \n",
    "        lasso2 = linear_model.Lasso( alpha = self.alpha ).fit( new_x , Y )\n",
    "        self.model = lasso2\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict( self , X ):\n",
    "        \n",
    "        dropped_X = X[ : , self.index ]\n",
    "        \n",
    "        predictions = self.model.predict( dropped_X )\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ec833b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7052034218714942, tolerance: 0.0064954511306218495\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7352467620324676, tolerance: 0.0064954511306218495\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01340878276278119, tolerance: 2.229516308165847e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013468489083670022, tolerance: 2.229516308165847e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.72019896266085, tolerance: 0.006767850662344651\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7323008235296109, tolerance: 0.006767850662344651\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013888815659987485, tolerance: 2.1019888034714994e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014075549261903107, tolerance: 2.1019888034714994e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7617934183488734, tolerance: 0.006339043303097201\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7737192608632815, tolerance: 0.006339043303097201\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013226132867256785, tolerance: 2.0986798559100284e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01365176724794226, tolerance: 2.0986798559100284e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8672702540696833, tolerance: 0.006127360756077136\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9052899542771831, tolerance: 0.006127360756077136\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011821191363254192, tolerance: 2.0059646397439622e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012657660086794737, tolerance: 2.0059646397439622e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7331687993909282, tolerance: 0.006149219485970364\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7668020794375805, tolerance: 0.006149219485970364\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013389620055661243, tolerance: 1.912012619565586e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013721962823417552, tolerance: 1.912012619565586e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5976163192729617, tolerance: 0.006746587143954202\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.608406241809652, tolerance: 0.006746587143954202\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013788364553845443, tolerance: 2.095146144691556e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013851062043529266, tolerance: 2.095146144691556e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9033342828262791, tolerance: 0.00601680387265788\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9133170803756647, tolerance: 0.00601680387265788\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013344796282662733, tolerance: 2.241942596421511e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01368579522054664, tolerance: 2.241942596421511e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8722946862206046, tolerance: 0.0065670847582299545\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8823670004903104, tolerance: 0.0065670847582299545\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011191464949372214, tolerance: 2.121979089933716e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011427967091668845, tolerance: 2.121979089933716e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8469112194989571, tolerance: 0.006400430121415339\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8434665298486184, tolerance: 0.006400430121415339\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01334983096993471, tolerance: 2.149002846078409e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01386280000580575, tolerance: 2.149002846078409e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8738544728655347, tolerance: 0.006648780797105465\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8774216876149293, tolerance: 0.006648780797105465\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014313681722932223, tolerance: 2.0933775952167613e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014850761595251845, tolerance: 2.0933775952167613e-05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n",
      "1  \n",
      "2  \n",
      "3  \n",
      "4  \n",
      "5  \n",
      "6  \n",
      "7  \n",
      "8  \n",
      "9  \n",
      "Coefficient is 0.022908952699243732, SE is equal to 0.011757157493360372\n"
     ]
    }
   ],
   "source": [
    "def dreg(x,d):\n",
    "    alpha=0.00000001\n",
    "    result = Lasso_post( alpha = alpha ).fit( x , d )\n",
    "    return result\n",
    "\n",
    "def yreg( x , y ):\n",
    "    alpha = 0.00000001\n",
    "    result = Lasso_post( alpha = alpha ).fit( x , y )\n",
    "    return result\n",
    "\n",
    "DML2_lasso_post = DML2_for_PLM(x, d, y, dreg, yreg, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666229fc",
   "metadata": {},
   "source": [
    "## DML with Elastic Net \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5818201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class standard_skl_model:\n",
    "    \n",
    "    def __init__(self, model ):\n",
    "        self.model = model\n",
    "       \n",
    "    def fit( self, X, Y ):\n",
    "        \n",
    "        # Standarization of X and Y\n",
    "        self.scaler_X = StandardScaler()\n",
    "        self.scaler_X.fit( X )\n",
    "        std_X = self.scaler_X.transform( X )\n",
    "                \n",
    "        self.model.fit( std_X , Y )\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def predict( self , X ):\n",
    "        \n",
    "        self.scaler_X = StandardScaler()\n",
    "        self.scaler_X.fit( X )\n",
    "        std_X = self.scaler_X.transform( X )\n",
    "        \n",
    "        prediction = self.model.predict( std_X )\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8872a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \n",
      "Coefficient is -0.04473856775230579, SE is equal to 0.012256020660717949\n"
     ]
    }
   ],
   "source": [
    "# DML with cross-validated Elastic Net:\n",
    "def dreg(x,d):\n",
    "    result = standard_skl_model( ElasticNetCV( cv = 10 , random_state = 0 , l1_ratio = 0.5, max_iter = 100000 ) ).fit( x, d )\n",
    "    return result\n",
    "\n",
    "def yreg(x,y):\n",
    "    result = standard_skl_model( ElasticNetCV( cv = 10 , random_state = 0 , l1_ratio = 0.5, max_iter = 100000 ) ).fit( x, y )\n",
    "    return result\n",
    "\n",
    "DML2_elnet = DML2_for_PLM(x, d, y, dreg, yreg, 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf5257",
   "metadata": {},
   "source": [
    "## DML ridge\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e49d726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \n",
      "Coefficient is -0.004108022155506074, SE is equal to 0.009973034782523245\n"
     ]
    }
   ],
   "source": [
    "#DML with cross-validated Ridge:\n",
    "def dreg(z,d):\n",
    "    result = standard_skl_model( ElasticNetCV( cv = 10 ,  random_state = 0 , l1_ratio = 0.0001 ) ).fit( z, d )\n",
    "    return result\n",
    "\n",
    "def yreg(z,y):\n",
    "    result = standard_skl_model( ElasticNetCV( cv = 10 , random_state = 0 , l1_ratio = 0.0001 ) ).fit( z, y )\n",
    "    return result\n",
    "\n",
    "DML2_ridge = DML2_for_PLM(x, d, y, dreg, yreg, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c95e95",
   "metadata": {},
   "source": [
    "## DML Random forest\n",
    "***\n",
    "\n",
    "Now we are going to predict $y$ and $d$ using Random forest. Note that we have to set the maximun number of features. The number of features is going to be 61 since we have 63 variables and we cannot include $y$ or $d$ as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61dd8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2423eca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-10f97f9b3f09>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 61 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, d )\n",
      "<ipython-input-31-10f97f9b3f09>:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 61 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, y )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-10f97f9b3f09>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 61 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, d )\n",
      "<ipython-input-31-10f97f9b3f09>:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 61 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, y )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \n",
      "Coefficient is -0.032367707723629464, SE is equal to 0.012010075390869464\n"
     ]
    }
   ],
   "source": [
    "#DML with Random Forest:\n",
    "def dreg(z,d):\n",
    "    result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 61 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, d )\n",
    "    return result\n",
    "\n",
    "def yreg(z,y):\n",
    "    result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 61 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, y )\n",
    "    return result\n",
    "\n",
    "DML2_RF = DML2_for_PLM(x, d, y, dreg, yreg, 2)   # set to 2 due to computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c51080a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DML2_lasso</th>\n",
       "      <th>DML2_lasso_post</th>\n",
       "      <th>DML2_elnet</th>\n",
       "      <th>DML2_ridge</th>\n",
       "      <th>DML2_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSEY</th>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>3.700743e-18</td>\n",
       "      <td>8.943463e-18</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSED</th>\n",
       "      <td>0.026099</td>\n",
       "      <td>0.034598</td>\n",
       "      <td>1.480297e-16</td>\n",
       "      <td>1.154632e-15</td>\n",
       "      <td>0.024790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DML2_lasso  DML2_lasso_post    DML2_elnet    DML2_ridge   DML2_RF\n",
       "RMSEY    0.002021         0.000422  3.700743e-18  8.943463e-18  0.001525\n",
       "RMSED    0.026099         0.034598  1.480297e-16  1.154632e-15  0.024790"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods = [DML2_lasso, DML2_lasso_post ,DML2_elnet, DML2_ridge, DML2_RF]\n",
    "mods_name = [\"DML2_lasso\", \"DML2_lasso_post\" ,'DML2_elnet', 'DML2_ridge', 'DML2_RF']\n",
    "\n",
    "def mdl( model , model_name ):\n",
    "    \n",
    "    RMSEY = np.sqrt( np.mean( model[ 'ytil' ] ) ** 2 ) # I have some doubts about these equations...we have to recheck\n",
    "    RMSED = np.sqrt( np.mean( model[ 'dtil' ] ) ** 2 ) # I have some doubts about these equations...we have to recheck\n",
    "    \n",
    "    result = pd.DataFrame( { model_name : [ RMSEY , RMSED ]} , index = [ 'RMSEY' , 'RMSED' ])\n",
    "    return result\n",
    "\n",
    "RES = [ mdl( model , name ) for model, name in zip( mods , mods_name ) ]\n",
    "    \n",
    "\n",
    "pr_Res = pd.concat( RES, axis = 1)\n",
    "\n",
    "pr_Res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9a9840",
   "metadata": {},
   "source": [
    "It looks like the best method for predicting both Y and D is Elastic Net."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12a62c",
   "metadata": {},
   "source": [
    "## Best Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "743f2205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Anaconda\\envs\\renv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \n",
      "Coefficient is -0.058295049580833196, SE is equal to 0.015587324159142883\n"
     ]
    }
   ],
   "source": [
    "# DML with cross-validated Elastic Net:\n",
    "def dreg(x,d):\n",
    "    result = standard_skl_model( ElasticNetCV( cv = 10 , random_state = 0 , l1_ratio = 0.5, max_iter = 100000 ) ).fit( x, d )\n",
    "    return result\n",
    "\n",
    "def yreg(x,y):\n",
    "    result = standard_skl_model( ElasticNetCV( cv = 10 , random_state = 0 , l1_ratio = 0.5, max_iter = 100000 ) ).fit( x, y )\n",
    "    return result\n",
    "\n",
    "DML2_best = DML2_for_PLM(x, d, y, dreg, yreg, 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "255a9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = np.zeros( ( 8 , 2 ))\n",
    "table[ 0 , 0] = table_ols.iloc[ 0 , 0 ]\n",
    "table[ 1 , 0] = table_ols.iloc[ 1 , 0 ]\n",
    "table[ 2 , 0] = DML2_lasso['coef_est']\n",
    "table[ 3 , 0] = DML2_lasso_post['coef_est']\n",
    "table[ 4 , 0] = DML2_ridge['coef_est']\n",
    "table[ 5 , 0] = DML2_elnet['coef_est']\n",
    "table[ 6 , 0] = DML2_RF['coef_est']\n",
    "table[ 7 , 0] = DML2_best['coef_est']\n",
    "table[ 0 , 1] = table_ols.iloc[ 0 , 1 ]\n",
    "table[ 1 , 1] = table_ols.iloc[ 1 , 1 ]\n",
    "table[ 2 , 1] = DML2_lasso['se']\n",
    "table[ 3 , 1] = DML2_lasso_post['se']\n",
    "table[ 4 , 1] = DML2_ridge['se']\n",
    "table[ 5 , 1] = DML2_elnet['se']\n",
    "table[ 6 , 1] = DML2_RF['se']\n",
    "table[ 7 , 1] = DML2_best['se']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef318aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Standard Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline OLS</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Least Squares with controls</th>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post-Lasso</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV Ridge</th>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV Elastic Net</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best</th>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Estimate  Standard Error\n",
       "Baseline OLS                    0.001           0.006\n",
       "Least Squares with controls    -0.009           0.030\n",
       "Lasso                           0.015           0.013\n",
       "Post-Lasso                      0.023           0.012\n",
       "CV Ridge                       -0.004           0.010\n",
       "CV Elastic Net                  0.001           0.013\n",
       "Random Forest                  -0.032           0.012\n",
       "Best                           -0.058           0.016"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame( table , index = [ \"Baseline OLS\", \"Least Squares with controls\", \"Lasso\", \\\n",
    "             \"Post-Lasso\",\"CV Ridge\", \"CV Elastic Net\", \"Random Forest\", \"Best\" ] , \\\n",
    "            columns = [\"Estimate\",\"Standard Error\"] )\n",
    "table.round( 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaae639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
