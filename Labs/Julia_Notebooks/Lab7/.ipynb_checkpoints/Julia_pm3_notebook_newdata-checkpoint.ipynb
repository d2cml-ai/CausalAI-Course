{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Python code replication of:\n",
    "\" https://www.kaggle.com/janniskueck/pm3-notebook-newdata \"\n",
    "* Created by: Alexander Quispe and Anzony Quispe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03819,
     "end_time": "2021-02-13T18:19:43.324200",
     "exception": false,
     "start_time": "2021-02-13T18:19:43.286010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "This notebook contains an example for teaching.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "051d70d956493feee0c6d64651c6a088724dca2a",
    "papermill": {
     "duration": 0.036479,
     "end_time": "2021-02-13T18:19:43.396666",
     "exception": false,
     "start_time": "2021-02-13T18:19:43.360187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A Simple Case Study using Wage Data from 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036639,
     "end_time": "2021-02-13T18:19:43.468425",
     "exception": false,
     "start_time": "2021-02-13T18:19:43.431786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We illustrate how to predict an outcome variable Y in a high-dimensional setting, where the number of covariates $p$ is large in relation to the sample size $n$. So far we have used linear prediction rules, e.g. Lasso regression, for estimation.\n",
    "Now, we also consider nonlinear prediction rules including tree-based methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034705,
     "end_time": "2021-02-13T18:19:43.537814",
     "exception": false,
     "start_time": "2021-02-13T18:19:43.503109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036082,
     "end_time": "2021-02-13T18:19:43.609347",
     "exception": false,
     "start_time": "2021-02-13T18:19:43.573265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Again, we consider data from the U.S. March Supplement of the Current Population Survey (CPS) in 2015.\n",
    "The preproccessed sample consists of $5150$ never-married individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pkg; Pkg.add(\"RData\")\n",
    "# import Pkg; Pkg.add(\"CodecBzip2\")\n",
    "# import Pkg; Pkg.add(\"DataStructures\")\n",
    "# import Pkg; Pkg.add(\"NamedArrays\")\n",
    "# import Pkg; Pkg.add(\"PrettyTables\")\n",
    "# import Pkg; Pkg.add(\"Lasso\")\n",
    "# import Pkg; Pkg.add(\"Libz\")\n",
    "# import Pkg; Pkg.add(\"PlotlyJS\")\n",
    "# import Pkg; Pkg.add(\"StatsBase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RData, LinearAlgebra, GLM, DataFrames, Statistics, Random, Distributions, DataStructures, NamedArrays, PrettyTables,\n",
    "        Plots, StatsBase,StatsPlots, GLM\n",
    "import CodecBzip2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5,150 rows × 20 columns (omitted printing of 11 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>wage</th><th>lwage</th><th>sex</th><th>shs</th><th>hsg</th><th>scl</th><th>clg</th><th>ad</th><th>mw</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>9.61538</td><td>2.26336</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>48.0769</td><td>3.8728</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>11.0577</td><td>2.40313</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>13.9423</td><td>2.63493</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>5</th><td>28.8462</td><td>3.36198</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>11.7308</td><td>2.46222</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>19.2308</td><td>2.95651</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>19.2308</td><td>2.95651</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>12.0</td><td>2.48491</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>19.2308</td><td>2.95651</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>17.3077</td><td>2.85115</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>12.0192</td><td>2.48651</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>12.0192</td><td>2.48651</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>13.4615</td><td>2.59984</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>16.3462</td><td>2.79399</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>27.8846</td><td>3.32808</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>21.6</td><td>3.07269</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>8.65385</td><td>2.158</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>19</th><td>19.2308</td><td>2.95651</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>13.1868</td><td>2.57922</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>10.6838</td><td>2.36872</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>22</th><td>11.5385</td><td>2.44569</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>17.7885</td><td>2.87855</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>24</th><td>19.2308</td><td>2.95651</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>16.3043</td><td>2.79143</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>19.2308</td><td>2.95651</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>27</th><td>14.4231</td><td>2.66883</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>12.0</td><td>2.48491</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>16.8269</td><td>2.82298</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>19.6703</td><td>2.97911</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& wage & lwage & sex & shs & hsg & scl & clg & ad & mw & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 9.61538 & 2.26336 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 48.0769 & 3.8728 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 11.0577 & 2.40313 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 13.9423 & 2.63493 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 28.8462 & 3.36198 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 11.7308 & 2.46222 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 19.2308 & 2.95651 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 19.2308 & 2.95651 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 12.0 & 2.48491 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 19.2308 & 2.95651 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & 17.3077 & 2.85115 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & 12.0192 & 2.48651 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 12.0192 & 2.48651 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 13.4615 & 2.59984 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 16.3462 & 2.79399 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t16 & 27.8846 & 3.32808 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 21.6 & 3.07269 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & 8.65385 & 2.158 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t19 & 19.2308 & 2.95651 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 13.1868 & 2.57922 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 10.6838 & 2.36872 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & 11.5385 & 2.44569 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 17.7885 & 2.87855 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 19.2308 & 2.95651 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & 16.3043 & 2.79143 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 19.2308 & 2.95651 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & 14.4231 & 2.66883 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & 12.0 & 2.48491 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 16.8269 & 2.82298 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 19.6703 & 2.97911 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5150×20 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m wage     \u001b[0m\u001b[1m lwage   \u001b[0m\u001b[1m sex     \u001b[0m\u001b[1m shs     \u001b[0m\u001b[1m hsg     \u001b[0m\u001b[1m scl     \u001b[0m\u001b[1m clg     \u001b[0m\u001b[1m ad    \u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float6\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │  9.61538  2.26336      1.0      0.0      0.0      0.0      1.0      0. ⋯\n",
       "    2 │ 48.0769   3.8728       0.0      0.0      0.0      0.0      1.0      0.\n",
       "    3 │ 11.0577   2.40313      0.0      0.0      1.0      0.0      0.0      0.\n",
       "    4 │ 13.9423   2.63493      1.0      0.0      0.0      0.0      0.0      1.\n",
       "    5 │ 28.8462   3.36198      1.0      0.0      0.0      0.0      1.0      0. ⋯\n",
       "    6 │ 11.7308   2.46222      1.0      0.0      0.0      0.0      1.0      0.\n",
       "    7 │ 19.2308   2.95651      1.0      0.0      1.0      0.0      0.0      0.\n",
       "    8 │ 19.2308   2.95651      0.0      0.0      1.0      0.0      0.0      0.\n",
       "    9 │ 12.0      2.48491      1.0      0.0      1.0      0.0      0.0      0. ⋯\n",
       "   10 │ 19.2308   2.95651      1.0      0.0      0.0      0.0      1.0      0.\n",
       "   11 │ 17.3077   2.85115      1.0      0.0      1.0      0.0      0.0      0.\n",
       "  ⋮   │    ⋮         ⋮        ⋮        ⋮        ⋮        ⋮        ⋮        ⋮   ⋱\n",
       " 5141 │ 45.5466   3.81874      1.0      0.0      0.0      0.0      1.0      0.\n",
       " 5142 │ 22.5962   3.11778      0.0      0.0      1.0      0.0      0.0      0. ⋯\n",
       " 5143 │ 16.8269   2.82298      0.0      0.0      1.0      0.0      0.0      0.\n",
       " 5144 │ 24.0385   3.17966      1.0      0.0      0.0      0.0      1.0      0.\n",
       " 5145 │ 13.8462   2.62801      0.0      0.0      0.0      0.0      1.0      0.\n",
       " 5146 │ 14.7692   2.69255      0.0      0.0      0.0      0.0      1.0      0. ⋯\n",
       " 5147 │ 23.0769   3.13883      1.0      0.0      0.0      1.0      0.0      0.\n",
       " 5148 │ 38.4615   3.64966      0.0      0.0      0.0      0.0      0.0      1.\n",
       " 5149 │ 32.967    3.49551      0.0      0.0      1.0      0.0      0.0      0.\n",
       " 5150 │ 17.3077   2.85115      0.0      0.0      0.0      0.0      0.0      1. ⋯\n",
       "\u001b[36m                                                13 columns and 5129 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdata_read = load(\"../../../data/wage2015_subsample_inference.RData\")\n",
    "data = rdata_read[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034902,
     "end_time": "2021-02-13T18:19:43.994834",
     "exception": false,
     "start_time": "2021-02-13T18:19:43.959932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The outcomes $Y_i$'s are hourly (log) wages of never-married workers living in the U.S. The raw regressors $Z_i$'s consist of a variety of characteristics, including experience, education and industry and occupation indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18-element Vector{String}:\n",
       " \"sex\"\n",
       " \"shs\"\n",
       " \"hsg\"\n",
       " \"scl\"\n",
       " \"clg\"\n",
       " \"ad\"\n",
       " \"mw\"\n",
       " \"so\"\n",
       " \"we\"\n",
       " \"ne\"\n",
       " \"exp1\"\n",
       " \"exp2\"\n",
       " \"exp3\"\n",
       " \"exp4\"\n",
       " \"occ\"\n",
       " \"occ2\"\n",
       " \"ind\"\n",
       " \"ind2\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = select( data, Not( [\"lwage\", \"wage\"]) )\n",
    "names( Z )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037074,
     "end_time": "2021-02-13T18:19:44.196749",
     "exception": false,
     "start_time": "2021-02-13T18:19:44.159675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following figure shows the weekly wage distribution from the US survey data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip330\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip330)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip331\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip330)\" d=\"\n",
       "M264.287 1423.18 L2352.76 1423.18 L2352.76 123.472 L264.287 123.472  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip332\">\n",
       "    <rect x=\"264\" y=\"123\" width=\"2089\" height=\"1301\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  379.157,1423.18 379.157,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  723.366,1423.18 723.366,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1067.58,1423.18 1067.58,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1411.78,1423.18 1411.78,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1755.99,1423.18 1755.99,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2100.2,1423.18 2100.2,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  264.287,1423.18 2352.76,1423.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  379.157,1423.18 379.157,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  723.366,1423.18 723.366,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1067.58,1423.18 1067.58,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1411.78,1423.18 1411.78,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1755.99,1423.18 1755.99,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2100.2,1423.18 2100.2,1404.28 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip330)\" d=\"M379.157 1454.1 Q375.546 1454.1 373.717 1457.66 Q371.911 1461.2 371.911 1468.33 Q371.911 1475.44 373.717 1479.01 Q375.546 1482.55 379.157 1482.55 Q382.791 1482.55 384.597 1479.01 Q386.425 1475.44 386.425 1468.33 Q386.425 1461.2 384.597 1457.66 Q382.791 1454.1 379.157 1454.1 M379.157 1450.39 Q384.967 1450.39 388.023 1455 Q391.101 1459.58 391.101 1468.33 Q391.101 1477.06 388.023 1481.67 Q384.967 1486.25 379.157 1486.25 Q373.347 1486.25 370.268 1481.67 Q367.212 1477.06 367.212 1468.33 Q367.212 1459.58 370.268 1455 Q373.347 1450.39 379.157 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M682.973 1481.64 L690.612 1481.64 L690.612 1455.28 L682.301 1456.95 L682.301 1452.69 L690.565 1451.02 L695.241 1451.02 L695.241 1481.64 L702.88 1481.64 L702.88 1485.58 L682.973 1485.58 L682.973 1481.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M722.324 1454.1 Q718.713 1454.1 716.885 1457.66 Q715.079 1461.2 715.079 1468.33 Q715.079 1475.44 716.885 1479.01 Q718.713 1482.55 722.324 1482.55 Q725.959 1482.55 727.764 1479.01 Q729.593 1475.44 729.593 1468.33 Q729.593 1461.2 727.764 1457.66 Q725.959 1454.1 722.324 1454.1 M722.324 1450.39 Q728.134 1450.39 731.19 1455 Q734.269 1459.58 734.269 1468.33 Q734.269 1477.06 731.19 1481.67 Q728.134 1486.25 722.324 1486.25 Q716.514 1486.25 713.435 1481.67 Q710.38 1477.06 710.38 1468.33 Q710.38 1459.58 713.435 1455 Q716.514 1450.39 722.324 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M752.486 1454.1 Q748.875 1454.1 747.046 1457.66 Q745.241 1461.2 745.241 1468.33 Q745.241 1475.44 747.046 1479.01 Q748.875 1482.55 752.486 1482.55 Q756.12 1482.55 757.926 1479.01 Q759.755 1475.44 759.755 1468.33 Q759.755 1461.2 757.926 1457.66 Q756.12 1454.1 752.486 1454.1 M752.486 1450.39 Q758.296 1450.39 761.352 1455 Q764.431 1459.58 764.431 1468.33 Q764.431 1477.06 761.352 1481.67 Q758.296 1486.25 752.486 1486.25 Q746.676 1486.25 743.597 1481.67 Q740.542 1477.06 740.542 1468.33 Q740.542 1459.58 743.597 1455 Q746.676 1450.39 752.486 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1031.27 1481.64 L1047.59 1481.64 L1047.59 1485.58 L1025.64 1485.58 L1025.64 1481.64 Q1028.3 1478.89 1032.89 1474.26 Q1037.49 1469.61 1038.67 1468.27 Q1040.92 1465.74 1041.8 1464.01 Q1042.7 1462.25 1042.7 1460.56 Q1042.7 1457.8 1040.76 1456.07 Q1038.84 1454.33 1035.74 1454.33 Q1033.54 1454.33 1031.08 1455.09 Q1028.65 1455.86 1025.87 1457.41 L1025.87 1452.69 Q1028.7 1451.55 1031.15 1450.97 Q1033.61 1450.39 1035.64 1450.39 Q1041.01 1450.39 1044.21 1453.08 Q1047.4 1455.77 1047.4 1460.26 Q1047.4 1462.39 1046.59 1464.31 Q1045.8 1466.2 1043.7 1468.8 Q1043.12 1469.47 1040.02 1472.69 Q1036.92 1475.88 1031.27 1481.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1067.4 1454.1 Q1063.79 1454.1 1061.96 1457.66 Q1060.16 1461.2 1060.16 1468.33 Q1060.16 1475.44 1061.96 1479.01 Q1063.79 1482.55 1067.4 1482.55 Q1071.04 1482.55 1072.84 1479.01 Q1074.67 1475.44 1074.67 1468.33 Q1074.67 1461.2 1072.84 1457.66 Q1071.04 1454.1 1067.4 1454.1 M1067.4 1450.39 Q1073.21 1450.39 1076.27 1455 Q1079.35 1459.58 1079.35 1468.33 Q1079.35 1477.06 1076.27 1481.67 Q1073.21 1486.25 1067.4 1486.25 Q1061.59 1486.25 1058.51 1481.67 Q1055.46 1477.06 1055.46 1468.33 Q1055.46 1459.58 1058.51 1455 Q1061.59 1450.39 1067.4 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1097.56 1454.1 Q1093.95 1454.1 1092.12 1457.66 Q1090.32 1461.2 1090.32 1468.33 Q1090.32 1475.44 1092.12 1479.01 Q1093.95 1482.55 1097.56 1482.55 Q1101.2 1482.55 1103 1479.01 Q1104.83 1475.44 1104.83 1468.33 Q1104.83 1461.2 1103 1457.66 Q1101.2 1454.1 1097.56 1454.1 M1097.56 1450.39 Q1103.37 1450.39 1106.43 1455 Q1109.51 1459.58 1109.51 1468.33 Q1109.51 1477.06 1106.43 1481.67 Q1103.37 1486.25 1097.56 1486.25 Q1091.75 1486.25 1088.67 1481.67 Q1085.62 1477.06 1085.62 1468.33 Q1085.62 1459.58 1088.67 1455 Q1091.75 1450.39 1097.56 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1385.55 1466.95 Q1388.9 1467.66 1390.78 1469.93 Q1392.68 1472.2 1392.68 1475.53 Q1392.68 1480.65 1389.16 1483.45 Q1385.64 1486.25 1379.16 1486.25 Q1376.98 1486.25 1374.67 1485.81 Q1372.37 1485.39 1369.92 1484.54 L1369.92 1480.02 Q1371.87 1481.16 1374.18 1481.74 Q1376.5 1482.32 1379.02 1482.32 Q1383.42 1482.32 1385.71 1480.58 Q1388.02 1478.84 1388.02 1475.53 Q1388.02 1472.48 1385.87 1470.77 Q1383.74 1469.03 1379.92 1469.03 L1375.89 1469.03 L1375.89 1465.19 L1380.11 1465.19 Q1383.56 1465.19 1385.38 1463.82 Q1387.21 1462.43 1387.21 1459.84 Q1387.21 1457.18 1385.31 1455.77 Q1383.44 1454.33 1379.92 1454.33 Q1378 1454.33 1375.8 1454.75 Q1373.6 1455.16 1370.96 1456.04 L1370.96 1451.88 Q1373.62 1451.14 1375.94 1450.77 Q1378.28 1450.39 1380.34 1450.39 Q1385.66 1450.39 1388.76 1452.83 Q1391.87 1455.23 1391.87 1459.35 Q1391.87 1462.22 1390.22 1464.21 Q1388.58 1466.18 1385.55 1466.95 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1411.54 1454.1 Q1407.93 1454.1 1406.1 1457.66 Q1404.3 1461.2 1404.3 1468.33 Q1404.3 1475.44 1406.1 1479.01 Q1407.93 1482.55 1411.54 1482.55 Q1415.18 1482.55 1416.98 1479.01 Q1418.81 1475.44 1418.81 1468.33 Q1418.81 1461.2 1416.98 1457.66 Q1415.18 1454.1 1411.54 1454.1 M1411.54 1450.39 Q1417.35 1450.39 1420.41 1455 Q1423.49 1459.58 1423.49 1468.33 Q1423.49 1477.06 1420.41 1481.67 Q1417.35 1486.25 1411.54 1486.25 Q1405.73 1486.25 1402.65 1481.67 Q1399.6 1477.06 1399.6 1468.33 Q1399.6 1459.58 1402.65 1455 Q1405.73 1450.39 1411.54 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1441.7 1454.1 Q1438.09 1454.1 1436.26 1457.66 Q1434.46 1461.2 1434.46 1468.33 Q1434.46 1475.44 1436.26 1479.01 Q1438.09 1482.55 1441.7 1482.55 Q1445.34 1482.55 1447.14 1479.01 Q1448.97 1475.44 1448.97 1468.33 Q1448.97 1461.2 1447.14 1457.66 Q1445.34 1454.1 1441.7 1454.1 M1441.7 1450.39 Q1447.51 1450.39 1450.57 1455 Q1453.65 1459.58 1453.65 1468.33 Q1453.65 1477.06 1450.57 1481.67 Q1447.51 1486.25 1441.7 1486.25 Q1435.89 1486.25 1432.81 1481.67 Q1429.76 1477.06 1429.76 1468.33 Q1429.76 1459.58 1432.81 1455 Q1435.89 1450.39 1441.7 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1729.08 1455.09 L1717.28 1473.54 L1729.08 1473.54 L1729.08 1455.09 M1727.86 1451.02 L1733.74 1451.02 L1733.74 1473.54 L1738.67 1473.54 L1738.67 1477.43 L1733.74 1477.43 L1733.74 1485.58 L1729.08 1485.58 L1729.08 1477.43 L1713.48 1477.43 L1713.48 1472.92 L1727.86 1451.02 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1756.4 1454.1 Q1752.79 1454.1 1750.96 1457.66 Q1749.15 1461.2 1749.15 1468.33 Q1749.15 1475.44 1750.96 1479.01 Q1752.79 1482.55 1756.4 1482.55 Q1760.03 1482.55 1761.84 1479.01 Q1763.67 1475.44 1763.67 1468.33 Q1763.67 1461.2 1761.84 1457.66 Q1760.03 1454.1 1756.4 1454.1 M1756.4 1450.39 Q1762.21 1450.39 1765.26 1455 Q1768.34 1459.58 1768.34 1468.33 Q1768.34 1477.06 1765.26 1481.67 Q1762.21 1486.25 1756.4 1486.25 Q1750.59 1486.25 1747.51 1481.67 Q1744.45 1477.06 1744.45 1468.33 Q1744.45 1459.58 1747.51 1455 Q1750.59 1450.39 1756.4 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1786.56 1454.1 Q1782.95 1454.1 1781.12 1457.66 Q1779.32 1461.2 1779.32 1468.33 Q1779.32 1475.44 1781.12 1479.01 Q1782.95 1482.55 1786.56 1482.55 Q1790.19 1482.55 1792 1479.01 Q1793.83 1475.44 1793.83 1468.33 Q1793.83 1461.2 1792 1457.66 Q1790.19 1454.1 1786.56 1454.1 M1786.56 1450.39 Q1792.37 1450.39 1795.43 1455 Q1798.5 1459.58 1798.5 1468.33 Q1798.5 1477.06 1795.43 1481.67 Q1792.37 1486.25 1786.56 1486.25 Q1780.75 1486.25 1777.67 1481.67 Q1774.62 1477.06 1774.62 1468.33 Q1774.62 1459.58 1777.67 1455 Q1780.75 1450.39 1786.56 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M2059.82 1451.02 L2078.18 1451.02 L2078.18 1454.96 L2064.1 1454.96 L2064.1 1463.43 Q2065.12 1463.08 2066.14 1462.92 Q2067.16 1462.73 2068.18 1462.73 Q2073.96 1462.73 2077.34 1465.9 Q2080.72 1469.08 2080.72 1474.49 Q2080.72 1480.07 2077.25 1483.17 Q2073.78 1486.25 2067.46 1486.25 Q2065.28 1486.25 2063.02 1485.88 Q2060.77 1485.51 2058.36 1484.77 L2058.36 1480.07 Q2060.45 1481.2 2062.67 1481.76 Q2064.89 1482.32 2067.37 1482.32 Q2071.37 1482.32 2073.71 1480.21 Q2076.05 1478.1 2076.05 1474.49 Q2076.05 1470.88 2073.71 1468.77 Q2071.37 1466.67 2067.37 1466.67 Q2065.49 1466.67 2063.62 1467.08 Q2061.77 1467.5 2059.82 1468.38 L2059.82 1451.02 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M2099.94 1454.1 Q2096.33 1454.1 2094.5 1457.66 Q2092.69 1461.2 2092.69 1468.33 Q2092.69 1475.44 2094.5 1479.01 Q2096.33 1482.55 2099.94 1482.55 Q2103.57 1482.55 2105.38 1479.01 Q2107.21 1475.44 2107.21 1468.33 Q2107.21 1461.2 2105.38 1457.66 Q2103.57 1454.1 2099.94 1454.1 M2099.94 1450.39 Q2105.75 1450.39 2108.8 1455 Q2111.88 1459.58 2111.88 1468.33 Q2111.88 1477.06 2108.8 1481.67 Q2105.75 1486.25 2099.94 1486.25 Q2094.13 1486.25 2091.05 1481.67 Q2087.99 1477.06 2087.99 1468.33 Q2087.99 1459.58 2091.05 1455 Q2094.13 1450.39 2099.94 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M2130.1 1454.1 Q2126.49 1454.1 2124.66 1457.66 Q2122.85 1461.2 2122.85 1468.33 Q2122.85 1475.44 2124.66 1479.01 Q2126.49 1482.55 2130.1 1482.55 Q2133.73 1482.55 2135.54 1479.01 Q2137.37 1475.44 2137.37 1468.33 Q2137.37 1461.2 2135.54 1457.66 Q2133.73 1454.1 2130.1 1454.1 M2130.1 1450.39 Q2135.91 1450.39 2138.96 1455 Q2142.04 1459.58 2142.04 1468.33 Q2142.04 1477.06 2138.96 1481.67 Q2135.91 1486.25 2130.1 1486.25 Q2124.29 1486.25 2121.21 1481.67 Q2118.15 1477.06 2118.15 1468.33 Q2118.15 1459.58 2121.21 1455 Q2124.29 1450.39 2130.1 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1270.68 1549.81 Q1270.68 1543.44 1268.04 1539.94 Q1265.43 1536.44 1260.68 1536.44 Q1255.97 1536.44 1253.33 1539.94 Q1250.72 1543.44 1250.72 1549.81 Q1250.72 1556.14 1253.33 1559.64 Q1255.97 1563.14 1260.68 1563.14 Q1265.43 1563.14 1268.04 1559.64 Q1270.68 1556.14 1270.68 1549.81 M1276.53 1563.62 Q1276.53 1572.72 1272.49 1577.15 Q1268.45 1581.6 1260.11 1581.6 Q1257.02 1581.6 1254.29 1581.13 Q1251.55 1580.68 1248.97 1579.72 L1248.97 1574.03 Q1251.55 1575.43 1254.06 1576.1 Q1256.58 1576.76 1259.19 1576.76 Q1264.95 1576.76 1267.81 1573.74 Q1270.68 1570.75 1270.68 1564.67 L1270.68 1561.77 Q1268.86 1564.92 1266.03 1566.48 Q1263.2 1568.04 1259.25 1568.04 Q1252.69 1568.04 1248.68 1563.05 Q1244.67 1558.05 1244.67 1549.81 Q1244.67 1541.53 1248.68 1536.53 Q1252.69 1531.54 1259.25 1531.54 Q1263.2 1531.54 1266.03 1533.1 Q1268.86 1534.66 1270.68 1537.81 L1270.68 1532.4 L1276.53 1532.4 L1276.53 1563.62 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1302.67 1518.58 Q1298.4 1525.9 1296.33 1533.06 Q1294.26 1540.23 1294.26 1547.58 Q1294.26 1554.93 1296.33 1562.16 Q1298.43 1569.35 1302.67 1576.64 L1297.57 1576.64 Q1292.8 1569.16 1290.41 1561.93 Q1288.06 1554.71 1288.06 1547.58 Q1288.06 1540.48 1290.41 1533.29 Q1292.77 1526.09 1297.57 1518.58 L1302.67 1518.58 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1311.99 1520.52 L1318.9 1520.52 L1330.71 1538.19 L1342.58 1520.52 L1349.48 1520.52 L1334.21 1543.34 L1350.5 1568.04 L1343.6 1568.04 L1330.23 1547.83 L1316.77 1568.04 L1309.83 1568.04 L1326.79 1542.68 L1311.99 1520.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1357.76 1518.58 L1362.85 1518.58 Q1367.63 1526.09 1369.98 1533.29 Q1372.37 1540.48 1372.37 1547.58 Q1372.37 1554.71 1369.98 1561.93 Q1367.63 1569.16 1362.85 1576.64 L1357.76 1576.64 Q1361.99 1569.35 1364.06 1562.16 Q1366.16 1554.93 1366.16 1547.58 Q1366.16 1540.23 1364.06 1533.06 Q1361.99 1525.9 1357.76 1518.58 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  264.287,1386.4 2352.76,1386.4 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  264.287,1166.1 2352.76,1166.1 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  264.287,945.814 2352.76,945.814 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  264.287,725.523 2352.76,725.523 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  264.287,505.232 2352.76,505.232 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  264.287,284.941 2352.76,284.941 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  264.287,1423.18 264.287,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  264.287,1386.4 283.185,1386.4 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  264.287,1166.1 283.185,1166.1 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  264.287,945.814 283.185,945.814 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  264.287,725.523 283.185,725.523 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  264.287,505.232 283.185,505.232 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip330)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  264.287,284.941 283.185,284.941 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip330)\" d=\"M216.343 1372.19 Q212.732 1372.19 210.903 1375.76 Q209.098 1379.3 209.098 1386.43 Q209.098 1393.54 210.903 1397.1 Q212.732 1400.64 216.343 1400.64 Q219.977 1400.64 221.783 1397.1 Q223.611 1393.54 223.611 1386.43 Q223.611 1379.3 221.783 1375.76 Q219.977 1372.19 216.343 1372.19 M216.343 1368.49 Q222.153 1368.49 225.209 1373.1 Q228.287 1377.68 228.287 1386.43 Q228.287 1395.16 225.209 1399.76 Q222.153 1404.35 216.343 1404.35 Q210.533 1404.35 207.454 1399.76 Q204.399 1395.16 204.399 1386.43 Q204.399 1377.68 207.454 1373.1 Q210.533 1368.49 216.343 1368.49 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M146.066 1148.82 L164.422 1148.82 L164.422 1152.76 L150.348 1152.76 L150.348 1161.23 Q151.366 1160.88 152.385 1160.72 Q153.403 1160.54 154.422 1160.54 Q160.209 1160.54 163.589 1163.71 Q166.968 1166.88 166.968 1172.3 Q166.968 1177.88 163.496 1180.98 Q160.024 1184.06 153.704 1184.06 Q151.528 1184.06 149.26 1183.69 Q147.015 1183.32 144.607 1182.57 L144.607 1177.88 Q146.691 1179.01 148.913 1179.57 Q151.135 1180.12 153.612 1180.12 Q157.616 1180.12 159.954 1178.01 Q162.292 1175.91 162.292 1172.3 Q162.292 1168.69 159.954 1166.58 Q157.616 1164.47 153.612 1164.47 Q151.737 1164.47 149.862 1164.89 Q148.01 1165.31 146.066 1166.19 L146.066 1148.82 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M186.181 1151.9 Q182.57 1151.9 180.741 1155.47 Q178.936 1159.01 178.936 1166.14 Q178.936 1173.25 180.741 1176.81 Q182.57 1180.35 186.181 1180.35 Q189.815 1180.35 191.621 1176.81 Q193.45 1173.25 193.45 1166.14 Q193.45 1159.01 191.621 1155.47 Q189.815 1151.9 186.181 1151.9 M186.181 1148.2 Q191.991 1148.2 195.047 1152.81 Q198.125 1157.39 198.125 1166.14 Q198.125 1174.87 195.047 1179.47 Q191.991 1184.06 186.181 1184.06 Q180.371 1184.06 177.292 1179.47 Q174.237 1174.87 174.237 1166.14 Q174.237 1157.39 177.292 1152.81 Q180.371 1148.2 186.181 1148.2 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M216.343 1151.9 Q212.732 1151.9 210.903 1155.47 Q209.098 1159.01 209.098 1166.14 Q209.098 1173.25 210.903 1176.81 Q212.732 1180.35 216.343 1180.35 Q219.977 1180.35 221.783 1176.81 Q223.611 1173.25 223.611 1166.14 Q223.611 1159.01 221.783 1155.47 Q219.977 1151.9 216.343 1151.9 M216.343 1148.2 Q222.153 1148.2 225.209 1152.81 Q228.287 1157.39 228.287 1166.14 Q228.287 1174.87 225.209 1179.47 Q222.153 1184.06 216.343 1184.06 Q210.533 1184.06 207.454 1179.47 Q204.399 1174.87 204.399 1166.14 Q204.399 1157.39 207.454 1152.81 Q210.533 1148.2 216.343 1148.2 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M116.668 959.159 L124.306 959.159 L124.306 932.793 L115.996 934.46 L115.996 930.2 L124.26 928.534 L128.936 928.534 L128.936 959.159 L136.575 959.159 L136.575 963.094 L116.668 963.094 L116.668 959.159 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M156.019 931.612 Q152.408 931.612 150.579 935.177 Q148.774 938.719 148.774 945.849 Q148.774 952.955 150.579 956.52 Q152.408 960.061 156.019 960.061 Q159.653 960.061 161.459 956.52 Q163.288 952.955 163.288 945.849 Q163.288 938.719 161.459 935.177 Q159.653 931.612 156.019 931.612 M156.019 927.909 Q161.829 927.909 164.885 932.515 Q167.964 937.099 167.964 945.849 Q167.964 954.575 164.885 959.182 Q161.829 963.765 156.019 963.765 Q150.209 963.765 147.13 959.182 Q144.075 954.575 144.075 945.849 Q144.075 937.099 147.13 932.515 Q150.209 927.909 156.019 927.909 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M186.181 931.612 Q182.57 931.612 180.741 935.177 Q178.936 938.719 178.936 945.849 Q178.936 952.955 180.741 956.52 Q182.57 960.061 186.181 960.061 Q189.815 960.061 191.621 956.52 Q193.45 952.955 193.45 945.849 Q193.45 938.719 191.621 935.177 Q189.815 931.612 186.181 931.612 M186.181 927.909 Q191.991 927.909 195.047 932.515 Q198.125 937.099 198.125 945.849 Q198.125 954.575 195.047 959.182 Q191.991 963.765 186.181 963.765 Q180.371 963.765 177.292 959.182 Q174.237 954.575 174.237 945.849 Q174.237 937.099 177.292 932.515 Q180.371 927.909 186.181 927.909 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M216.343 931.612 Q212.732 931.612 210.903 935.177 Q209.098 938.719 209.098 945.849 Q209.098 952.955 210.903 956.52 Q212.732 960.061 216.343 960.061 Q219.977 960.061 221.783 956.52 Q223.611 952.955 223.611 945.849 Q223.611 938.719 221.783 935.177 Q219.977 931.612 216.343 931.612 M216.343 927.909 Q222.153 927.909 225.209 932.515 Q228.287 937.099 228.287 945.849 Q228.287 954.575 225.209 959.182 Q222.153 963.765 216.343 963.765 Q210.533 963.765 207.454 959.182 Q204.399 954.575 204.399 945.849 Q204.399 937.099 207.454 932.515 Q210.533 927.909 216.343 927.909 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M116.668 738.868 L124.306 738.868 L124.306 712.502 L115.996 714.169 L115.996 709.91 L124.26 708.243 L128.936 708.243 L128.936 738.868 L136.575 738.868 L136.575 742.803 L116.668 742.803 L116.668 738.868 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M146.066 708.243 L164.422 708.243 L164.422 712.178 L150.348 712.178 L150.348 720.65 Q151.366 720.303 152.385 720.141 Q153.403 719.956 154.422 719.956 Q160.209 719.956 163.589 723.127 Q166.968 726.298 166.968 731.715 Q166.968 737.294 163.496 740.395 Q160.024 743.474 153.704 743.474 Q151.528 743.474 149.26 743.104 Q147.015 742.733 144.607 741.993 L144.607 737.294 Q146.691 738.428 148.913 738.983 Q151.135 739.539 153.612 739.539 Q157.616 739.539 159.954 737.433 Q162.292 735.326 162.292 731.715 Q162.292 728.104 159.954 725.997 Q157.616 723.891 153.612 723.891 Q151.737 723.891 149.862 724.308 Q148.01 724.724 146.066 725.604 L146.066 708.243 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M186.181 711.322 Q182.57 711.322 180.741 714.886 Q178.936 718.428 178.936 725.558 Q178.936 732.664 180.741 736.229 Q182.57 739.77 186.181 739.77 Q189.815 739.77 191.621 736.229 Q193.45 732.664 193.45 725.558 Q193.45 718.428 191.621 714.886 Q189.815 711.322 186.181 711.322 M186.181 707.618 Q191.991 707.618 195.047 712.224 Q198.125 716.808 198.125 725.558 Q198.125 734.284 195.047 738.891 Q191.991 743.474 186.181 743.474 Q180.371 743.474 177.292 738.891 Q174.237 734.284 174.237 725.558 Q174.237 716.808 177.292 712.224 Q180.371 707.618 186.181 707.618 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M216.343 711.322 Q212.732 711.322 210.903 714.886 Q209.098 718.428 209.098 725.558 Q209.098 732.664 210.903 736.229 Q212.732 739.77 216.343 739.77 Q219.977 739.77 221.783 736.229 Q223.611 732.664 223.611 725.558 Q223.611 718.428 221.783 714.886 Q219.977 711.322 216.343 711.322 M216.343 707.618 Q222.153 707.618 225.209 712.224 Q228.287 716.808 228.287 725.558 Q228.287 734.284 225.209 738.891 Q222.153 743.474 216.343 743.474 Q210.533 743.474 207.454 738.891 Q204.399 734.284 204.399 725.558 Q204.399 716.808 207.454 712.224 Q210.533 707.618 216.343 707.618 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M119.885 518.577 L136.204 518.577 L136.204 522.512 L114.26 522.512 L114.26 518.577 Q116.922 515.822 121.505 511.193 Q126.112 506.54 127.292 505.197 Q129.538 502.674 130.417 500.938 Q131.32 499.179 131.32 497.489 Q131.32 494.734 129.376 492.998 Q127.455 491.262 124.353 491.262 Q122.154 491.262 119.7 492.026 Q117.269 492.79 114.492 494.341 L114.492 489.619 Q117.316 488.484 119.769 487.906 Q122.223 487.327 124.26 487.327 Q129.63 487.327 132.825 490.012 Q136.019 492.697 136.019 497.188 Q136.019 499.318 135.209 501.239 Q134.422 503.137 132.316 505.73 Q131.737 506.401 128.635 509.618 Q125.533 512.813 119.885 518.577 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M156.019 491.031 Q152.408 491.031 150.579 494.595 Q148.774 498.137 148.774 505.267 Q148.774 512.373 150.579 515.938 Q152.408 519.48 156.019 519.48 Q159.653 519.48 161.459 515.938 Q163.288 512.373 163.288 505.267 Q163.288 498.137 161.459 494.595 Q159.653 491.031 156.019 491.031 M156.019 487.327 Q161.829 487.327 164.885 491.933 Q167.964 496.517 167.964 505.267 Q167.964 513.993 164.885 518.6 Q161.829 523.183 156.019 523.183 Q150.209 523.183 147.13 518.6 Q144.075 513.993 144.075 505.267 Q144.075 496.517 147.13 491.933 Q150.209 487.327 156.019 487.327 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M186.181 491.031 Q182.57 491.031 180.741 494.595 Q178.936 498.137 178.936 505.267 Q178.936 512.373 180.741 515.938 Q182.57 519.48 186.181 519.48 Q189.815 519.48 191.621 515.938 Q193.45 512.373 193.45 505.267 Q193.45 498.137 191.621 494.595 Q189.815 491.031 186.181 491.031 M186.181 487.327 Q191.991 487.327 195.047 491.933 Q198.125 496.517 198.125 505.267 Q198.125 513.993 195.047 518.6 Q191.991 523.183 186.181 523.183 Q180.371 523.183 177.292 518.6 Q174.237 513.993 174.237 505.267 Q174.237 496.517 177.292 491.933 Q180.371 487.327 186.181 487.327 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M216.343 491.031 Q212.732 491.031 210.903 494.595 Q209.098 498.137 209.098 505.267 Q209.098 512.373 210.903 515.938 Q212.732 519.48 216.343 519.48 Q219.977 519.48 221.783 515.938 Q223.611 512.373 223.611 505.267 Q223.611 498.137 221.783 494.595 Q219.977 491.031 216.343 491.031 M216.343 487.327 Q222.153 487.327 225.209 491.933 Q228.287 496.517 228.287 505.267 Q228.287 513.993 225.209 518.6 Q222.153 523.183 216.343 523.183 Q210.533 523.183 207.454 518.6 Q204.399 513.993 204.399 505.267 Q204.399 496.517 207.454 491.933 Q210.533 487.327 216.343 487.327 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M119.885 298.286 L136.204 298.286 L136.204 302.221 L114.26 302.221 L114.26 298.286 Q116.922 295.531 121.505 290.902 Q126.112 286.249 127.292 284.906 Q129.538 282.383 130.417 280.647 Q131.32 278.888 131.32 277.198 Q131.32 274.443 129.376 272.707 Q127.455 270.971 124.353 270.971 Q122.154 270.971 119.7 271.735 Q117.269 272.499 114.492 274.05 L114.492 269.328 Q117.316 268.193 119.769 267.615 Q122.223 267.036 124.26 267.036 Q129.63 267.036 132.825 269.721 Q136.019 272.406 136.019 276.897 Q136.019 279.027 135.209 280.948 Q134.422 282.846 132.316 285.439 Q131.737 286.11 128.635 289.328 Q125.533 292.522 119.885 298.286 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M146.066 267.661 L164.422 267.661 L164.422 271.596 L150.348 271.596 L150.348 280.068 Q151.366 279.721 152.385 279.559 Q153.403 279.374 154.422 279.374 Q160.209 279.374 163.589 282.545 Q166.968 285.716 166.968 291.133 Q166.968 296.712 163.496 299.814 Q160.024 302.892 153.704 302.892 Q151.528 302.892 149.26 302.522 Q147.015 302.152 144.607 301.411 L144.607 296.712 Q146.691 297.846 148.913 298.402 Q151.135 298.957 153.612 298.957 Q157.616 298.957 159.954 296.851 Q162.292 294.744 162.292 291.133 Q162.292 287.522 159.954 285.416 Q157.616 283.309 153.612 283.309 Q151.737 283.309 149.862 283.726 Q148.01 284.142 146.066 285.022 L146.066 267.661 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M186.181 270.74 Q182.57 270.74 180.741 274.304 Q178.936 277.846 178.936 284.976 Q178.936 292.082 180.741 295.647 Q182.57 299.189 186.181 299.189 Q189.815 299.189 191.621 295.647 Q193.45 292.082 193.45 284.976 Q193.45 277.846 191.621 274.304 Q189.815 270.74 186.181 270.74 M186.181 267.036 Q191.991 267.036 195.047 271.642 Q198.125 276.226 198.125 284.976 Q198.125 293.703 195.047 298.309 Q191.991 302.892 186.181 302.892 Q180.371 302.892 177.292 298.309 Q174.237 293.703 174.237 284.976 Q174.237 276.226 177.292 271.642 Q180.371 267.036 186.181 267.036 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M216.343 270.74 Q212.732 270.74 210.903 274.304 Q209.098 277.846 209.098 284.976 Q209.098 292.082 210.903 295.647 Q212.732 299.189 216.343 299.189 Q219.977 299.189 221.783 295.647 Q223.611 292.082 223.611 284.976 Q223.611 277.846 221.783 274.304 Q219.977 270.74 216.343 270.74 M216.343 267.036 Q222.153 267.036 225.209 271.642 Q228.287 276.226 228.287 284.976 Q228.287 293.703 225.209 298.309 Q222.153 302.892 216.343 302.892 Q210.533 302.892 207.454 298.309 Q204.399 293.703 204.399 284.976 Q204.399 276.226 207.454 271.642 Q210.533 267.036 216.343 267.036 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M42.4881 939.503 L64.0042 939.503 L64.0042 945.359 L42.679 945.359 Q37.6183 945.359 35.1038 947.333 Q32.5894 949.306 32.5894 953.253 Q32.5894 957.995 35.6131 960.732 Q38.6368 963.47 43.8567 963.47 L64.0042 963.47 L64.0042 969.358 L14.479 969.358 L14.479 963.47 L33.8944 963.47 Q30.6797 961.369 29.0883 958.536 Q27.4968 955.672 27.4968 951.948 Q27.4968 945.805 31.3163 942.654 Q35.1038 939.503 42.4881 939.503 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M32.4621 914.008 Q32.4621 918.719 36.1542 921.456 Q39.8145 924.193 46.212 924.193 Q52.6095 924.193 56.3017 921.488 Q59.9619 918.751 59.9619 914.008 Q59.9619 909.329 56.2698 906.592 Q52.5777 903.855 46.212 903.855 Q39.8781 903.855 36.186 906.592 Q32.4621 909.329 32.4621 914.008 M27.4968 914.008 Q27.4968 906.369 32.4621 902.009 Q37.4273 897.648 46.212 897.648 Q54.9649 897.648 59.9619 902.009 Q64.9272 906.369 64.9272 914.008 Q64.9272 921.679 59.9619 926.039 Q54.9649 930.368 46.212 930.368 Q37.4273 930.368 32.4621 926.039 Q27.4968 921.679 27.4968 914.008 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M49.9359 888.545 L28.3562 888.545 L28.3562 882.689 L49.7131 882.689 Q54.7739 882.689 57.3202 880.715 Q59.8346 878.742 59.8346 874.795 Q59.8346 870.053 56.8109 867.316 Q53.7872 864.547 48.5673 864.547 L28.3562 864.547 L28.3562 858.69 L64.0042 858.69 L64.0042 864.547 L58.5296 864.547 Q61.7762 866.679 63.3676 869.512 Q64.9272 872.313 64.9272 876.037 Q64.9272 882.18 61.1078 885.362 Q57.2883 888.545 49.9359 888.545 M27.4968 873.809 L27.4968 873.809 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M33.8307 825.97 Q33.2578 826.957 33.0032 828.135 Q32.7167 829.281 32.7167 830.681 Q32.7167 835.646 35.9632 838.32 Q39.1779 840.962 45.2253 840.962 L64.0042 840.962 L64.0042 846.85 L28.3562 846.85 L28.3562 840.962 L33.8944 840.962 Q30.6479 839.116 29.0883 836.156 Q27.4968 833.195 27.4968 828.962 Q27.4968 828.358 27.5923 827.625 Q27.656 826.893 27.8151 826.002 L33.8307 825.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M14.479 819.827 L14.479 813.971 L64.0042 813.971 L64.0042 819.827 L14.479 819.827 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M67.3143 786.885 Q73.68 789.368 75.6216 791.723 Q77.5631 794.078 77.5631 798.025 L77.5631 802.704 L72.6615 802.704 L72.6615 799.266 Q72.6615 796.847 71.5157 795.51 Q70.3699 794.174 66.1048 792.55 L63.4312 791.5 L28.3562 805.918 L28.3562 799.712 L56.238 788.572 L28.3562 777.432 L28.3562 771.225 L67.3143 786.885 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M28.3562 745.826 L28.3562 739.97 L56.1743 732.649 L28.3562 725.36 L28.3562 718.454 L56.1743 711.133 L28.3562 703.844 L28.3562 697.988 L64.0042 707.314 L64.0042 714.22 L34.7856 721.891 L64.0042 729.594 L64.0042 736.5 L28.3562 745.826 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M46.0847 672.907 Q46.0847 680.005 47.7079 682.742 Q49.3312 685.479 53.2461 685.479 Q56.3653 685.479 58.2114 683.442 Q60.0256 681.373 60.0256 677.84 Q60.0256 672.971 56.5881 670.042 Q53.1188 667.082 47.3897 667.082 L46.0847 667.082 L46.0847 672.907 M43.6657 661.226 L64.0042 661.226 L64.0042 667.082 L58.5933 667.082 Q61.8398 669.088 63.3994 672.079 Q64.9272 675.071 64.9272 679.4 Q64.9272 684.874 61.8716 688.121 Q58.7843 691.336 53.6281 691.336 Q47.6125 691.336 44.5569 687.325 Q41.5014 683.283 41.5014 675.294 L41.5014 667.082 L40.9285 667.082 Q36.8862 667.082 34.6901 669.756 Q32.4621 672.398 32.4621 677.204 Q32.4621 680.259 33.1941 683.156 Q33.9262 686.052 35.3903 688.726 L29.9795 688.726 Q28.7381 685.511 28.1334 682.487 Q27.4968 679.464 27.4968 676.599 Q27.4968 668.865 31.5072 665.045 Q35.5176 661.226 43.6657 661.226 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M45.7664 625.705 Q39.4007 625.705 35.8996 628.347 Q32.3984 630.957 32.3984 635.699 Q32.3984 640.41 35.8996 643.052 Q39.4007 645.662 45.7664 645.662 Q52.1003 645.662 55.6014 643.052 Q59.1026 640.41 59.1026 635.699 Q59.1026 630.957 55.6014 628.347 Q52.1003 625.705 45.7664 625.705 M59.58 619.849 Q68.683 619.849 73.1071 623.891 Q77.5631 627.933 77.5631 636.272 Q77.5631 639.36 77.0857 642.097 Q76.6401 644.834 75.6852 647.412 L69.9879 647.412 Q71.3884 644.834 72.0568 642.32 Q72.7252 639.805 72.7252 637.195 Q72.7252 631.434 69.7015 628.57 Q66.7096 625.705 60.6303 625.705 L57.7339 625.705 Q60.885 627.519 62.4446 630.352 Q64.0042 633.185 64.0042 637.132 Q64.0042 643.688 59.0071 647.699 Q54.01 651.709 45.7664 651.709 Q37.491 651.709 32.4939 647.699 Q27.4968 643.688 27.4968 637.132 Q27.4968 633.185 29.0564 630.352 Q30.616 627.519 33.7671 625.705 L28.3562 625.705 L28.3562 619.849 L59.58 619.849 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M44.7161 577.294 L47.5806 577.294 L47.5806 604.221 Q53.6281 603.839 56.8109 600.593 Q59.9619 597.314 59.9619 591.49 Q59.9619 588.116 59.1344 584.965 Q58.3069 581.782 56.6518 578.663 L62.1899 578.663 Q63.5267 581.814 64.227 585.124 Q64.9272 588.434 64.9272 591.84 Q64.9272 600.37 59.9619 605.367 Q54.9967 610.332 46.5303 610.332 Q37.7774 610.332 32.6531 605.621 Q27.4968 600.879 27.4968 592.858 Q27.4968 585.665 32.1438 581.495 Q36.7589 577.294 44.7161 577.294 M42.9973 583.15 Q38.1912 583.214 35.3266 585.856 Q32.4621 588.466 32.4621 592.795 Q32.4621 597.696 35.2312 600.656 Q38.0002 603.584 43.0292 604.03 L42.9973 583.15 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M229.361 12.096 L267.601 12.096 L267.601 18.9825 L237.544 18.9825 L237.544 36.8875 L266.345 36.8875 L266.345 43.7741 L237.544 43.7741 L237.544 65.6895 L268.33 65.6895 L268.33 72.576 L229.361 72.576 L229.361 12.096 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M316.779 35.9153 Q319.574 30.8922 323.463 28.5022 Q327.352 26.1121 332.618 26.1121 Q339.707 26.1121 343.556 31.0947 Q347.404 36.0368 347.404 45.1919 L347.404 72.576 L339.91 72.576 L339.91 45.4349 Q339.91 38.913 337.601 35.7533 Q335.292 32.5936 330.552 32.5936 Q324.76 32.5936 321.397 36.4419 Q318.035 40.2903 318.035 46.9338 L318.035 72.576 L310.541 72.576 L310.541 45.4349 Q310.541 38.8725 308.232 35.7533 Q305.923 32.5936 301.102 32.5936 Q295.39 32.5936 292.028 36.4824 Q288.666 40.3308 288.666 46.9338 L288.666 72.576 L281.172 72.576 L281.172 27.2059 L288.666 27.2059 L288.666 34.2544 Q291.218 30.082 294.783 28.0971 Q298.348 26.1121 303.249 26.1121 Q308.191 26.1121 311.635 28.6237 Q315.118 31.1352 316.779 35.9153 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M369.482 65.7705 L369.482 89.8329 L361.987 89.8329 L361.987 27.2059 L369.482 27.2059 L369.482 34.0924 Q371.831 30.0415 375.396 28.0971 Q379.001 26.1121 383.984 26.1121 Q392.248 26.1121 397.392 32.6746 Q402.577 39.2371 402.577 49.9314 Q402.577 60.6258 397.392 67.1883 Q392.248 73.7508 383.984 73.7508 Q379.001 73.7508 375.396 71.8063 Q371.831 69.8214 369.482 65.7705 M394.84 49.9314 Q394.84 41.7081 391.437 37.0496 Q388.075 32.3505 382.161 32.3505 Q376.247 32.3505 372.844 37.0496 Q369.482 41.7081 369.482 49.9314 Q369.482 58.1548 372.844 62.8538 Q376.247 67.5124 382.161 67.5124 Q388.075 67.5124 391.437 62.8538 Q394.84 58.1548 394.84 49.9314 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M414.933 27.2059 L422.386 27.2059 L422.386 72.576 L414.933 72.576 L414.933 27.2059 M414.933 9.54393 L422.386 9.54393 L422.386 18.9825 L414.933 18.9825 L414.933 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M464.273 34.1734 Q463.017 33.4443 461.518 33.1202 Q460.06 32.7556 458.277 32.7556 Q451.958 32.7556 448.555 36.8875 Q445.193 40.9789 445.193 48.6757 L445.193 72.576 L437.699 72.576 L437.699 27.2059 L445.193 27.2059 L445.193 34.2544 Q447.542 30.1225 451.31 28.1376 Q455.077 26.1121 460.465 26.1121 Q461.234 26.1121 462.166 26.2337 Q463.098 26.3147 464.232 26.5172 L464.273 34.1734 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M472.091 27.2059 L479.545 27.2059 L479.545 72.576 L472.091 72.576 L472.091 27.2059 M472.091 9.54393 L479.545 9.54393 L479.545 18.9825 L472.091 18.9825 L472.091 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M527.791 28.9478 L527.791 35.9153 Q524.631 34.1734 521.431 33.3227 Q518.271 32.4315 515.03 32.4315 Q507.779 32.4315 503.769 37.0496 Q499.759 41.6271 499.759 49.9314 Q499.759 58.2358 503.769 62.8538 Q507.779 67.4314 515.03 67.4314 Q518.271 67.4314 521.431 66.5807 Q524.631 65.6895 527.791 63.9476 L527.791 70.8341 Q524.672 72.2924 521.309 73.0216 Q517.988 73.7508 514.22 73.7508 Q503.972 73.7508 497.936 67.3098 Q491.9 60.8689 491.9 49.9314 Q491.9 38.832 497.976 32.472 Q504.093 26.1121 514.706 26.1121 Q518.15 26.1121 521.431 26.8413 Q524.712 27.5299 527.791 28.9478 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M561.373 49.7694 Q552.339 49.7694 548.856 51.8354 Q545.372 53.9013 545.372 58.8839 Q545.372 62.8538 547.964 65.2034 Q550.597 67.5124 555.094 67.5124 Q561.292 67.5124 565.019 63.1374 Q568.786 58.7219 568.786 51.4303 L568.786 49.7694 L561.373 49.7694 M576.24 46.6907 L576.24 72.576 L568.786 72.576 L568.786 65.6895 Q566.234 69.8214 562.426 71.8063 Q558.618 73.7508 553.109 73.7508 Q546.141 73.7508 542.01 69.8619 Q537.918 65.9325 537.918 59.3701 Q537.918 51.7138 543.022 47.825 Q548.167 43.9361 558.335 43.9361 L568.786 43.9361 L568.786 43.2069 Q568.786 38.0623 565.383 35.2672 Q562.021 32.4315 555.904 32.4315 Q552.015 32.4315 548.329 33.3632 Q544.643 34.295 541.24 36.1584 L541.24 29.2718 Q545.331 27.692 549.18 26.9223 Q553.028 26.1121 556.674 26.1121 Q566.517 26.1121 571.379 31.2163 Q576.24 36.3204 576.24 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M591.593 9.54393 L599.046 9.54393 L599.046 72.576 L591.593 72.576 L591.593 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M636.679 27.2059 L644.133 27.2059 L653.45 62.6108 L662.726 27.2059 L671.517 27.2059 L680.834 62.6108 L690.111 27.2059 L697.564 27.2059 L685.695 72.576 L676.905 72.576 L667.142 35.3887 L657.339 72.576 L648.548 72.576 L636.679 27.2059 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M729.485 49.7694 Q720.452 49.7694 716.968 51.8354 Q713.484 53.9013 713.484 58.8839 Q713.484 62.8538 716.077 65.2034 Q718.71 67.5124 723.206 67.5124 Q729.404 67.5124 733.131 63.1374 Q736.899 58.7219 736.899 51.4303 L736.899 49.7694 L729.485 49.7694 M744.352 46.6907 L744.352 72.576 L736.899 72.576 L736.899 65.6895 Q734.346 69.8214 730.539 71.8063 Q726.731 73.7508 721.222 73.7508 Q714.254 73.7508 710.122 69.8619 Q706.031 65.9325 706.031 59.3701 Q706.031 51.7138 711.135 47.825 Q716.279 43.9361 726.447 43.9361 L736.899 43.9361 L736.899 43.2069 Q736.899 38.0623 733.496 35.2672 Q730.134 32.4315 724.017 32.4315 Q720.128 32.4315 716.441 33.3632 Q712.755 34.295 709.352 36.1584 L709.352 29.2718 Q713.444 27.692 717.292 26.9223 Q721.141 26.1121 724.786 26.1121 Q734.63 26.1121 739.491 31.2163 Q744.352 36.3204 744.352 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M789.56 49.3643 Q789.56 41.2625 786.198 36.8065 Q782.876 32.3505 776.84 32.3505 Q770.845 32.3505 767.483 36.8065 Q764.161 41.2625 764.161 49.3643 Q764.161 57.4256 767.483 61.8816 Q770.845 66.3376 776.84 66.3376 Q782.876 66.3376 786.198 61.8816 Q789.56 57.4256 789.56 49.3643 M797.014 66.9452 Q797.014 78.5308 791.869 84.1616 Q786.725 89.8329 776.111 89.8329 Q772.182 89.8329 768.698 89.2252 Q765.214 88.6581 761.933 87.4428 L761.933 80.1917 Q765.214 81.9741 768.415 82.8248 Q771.615 83.6755 774.937 83.6755 Q782.269 83.6755 785.914 79.8271 Q789.56 76.0193 789.56 68.282 L789.56 64.5957 Q787.251 68.6061 783.646 70.5911 Q780.041 72.576 775.018 72.576 Q766.673 72.576 761.569 66.2161 Q756.464 59.8562 756.464 49.3643 Q756.464 38.832 761.569 32.472 Q766.673 26.1121 775.018 26.1121 Q780.041 26.1121 783.646 28.0971 Q787.251 30.082 789.56 34.0924 L789.56 27.2059 L797.014 27.2059 L797.014 66.9452 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M851.175 48.0275 L851.175 51.6733 L816.904 51.6733 Q817.39 59.3701 821.522 63.421 Q825.694 67.4314 833.107 67.4314 Q837.401 67.4314 841.412 66.3781 Q845.463 65.3249 849.433 63.2184 L849.433 70.267 Q845.422 71.9684 841.209 72.8596 Q836.996 73.7508 832.662 73.7508 Q821.805 73.7508 815.446 67.4314 Q809.126 61.1119 809.126 50.3365 Q809.126 39.1965 815.121 32.6746 Q821.157 26.1121 831.366 26.1121 Q840.521 26.1121 845.827 32.0264 Q851.175 37.9003 851.175 48.0275 M843.721 45.84 Q843.64 39.7232 840.278 36.0774 Q836.956 32.4315 831.447 32.4315 Q825.208 32.4315 821.441 35.9558 Q817.714 39.4801 817.147 45.8805 L843.721 45.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M919.635 34.0924 L919.635 9.54393 L927.088 9.54393 L927.088 72.576 L919.635 72.576 L919.635 65.7705 Q917.285 69.8214 913.68 71.8063 Q910.115 73.7508 905.092 73.7508 Q896.869 73.7508 891.684 67.1883 Q886.539 60.6258 886.539 49.9314 Q886.539 39.2371 891.684 32.6746 Q896.869 26.1121 905.092 26.1121 Q910.115 26.1121 913.68 28.0971 Q917.285 30.0415 919.635 34.0924 M894.236 49.9314 Q894.236 58.1548 897.598 62.8538 Q901.001 67.5124 906.915 67.5124 Q912.829 67.5124 916.232 62.8538 Q919.635 58.1548 919.635 49.9314 Q919.635 41.7081 916.232 37.0496 Q912.829 32.3505 906.915 32.3505 Q901.001 32.3505 897.598 37.0496 Q894.236 41.7081 894.236 49.9314 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M942.441 27.2059 L949.895 27.2059 L949.895 72.576 L942.441 72.576 L942.441 27.2059 M942.441 9.54393 L949.895 9.54393 L949.895 18.9825 L942.441 18.9825 L942.441 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M994.415 28.5427 L994.415 35.5912 Q991.255 33.9709 987.852 33.1607 Q984.449 32.3505 980.803 32.3505 Q975.254 32.3505 972.459 34.0519 Q969.704 35.7533 969.704 39.156 Q969.704 41.7486 971.689 43.2475 Q973.674 44.7058 979.669 46.0426 L982.221 46.6097 Q990.161 48.3111 993.483 51.4303 Q996.845 54.509 996.845 60.0587 Q996.845 66.3781 991.822 70.0644 Q986.839 73.7508 978.089 73.7508 Q974.444 73.7508 970.474 73.0216 Q966.544 72.3329 962.169 70.9151 L962.169 63.2184 Q966.301 65.3654 970.312 66.4591 Q974.322 67.5124 978.251 67.5124 Q983.518 67.5124 986.353 65.73 Q989.189 63.9071 989.189 60.6258 Q989.189 57.5877 987.123 55.9673 Q985.097 54.3469 978.17 52.8481 L975.578 52.2405 Q968.651 50.7821 965.572 47.7845 Q962.493 44.7463 962.493 39.4801 Q962.493 33.0797 967.03 29.5959 Q971.567 26.1121 979.912 26.1121 Q984.044 26.1121 987.69 26.7198 Q991.336 27.3274 994.415 28.5427 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1016.09 14.324 L1016.09 27.2059 L1031.44 27.2059 L1031.44 32.9987 L1016.09 32.9987 L1016.09 57.6282 Q1016.09 63.1779 1017.59 64.7578 Q1019.13 66.3376 1023.78 66.3376 L1031.44 66.3376 L1031.44 72.576 L1023.78 72.576 Q1015.16 72.576 1011.87 69.3758 Q1008.59 66.1351 1008.59 57.6282 L1008.59 32.9987 L1003.12 32.9987 L1003.12 27.2059 L1008.59 27.2059 L1008.59 14.324 L1016.09 14.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1067.53 34.1734 Q1066.28 33.4443 1064.78 33.1202 Q1063.32 32.7556 1061.54 32.7556 Q1055.22 32.7556 1051.82 36.8875 Q1048.45 40.9789 1048.45 48.6757 L1048.45 72.576 L1040.96 72.576 L1040.96 27.2059 L1048.45 27.2059 L1048.45 34.2544 Q1050.8 30.1225 1054.57 28.1376 Q1058.34 26.1121 1063.73 26.1121 Q1064.5 26.1121 1065.43 26.2337 Q1066.36 26.3147 1067.49 26.5172 L1067.53 34.1734 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1075.35 27.2059 L1082.81 27.2059 L1082.81 72.576 L1075.35 72.576 L1075.35 27.2059 M1075.35 9.54393 L1082.81 9.54393 L1082.81 18.9825 L1075.35 18.9825 L1075.35 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1130.97 49.9314 Q1130.97 41.7081 1127.57 37.0496 Q1124.21 32.3505 1118.29 32.3505 Q1112.38 32.3505 1108.97 37.0496 Q1105.61 41.7081 1105.61 49.9314 Q1105.61 58.1548 1108.97 62.8538 Q1112.38 67.5124 1118.29 67.5124 Q1124.21 67.5124 1127.57 62.8538 Q1130.97 58.1548 1130.97 49.9314 M1105.61 34.0924 Q1107.96 30.0415 1111.53 28.0971 Q1115.13 26.1121 1120.11 26.1121 Q1128.38 26.1121 1133.52 32.6746 Q1138.71 39.2371 1138.71 49.9314 Q1138.71 60.6258 1133.52 67.1883 Q1128.38 73.7508 1120.11 73.7508 Q1115.13 73.7508 1111.53 71.8063 Q1107.96 69.8214 1105.61 65.7705 L1105.61 72.576 L1098.12 72.576 L1098.12 9.54393 L1105.61 9.54393 L1105.61 34.0924 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1150.29 54.671 L1150.29 27.2059 L1157.75 27.2059 L1157.75 54.3874 Q1157.75 60.8284 1160.26 64.0691 Q1162.77 67.2693 1167.79 67.2693 Q1173.83 67.2693 1177.31 63.421 Q1180.84 59.5726 1180.84 52.9291 L1180.84 27.2059 L1188.29 27.2059 L1188.29 72.576 L1180.84 72.576 L1180.84 65.6084 Q1178.12 69.7404 1174.52 71.7658 Q1170.95 73.7508 1166.21 73.7508 Q1158.4 73.7508 1154.34 68.8897 Q1150.29 64.0286 1150.29 54.671 M1169.05 26.1121 L1169.05 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1211.02 14.324 L1211.02 27.2059 L1226.37 27.2059 L1226.37 32.9987 L1211.02 32.9987 L1211.02 57.6282 Q1211.02 63.1779 1212.52 64.7578 Q1214.05 66.3376 1218.71 66.3376 L1226.37 66.3376 L1226.37 72.576 L1218.71 72.576 Q1210.08 72.576 1206.8 69.3758 Q1203.52 66.1351 1203.52 57.6282 L1203.52 32.9987 L1198.05 32.9987 L1198.05 27.2059 L1203.52 27.2059 L1203.52 14.324 L1211.02 14.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1236.17 27.2059 L1243.63 27.2059 L1243.63 72.576 L1236.17 72.576 L1236.17 27.2059 M1236.17 9.54393 L1243.63 9.54393 L1243.63 18.9825 L1236.17 18.9825 L1236.17 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1276.8 32.4315 Q1270.81 32.4315 1267.32 37.1306 Q1263.84 41.7891 1263.84 49.9314 Q1263.84 58.0738 1267.28 62.7728 Q1270.77 67.4314 1276.8 67.4314 Q1282.76 67.4314 1286.24 62.7323 Q1289.73 58.0333 1289.73 49.9314 Q1289.73 41.8701 1286.24 37.1711 Q1282.76 32.4315 1276.8 32.4315 M1276.8 26.1121 Q1286.53 26.1121 1292.07 32.4315 Q1297.62 38.7509 1297.62 49.9314 Q1297.62 61.0714 1292.07 67.4314 Q1286.53 73.7508 1276.8 73.7508 Q1267.04 73.7508 1261.49 67.4314 Q1255.98 61.0714 1255.98 49.9314 Q1255.98 38.7509 1261.49 32.4315 Q1267.04 26.1121 1276.8 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1347.69 45.1919 L1347.69 72.576 L1340.24 72.576 L1340.24 45.4349 Q1340.24 38.994 1337.73 35.7938 Q1335.22 32.5936 1330.19 32.5936 Q1324.16 32.5936 1320.67 36.4419 Q1317.19 40.2903 1317.19 46.9338 L1317.19 72.576 L1309.7 72.576 L1309.7 27.2059 L1317.19 27.2059 L1317.19 34.2544 Q1319.86 30.163 1323.47 28.1376 Q1327.12 26.1121 1331.85 26.1121 Q1339.67 26.1121 1343.68 30.9732 Q1347.69 35.7938 1347.69 45.1919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1411.9 9.54393 L1411.9 15.7418 L1404.77 15.7418 Q1400.76 15.7418 1399.18 17.3622 Q1397.64 18.9825 1397.64 23.1955 L1397.64 27.2059 L1409.92 27.2059 L1409.92 32.9987 L1397.64 32.9987 L1397.64 72.576 L1390.15 72.576 L1390.15 32.9987 L1383.02 32.9987 L1383.02 27.2059 L1390.15 27.2059 L1390.15 24.0462 Q1390.15 16.471 1393.67 13.0277 Q1397.2 9.54393 1404.85 9.54393 L1411.9 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1444.43 34.1734 Q1443.17 33.4443 1441.67 33.1202 Q1440.22 32.7556 1438.43 32.7556 Q1432.11 32.7556 1428.71 36.8875 Q1425.35 40.9789 1425.35 48.6757 L1425.35 72.576 L1417.86 72.576 L1417.86 27.2059 L1425.35 27.2059 L1425.35 34.2544 Q1427.7 30.1225 1431.47 28.1376 Q1435.23 26.1121 1440.62 26.1121 Q1441.39 26.1121 1442.32 26.2337 Q1443.25 26.3147 1444.39 26.5172 L1444.43 34.1734 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1468.01 32.4315 Q1462.01 32.4315 1458.53 37.1306 Q1455.04 41.7891 1455.04 49.9314 Q1455.04 58.0738 1458.49 62.7728 Q1461.97 67.4314 1468.01 67.4314 Q1473.96 67.4314 1477.44 62.7323 Q1480.93 58.0333 1480.93 49.9314 Q1480.93 41.8701 1477.44 37.1711 Q1473.96 32.4315 1468.01 32.4315 M1468.01 26.1121 Q1477.73 26.1121 1483.28 32.4315 Q1488.83 38.7509 1488.83 49.9314 Q1488.83 61.0714 1483.28 67.4314 Q1477.73 73.7508 1468.01 73.7508 Q1458.24 73.7508 1452.69 67.4314 Q1447.18 61.0714 1447.18 49.9314 Q1447.18 38.7509 1452.69 32.4315 Q1458.24 26.1121 1468.01 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1536.51 35.9153 Q1539.3 30.8922 1543.19 28.5022 Q1547.08 26.1121 1552.35 26.1121 Q1559.43 26.1121 1563.28 31.0947 Q1567.13 36.0368 1567.13 45.1919 L1567.13 72.576 L1559.64 72.576 L1559.64 45.4349 Q1559.64 38.913 1557.33 35.7533 Q1555.02 32.5936 1550.28 32.5936 Q1544.49 32.5936 1541.12 36.4419 Q1537.76 40.2903 1537.76 46.9338 L1537.76 72.576 L1530.27 72.576 L1530.27 45.4349 Q1530.27 38.8725 1527.96 35.7533 Q1525.65 32.5936 1520.83 32.5936 Q1515.12 32.5936 1511.76 36.4824 Q1508.39 40.3308 1508.39 46.9338 L1508.39 72.576 L1500.9 72.576 L1500.9 27.2059 L1508.39 27.2059 L1508.39 34.2544 Q1510.95 30.082 1514.51 28.0971 Q1518.07 26.1121 1522.98 26.1121 Q1527.92 26.1121 1531.36 28.6237 Q1534.85 31.1352 1536.51 35.9153 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1615.74 14.324 L1615.74 27.2059 L1631.1 27.2059 L1631.1 32.9987 L1615.74 32.9987 L1615.74 57.6282 Q1615.74 63.1779 1617.24 64.7578 Q1618.78 66.3376 1623.44 66.3376 L1631.1 66.3376 L1631.1 72.576 L1623.44 72.576 Q1614.81 72.576 1611.53 69.3758 Q1608.25 66.1351 1608.25 57.6282 L1608.25 32.9987 L1602.78 32.9987 L1602.78 27.2059 L1608.25 27.2059 L1608.25 14.324 L1615.74 14.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1678.61 45.1919 L1678.61 72.576 L1671.16 72.576 L1671.16 45.4349 Q1671.16 38.994 1668.65 35.7938 Q1666.14 32.5936 1661.11 32.5936 Q1655.08 32.5936 1651.59 36.4419 Q1648.11 40.2903 1648.11 46.9338 L1648.11 72.576 L1640.61 72.576 L1640.61 9.54393 L1648.11 9.54393 L1648.11 34.2544 Q1650.78 30.163 1654.39 28.1376 Q1658.03 26.1121 1662.77 26.1121 Q1670.59 26.1121 1674.6 30.9732 Q1678.61 35.7938 1678.61 45.1919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1732.29 48.0275 L1732.29 51.6733 L1698.02 51.6733 Q1698.5 59.3701 1702.63 63.421 Q1706.81 67.4314 1714.22 67.4314 Q1718.51 67.4314 1722.52 66.3781 Q1726.57 65.3249 1730.54 63.2184 L1730.54 70.267 Q1726.53 71.9684 1722.32 72.8596 Q1718.11 73.7508 1713.77 73.7508 Q1702.92 73.7508 1696.56 67.4314 Q1690.24 61.1119 1690.24 50.3365 Q1690.24 39.1965 1696.23 32.6746 Q1702.27 26.1121 1712.48 26.1121 Q1721.63 26.1121 1726.94 32.0264 Q1732.29 37.9003 1732.29 48.0275 M1724.83 45.84 Q1724.75 39.7232 1721.39 36.0774 Q1718.07 32.4315 1712.56 32.4315 Q1706.32 32.4315 1702.55 35.9558 Q1698.83 39.4801 1698.26 45.8805 L1724.83 45.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1770.28 12.096 L1778.51 12.096 L1778.51 48.8377 Q1778.51 58.5599 1782.03 62.8538 Q1785.56 67.1073 1793.46 67.1073 Q1801.31 67.1073 1804.84 62.8538 Q1808.36 58.5599 1808.36 48.8377 L1808.36 12.096 L1816.59 12.096 L1816.59 49.8504 Q1816.59 61.6791 1810.71 67.7149 Q1804.88 73.7508 1793.46 73.7508 Q1781.99 73.7508 1776.12 67.7149 Q1770.28 61.6791 1770.28 49.8504 L1770.28 12.096 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1868.19 14.0809 L1868.19 22.0612 Q1863.54 19.8332 1859.4 18.7395 Q1855.27 17.6457 1851.42 17.6457 Q1844.74 17.6457 1841.09 20.2383 Q1837.49 22.8309 1837.49 27.611 Q1837.49 31.6214 1839.88 33.6873 Q1842.31 35.7128 1849.03 36.9686 L1853.98 37.9813 Q1863.13 39.7232 1867.47 44.1387 Q1871.84 48.5136 1871.84 55.8863 Q1871.84 64.6767 1865.93 69.2137 Q1860.05 73.7508 1848.67 73.7508 Q1844.38 73.7508 1839.51 72.7785 Q1834.69 71.8063 1829.51 69.9024 L1829.51 61.4765 Q1834.49 64.2716 1839.27 65.6895 Q1844.05 67.1073 1848.67 67.1073 Q1855.68 67.1073 1859.49 64.3527 Q1863.29 61.598 1863.29 56.4939 Q1863.29 52.0379 1860.54 49.5264 Q1857.82 47.0148 1851.59 45.759 L1846.6 44.7868 Q1837.45 42.9639 1833.36 39.075 Q1829.27 35.1862 1829.27 28.2591 Q1829.27 20.2383 1834.9 15.6203 Q1840.57 11.0023 1850.49 11.0023 Q1854.75 11.0023 1859.16 11.7719 Q1863.58 12.5416 1868.19 14.0809 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1939.57 28.5427 L1939.57 35.5912 Q1936.41 33.9709 1933.01 33.1607 Q1929.61 32.3505 1925.96 32.3505 Q1920.41 32.3505 1917.62 34.0519 Q1914.86 35.7533 1914.86 39.156 Q1914.86 41.7486 1916.85 43.2475 Q1918.83 44.7058 1924.83 46.0426 L1927.38 46.6097 Q1935.32 48.3111 1938.64 51.4303 Q1942 54.509 1942 60.0587 Q1942 66.3781 1936.98 70.0644 Q1932 73.7508 1923.25 73.7508 Q1919.6 73.7508 1915.63 73.0216 Q1911.7 72.3329 1907.33 70.9151 L1907.33 63.2184 Q1911.46 65.3654 1915.47 66.4591 Q1919.48 67.5124 1923.41 67.5124 Q1928.67 67.5124 1931.51 65.73 Q1934.35 63.9071 1934.35 60.6258 Q1934.35 57.5877 1932.28 55.9673 Q1930.25 54.3469 1923.33 52.8481 L1920.73 52.2405 Q1913.81 50.7821 1910.73 47.7845 Q1907.65 44.7463 1907.65 39.4801 Q1907.65 33.0797 1912.19 29.5959 Q1916.72 26.1121 1925.07 26.1121 Q1929.2 26.1121 1932.85 26.7198 Q1936.49 27.3274 1939.57 28.5427 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M1953.1 54.671 L1953.1 27.2059 L1960.56 27.2059 L1960.56 54.3874 Q1960.56 60.8284 1963.07 64.0691 Q1965.58 67.2693 1970.6 67.2693 Q1976.64 67.2693 1980.12 63.421 Q1983.65 59.5726 1983.65 52.9291 L1983.65 27.2059 L1991.1 27.2059 L1991.1 72.576 L1983.65 72.576 L1983.65 65.6084 Q1980.93 69.7404 1977.33 71.7658 Q1973.76 73.7508 1969.02 73.7508 Q1961.2 73.7508 1957.15 68.8897 Q1953.1 64.0286 1953.1 54.671 M1971.86 26.1121 L1971.86 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M2032.74 34.1734 Q2031.49 33.4443 2029.99 33.1202 Q2028.53 32.7556 2026.75 32.7556 Q2020.43 32.7556 2017.02 36.8875 Q2013.66 40.9789 2013.66 48.6757 L2013.66 72.576 L2006.17 72.576 L2006.17 27.2059 L2013.66 27.2059 L2013.66 34.2544 Q2016.01 30.1225 2019.78 28.1376 Q2023.55 26.1121 2028.93 26.1121 Q2029.7 26.1121 2030.64 26.2337 Q2031.57 26.3147 2032.7 26.5172 L2032.74 34.1734 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M2035.21 27.2059 L2043.11 27.2059 L2057.29 65.2844 L2071.47 27.2059 L2079.37 27.2059 L2062.35 72.576 L2052.23 72.576 L2035.21 27.2059 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M2128.47 48.0275 L2128.47 51.6733 L2094.19 51.6733 Q2094.68 59.3701 2098.81 63.421 Q2102.98 67.4314 2110.4 67.4314 Q2114.69 67.4314 2118.7 66.3781 Q2122.75 65.3249 2126.72 63.2184 L2126.72 70.267 Q2122.71 71.9684 2118.5 72.8596 Q2114.29 73.7508 2109.95 73.7508 Q2099.1 73.7508 2092.74 67.4314 Q2086.42 61.1119 2086.42 50.3365 Q2086.42 39.1965 2092.41 32.6746 Q2098.45 26.1121 2108.66 26.1121 Q2117.81 26.1121 2123.12 32.0264 Q2128.47 37.9003 2128.47 48.0275 M2121.01 45.84 Q2120.93 39.7232 2117.57 36.0774 Q2114.25 32.4315 2108.74 32.4315 Q2102.5 32.4315 2098.73 35.9558 Q2095 39.4801 2094.44 45.8805 L2121.01 45.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M2159.58 76.7889 Q2156.42 84.8907 2153.42 87.3618 Q2150.42 89.8329 2145.4 89.8329 L2139.44 89.8329 L2139.44 83.5945 L2143.82 83.5945 Q2146.9 83.5945 2148.6 82.1361 Q2150.3 80.6778 2152.37 75.2496 L2153.7 71.8468 L2135.35 27.2059 L2143.25 27.2059 L2157.43 62.6918 L2171.61 27.2059 L2179.51 27.2059 L2159.58 76.7889 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M2246.02 34.0924 L2246.02 9.54393 L2253.48 9.54393 L2253.48 72.576 L2246.02 72.576 L2246.02 65.7705 Q2243.67 69.8214 2240.07 71.8063 Q2236.5 73.7508 2231.48 73.7508 Q2223.26 73.7508 2218.07 67.1883 Q2212.93 60.6258 2212.93 49.9314 Q2212.93 39.2371 2218.07 32.6746 Q2223.26 26.1121 2231.48 26.1121 Q2236.5 26.1121 2240.07 28.0971 Q2243.67 30.0415 2246.02 34.0924 M2220.62 49.9314 Q2220.62 58.1548 2223.99 62.8538 Q2227.39 67.5124 2233.3 67.5124 Q2239.22 67.5124 2242.62 62.8538 Q2246.02 58.1548 2246.02 49.9314 Q2246.02 41.7081 2242.62 37.0496 Q2239.22 32.3505 2233.3 32.3505 Q2227.39 32.3505 2223.99 37.0496 Q2220.62 41.7081 2220.62 49.9314 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M2289.45 49.7694 Q2280.41 49.7694 2276.93 51.8354 Q2273.45 53.9013 2273.45 58.8839 Q2273.45 62.8538 2276.04 65.2034 Q2278.67 67.5124 2283.17 67.5124 Q2289.37 67.5124 2293.09 63.1374 Q2296.86 58.7219 2296.86 51.4303 L2296.86 49.7694 L2289.45 49.7694 M2304.31 46.6907 L2304.31 72.576 L2296.86 72.576 L2296.86 65.6895 Q2294.31 69.8214 2290.5 71.8063 Q2286.69 73.7508 2281.18 73.7508 Q2274.22 73.7508 2270.08 69.8619 Q2265.99 65.9325 2265.99 59.3701 Q2265.99 51.7138 2271.1 47.825 Q2276.24 43.9361 2286.41 43.9361 L2296.86 43.9361 L2296.86 43.2069 Q2296.86 38.0623 2293.46 35.2672 Q2290.1 32.4315 2283.98 32.4315 Q2280.09 32.4315 2276.4 33.3632 Q2272.72 34.295 2269.32 36.1584 L2269.32 29.2718 Q2273.41 27.692 2277.25 26.9223 Q2281.1 26.1121 2284.75 26.1121 Q2294.59 26.1121 2299.45 31.2163 Q2304.31 36.3204 2304.31 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M2327.04 14.324 L2327.04 27.2059 L2342.39 27.2059 L2342.39 32.9987 L2327.04 32.9987 L2327.04 57.6282 Q2327.04 63.1779 2328.54 64.7578 Q2330.08 66.3376 2334.74 66.3376 L2342.39 66.3376 L2342.39 72.576 L2334.74 72.576 Q2326.11 72.576 2322.83 69.3758 Q2319.55 66.1351 2319.55 57.6282 L2319.55 32.9987 L2314.08 32.9987 L2314.08 27.2059 L2319.55 27.2059 L2319.55 14.324 L2327.04 14.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip330)\" d=\"M2372.82 49.7694 Q2363.78 49.7694 2360.3 51.8354 Q2356.81 53.9013 2356.81 58.8839 Q2356.81 62.8538 2359.41 65.2034 Q2362.04 67.5124 2366.54 67.5124 Q2372.73 67.5124 2376.46 63.1374 Q2380.23 58.7219 2380.23 51.4303 L2380.23 49.7694 L2372.82 49.7694 M2387.68 46.6907 L2387.68 72.576 L2380.23 72.576 L2380.23 65.6895 Q2377.68 69.8214 2373.87 71.8063 Q2370.06 73.7508 2364.55 73.7508 Q2357.58 73.7508 2353.45 69.8619 Q2349.36 65.9325 2349.36 59.3701 Q2349.36 51.7138 2354.47 47.825 Q2359.61 43.9361 2369.78 43.9361 L2380.23 43.9361 L2380.23 43.2069 Q2380.23 38.0623 2376.83 35.2672 Q2373.46 32.4315 2367.35 32.4315 Q2363.46 32.4315 2359.77 33.3632 Q2356.09 34.295 2352.68 36.1584 L2352.68 29.2718 Q2356.77 27.692 2360.62 26.9223 Q2364.47 26.1121 2368.12 26.1121 Q2377.96 26.1121 2382.82 31.2163 Q2387.68 36.3204 2387.68 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip332)\" d=\"\n",
       "M379.157 160.256 L379.157 1386.4 L447.999 1386.4 L447.999 160.256 L379.157 160.256 L379.157 160.256  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  379.157,160.256 379.157,1386.4 447.999,1386.4 447.999,160.256 379.157,160.256 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M447.999 567.795 L447.999 1386.4 L516.84 1386.4 L516.84 567.795 L447.999 567.795 L447.999 567.795  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  447.999,567.795 447.999,1386.4 516.84,1386.4 516.84,567.795 447.999,567.795 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M516.84 1231.31 L516.84 1386.4 L585.682 1386.4 L585.682 1231.31 L516.84 1231.31 L516.84 1231.31  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  516.84,1231.31 516.84,1386.4 585.682,1386.4 585.682,1231.31 516.84,1231.31 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M585.682 1345.86 L585.682 1386.4 L654.524 1386.4 L654.524 1345.86 L585.682 1345.86 L585.682 1345.86  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  585.682,1345.86 585.682,1386.4 654.524,1386.4 654.524,1345.86 585.682,1345.86 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M654.524 1370.53 L654.524 1386.4 L723.366 1386.4 L723.366 1370.53 L654.524 1370.53 L654.524 1370.53  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  654.524,1370.53 654.524,1386.4 723.366,1386.4 723.366,1370.53 654.524,1370.53 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M723.366 1381.55 L723.366 1386.4 L792.208 1386.4 L792.208 1381.55 L723.366 1381.55 L723.366 1381.55  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  723.366,1381.55 723.366,1386.4 792.208,1386.4 792.208,1381.55 723.366,1381.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M792.208 1384.19 L792.208 1386.4 L861.05 1386.4 L861.05 1384.19 L792.208 1384.19 L792.208 1384.19  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  792.208,1384.19 792.208,1386.4 861.05,1386.4 861.05,1384.19 792.208,1384.19 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M861.05 1385.07 L861.05 1386.4 L929.892 1386.4 L929.892 1385.07 L861.05 1385.07 L861.05 1385.07  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  861.05,1385.07 861.05,1386.4 929.892,1386.4 929.892,1385.07 861.05,1385.07 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M929.892 1386.4 L929.892 1386.4 L998.733 1386.4 L998.733 1386.4 L929.892 1386.4 L929.892 1386.4  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  929.892,1386.4 929.892,1386.4 998.733,1386.4 929.892,1386.4 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M998.733 1385.51 L998.733 1386.4 L1067.58 1386.4 L1067.58 1385.51 L998.733 1385.51 L998.733 1385.51  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  998.733,1385.51 998.733,1386.4 1067.58,1386.4 1067.58,1385.51 998.733,1385.51 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1067.58 1385.96 L1067.58 1386.4 L1136.42 1386.4 L1136.42 1385.96 L1067.58 1385.96 L1067.58 1385.96  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1067.58,1385.96 1067.58,1386.4 1136.42,1386.4 1136.42,1385.96 1067.58,1385.96 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1136.42 1386.4 L1136.42 1386.4 L1205.26 1386.4 L1205.26 1386.4 L1136.42 1386.4 L1136.42 1386.4  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1136.42,1386.4 1136.42,1386.4 1205.26,1386.4 1136.42,1386.4 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1205.26 1385.96 L1205.26 1386.4 L1274.1 1386.4 L1274.1 1385.96 L1205.26 1385.96 L1205.26 1385.96  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1205.26,1385.96 1205.26,1386.4 1274.1,1386.4 1274.1,1385.96 1205.26,1385.96 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1274.1 1385.96 L1274.1 1386.4 L1342.94 1386.4 L1342.94 1385.96 L1274.1 1385.96 L1274.1 1385.96  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1274.1,1385.96 1274.1,1386.4 1342.94,1386.4 1342.94,1385.96 1274.1,1385.96 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1342.94 1386.4 L1342.94 1386.4 L1411.78 1386.4 L1411.78 1386.4 L1342.94 1386.4 L1342.94 1386.4  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1342.94,1386.4 1342.94,1386.4 1411.78,1386.4 1342.94,1386.4 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1411.78 1385.96 L1411.78 1386.4 L1480.63 1386.4 L1480.63 1385.96 L1411.78 1385.96 L1411.78 1385.96  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1411.78,1385.96 1411.78,1386.4 1480.63,1386.4 1480.63,1385.96 1411.78,1385.96 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1480.63 1386.4 L1480.63 1386.4 L1549.47 1386.4 L1549.47 1386.4 L1480.63 1386.4 L1480.63 1386.4  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1480.63,1386.4 1480.63,1386.4 1549.47,1386.4 1480.63,1386.4 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1549.47 1386.4 L1549.47 1386.4 L1618.31 1386.4 L1618.31 1386.4 L1549.47 1386.4 L1549.47 1386.4  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1549.47,1386.4 1549.47,1386.4 1618.31,1386.4 1549.47,1386.4 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1618.31 1386.4 L1618.31 1386.4 L1687.15 1386.4 L1687.15 1386.4 L1618.31 1386.4 L1618.31 1386.4  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1618.31,1386.4 1618.31,1386.4 1687.15,1386.4 1618.31,1386.4 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1687.15 1385.96 L1687.15 1386.4 L1755.99 1386.4 L1755.99 1385.96 L1687.15 1385.96 L1687.15 1385.96  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1687.15,1385.96 1687.15,1386.4 1755.99,1386.4 1755.99,1385.96 1687.15,1385.96 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1755.99 1386.4 L1755.99 1386.4 L1824.84 1386.4 L1824.84 1386.4 L1755.99 1386.4 L1755.99 1386.4  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1755.99,1386.4 1755.99,1386.4 1824.84,1386.4 1755.99,1386.4 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1824.84 1386.4 L1824.84 1386.4 L1893.68 1386.4 L1893.68 1386.4 L1824.84 1386.4 L1824.84 1386.4  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1824.84,1386.4 1824.84,1386.4 1893.68,1386.4 1824.84,1386.4 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1893.68 1386.4 L1893.68 1386.4 L1962.52 1386.4 L1962.52 1386.4 L1893.68 1386.4 L1893.68 1386.4  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1893.68,1386.4 1893.68,1386.4 1962.52,1386.4 1893.68,1386.4 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M1962.52 1386.4 L1962.52 1386.4 L2031.36 1386.4 L2031.36 1386.4 L1962.52 1386.4 L1962.52 1386.4  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1962.52,1386.4 1962.52,1386.4 2031.36,1386.4 1962.52,1386.4 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M2031.36 1385.96 L2031.36 1386.4 L2100.2 1386.4 L2100.2 1385.96 L2031.36 1385.96 L2031.36 1385.96  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2031.36,1385.96 2031.36,1386.4 2100.2,1386.4 2100.2,1385.96 2031.36,1385.96 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M2100.2 1386.4 L2100.2 1386.4 L2169.04 1386.4 L2169.04 1386.4 L2100.2 1386.4 L2100.2 1386.4  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2100.2,1386.4 2100.2,1386.4 2169.04,1386.4 2100.2,1386.4 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip332)\" d=\"\n",
       "M2169.04 1385.51 L2169.04 1386.4 L2237.89 1386.4 L2237.89 1385.51 L2169.04 1385.51 L2169.04 1385.51  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip332)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2169.04,1385.51 2169.04,1386.4 2237.89,1386.4 2237.89,1385.51 2169.04,1385.51 \n",
       "  \"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"413.578\" cy=\"160.256\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"482.42\" cy=\"567.795\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"551.261\" cy=\"1231.31\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"620.103\" cy=\"1345.86\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"688.945\" cy=\"1370.53\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"757.787\" cy=\"1381.55\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"826.629\" cy=\"1384.19\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"895.471\" cy=\"1385.07\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"964.312\" cy=\"1386.4\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1033.15\" cy=\"1385.51\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1102\" cy=\"1385.96\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1170.84\" cy=\"1386.4\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1239.68\" cy=\"1385.96\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1308.52\" cy=\"1385.96\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1377.36\" cy=\"1386.4\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1446.21\" cy=\"1385.96\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1515.05\" cy=\"1386.4\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1583.89\" cy=\"1386.4\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1652.73\" cy=\"1386.4\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1721.57\" cy=\"1385.96\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1790.41\" cy=\"1386.4\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1859.26\" cy=\"1386.4\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1928.1\" cy=\"1386.4\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1996.94\" cy=\"1386.4\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"2065.78\" cy=\"1385.96\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"2134.62\" cy=\"1386.4\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip332)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"2203.47\" cy=\"1385.51\" r=\"2\"/>\n",
       "</svg>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = Plots.histogram( data[!, \"wage\"], \n",
    "    title = \"Empirical wage distribution from the US survey data\", \n",
    "    nbins = 35, \n",
    "    label = \"\")\n",
    "xlabel!( \"g(X)\" )\n",
    "ylabel!( \"hourly wage\" )\n",
    "display( plt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28-element Vector{Float64}:\n",
       "   0.0\n",
       "  20.0\n",
       "  40.0\n",
       "  60.0\n",
       "  80.0\n",
       " 100.0\n",
       " 120.0\n",
       " 140.0\n",
       " 160.0\n",
       " 180.0\n",
       " 200.0\n",
       " 220.0\n",
       " 240.0\n",
       "   ⋮\n",
       " 320.0\n",
       " 340.0\n",
       " 360.0\n",
       " 380.0\n",
       " 400.0\n",
       " 420.0\n",
       " 440.0\n",
       " 460.0\n",
       " 480.0\n",
       " 500.0\n",
       " 520.0\n",
       " 540.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot1 = fit(Histogram, data[!, \"wage\"], nbins=35 )\n",
    "collect( plot1.edges[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036602,
     "end_time": "2021-02-13T18:19:44.752465",
     "exception": false,
     "start_time": "2021-02-13T18:19:44.715863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Wages show a high degree of skewness. Hence, wages are transformed in almost all studies by\n",
    "the logarithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036009,
     "end_time": "2021-02-13T18:19:44.826260",
     "exception": false,
     "start_time": "2021-02-13T18:19:44.790251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036925,
     "end_time": "2021-02-13T18:19:44.899159",
     "exception": false,
     "start_time": "2021-02-13T18:19:44.862234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Due to the skewness of the data, we are considering log wages which leads to the following regression model\n",
    "\n",
    "$$log(wage) = g(Z) + \\epsilon.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036183,
     "end_time": "2021-02-13T18:19:44.971528",
     "exception": false,
     "start_time": "2021-02-13T18:19:44.935345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will estimate the two sets of prediction rules: Linear and Nonlinear Models.\n",
    "In linear models, we estimate the prediction rule of the form\n",
    "\n",
    "$$\\hat g(Z) = \\hat \\beta'X.$$\n",
    "Again, we generate $X$ in two ways:\n",
    " \n",
    "1. Basic Model:   $X$ consists of a set of raw regressors (e.g. gender, experience, education indicators, regional indicators).\n",
    "\n",
    "\n",
    "2. Flexible Model:  $X$ consists of all raw regressors from the basic model plus occupation and industry indicators, transformations (e.g., ${exp}^2$ and ${exp}^3$) and additional two-way interactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037318,
     "end_time": "2021-02-13T18:19:45.044959",
     "exception": false,
     "start_time": "2021-02-13T18:19:45.007641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To evaluate the out-of-sample performance, we split the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>1,288 rows × 20 columns (omitted printing of 11 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>wage</th><th>lwage</th><th>sex</th><th>shs</th><th>hsg</th><th>scl</th><th>clg</th><th>ad</th><th>mw</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>13.9423</td><td>2.63493</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>2</th><td>19.2308</td><td>2.95651</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>12.0192</td><td>2.48651</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>21.6</td><td>3.07269</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>11.5385</td><td>2.44569</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>17.7885</td><td>2.87855</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>7</th><td>12.0</td><td>2.48491</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>19.6703</td><td>2.97911</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>6.73077</td><td>1.90669</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>14.0224</td><td>2.64066</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>15.3846</td><td>2.73337</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>19.2308</td><td>2.95651</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>15.7212</td><td>2.75501</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>23.3339</td><td>3.14991</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>22.5962</td><td>3.11778</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>28.8462</td><td>3.36198</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>17.094</td><td>2.83873</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>18.75</td><td>2.93119</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>19</th><td>23.7316</td><td>3.16681</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>21.6346</td><td>3.07429</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>17.6715</td><td>2.87195</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>22</th><td>21.8531</td><td>3.08434</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>24.0385</td><td>3.17966</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>12.0192</td><td>2.48651</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>10.8132</td><td>2.38077</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>21.5385</td><td>3.06984</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>27</th><td>15.3846</td><td>2.73337</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>12.0192</td><td>2.48651</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>9.89011</td><td>2.29154</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>13.1868</td><td>2.57922</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& wage & lwage & sex & shs & hsg & scl & clg & ad & mw & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 13.9423 & 2.63493 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 19.2308 & 2.95651 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 12.0192 & 2.48651 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 21.6 & 3.07269 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 11.5385 & 2.44569 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 17.7885 & 2.87855 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 12.0 & 2.48491 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 19.6703 & 2.97911 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 6.73077 & 1.90669 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 14.0224 & 2.64066 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & 15.3846 & 2.73337 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & 19.2308 & 2.95651 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 15.7212 & 2.75501 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 23.3339 & 3.14991 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 22.5962 & 3.11778 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t16 & 28.8462 & 3.36198 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 17.094 & 2.83873 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & 18.75 & 2.93119 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t19 & 23.7316 & 3.16681 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 21.6346 & 3.07429 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 17.6715 & 2.87195 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & 21.8531 & 3.08434 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 24.0385 & 3.17966 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 12.0192 & 2.48651 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & 10.8132 & 2.38077 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 21.5385 & 3.06984 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & 15.3846 & 2.73337 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & 12.0192 & 2.48651 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 9.89011 & 2.29154 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 13.1868 & 2.57922 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1288×20 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m wage     \u001b[0m\u001b[1m lwage   \u001b[0m\u001b[1m sex     \u001b[0m\u001b[1m shs     \u001b[0m\u001b[1m hsg     \u001b[0m\u001b[1m scl     \u001b[0m\u001b[1m clg     \u001b[0m\u001b[1m ad    \u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float6\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │ 13.9423   2.63493      1.0      0.0      0.0      0.0      0.0      1. ⋯\n",
       "    2 │ 19.2308   2.95651      1.0      0.0      1.0      0.0      0.0      0.\n",
       "    3 │ 12.0192   2.48651      0.0      0.0      1.0      0.0      0.0      0.\n",
       "    4 │ 21.6      3.07269      0.0      0.0      1.0      0.0      0.0      0.\n",
       "    5 │ 11.5385   2.44569      1.0      0.0      0.0      1.0      0.0      0. ⋯\n",
       "    6 │ 17.7885   2.87855      1.0      0.0      0.0      0.0      0.0      1.\n",
       "    7 │ 12.0      2.48491      0.0      0.0      0.0      1.0      0.0      0.\n",
       "    8 │ 19.6703   2.97911      0.0      0.0      0.0      0.0      1.0      0.\n",
       "    9 │  6.73077  1.90669      1.0      0.0      1.0      0.0      0.0      0. ⋯\n",
       "   10 │ 14.0224   2.64066      0.0      0.0      1.0      0.0      0.0      0.\n",
       "   11 │ 15.3846   2.73337      0.0      0.0      1.0      0.0      0.0      0.\n",
       "  ⋮   │    ⋮         ⋮        ⋮        ⋮        ⋮        ⋮        ⋮        ⋮   ⋱\n",
       " 1279 │ 12.2378   2.50453      1.0      0.0      0.0      0.0      0.0      1.\n",
       " 1280 │ 15.8654   2.76414      0.0      0.0      0.0      0.0      0.0      1. ⋯\n",
       " 1281 │ 28.8462   3.36198      0.0      0.0      0.0      0.0      1.0      0.\n",
       " 1282 │ 12.0192   2.48651      0.0      0.0      1.0      0.0      0.0      0.\n",
       " 1283 │ 12.9808   2.56347      0.0      0.0      1.0      0.0      0.0      0.\n",
       " 1284 │ 19.7115   2.9812       1.0      0.0      0.0      0.0      0.0      1. ⋯\n",
       " 1285 │ 45.5466   3.81874      1.0      0.0      0.0      0.0      1.0      0.\n",
       " 1286 │ 13.8462   2.62801      0.0      0.0      0.0      0.0      1.0      0.\n",
       " 1287 │ 23.0769   3.13883      1.0      0.0      0.0      1.0      0.0      0.\n",
       " 1288 │ 17.3077   2.85115      0.0      0.0      0.0      0.0      0.0      1. ⋯\n",
       "\u001b[36m                                                13 columns and 1267 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = sample( collect(1:nrow( data ) ), trunc(Int, 3 * nrow( data ) / 4 ),  replace= false )\n",
    "\n",
    "data_train = data[ vec(training), : ]\n",
    "data_test = data[ Not(training), : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038774,
     "end_time": "2021-02-13T18:19:45.217757",
     "exception": false,
     "start_time": "2021-02-13T18:19:45.178983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We construct the two different model matrices $X_{basic}$ and $X_{flex}$ for both the training and the test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3862, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sex + exp1 + exp2 + shs+hsg+scl+clg+occ2+ind2+mw+so+we + (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_basic =  \"sex + exp1 + exp2+ shs + hsg+ scl + clg + mw + so + we + occ2+ ind2\"\n",
    "X_flex = \"sex + exp1 + exp2 + shs+hsg+scl+clg+occ2+ind2+mw+so+we + (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map(*, \"lwage\", \"~\", X_basic )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FormulaTerm\n",
       "Response:\n",
       "  lwage(unknown)\n",
       "Predictors:\n",
       "  sex(unknown)\n",
       "  exp1(unknown)\n",
       "  exp2(unknown)\n",
       "  shs(unknown)\n",
       "  hsg(unknown)\n",
       "  scl(unknown)\n",
       "  clg(unknown)\n",
       "  occ2(unknown)\n",
       "  ind2(unknown)\n",
       "  mw(unknown)\n",
       "  so(unknown)\n",
       "  we(unknown)\n",
       "  exp3(unknown)\n",
       "  exp4(unknown)\n",
       "  exp1(unknown) & shs(unknown)\n",
       "  exp1(unknown) & hsg(unknown)\n",
       "  exp1(unknown) & scl(unknown)\n",
       "  exp1(unknown) & clg(unknown)\n",
       "  exp1(unknown) & occ2(unknown)\n",
       "  exp1(unknown) & ind2(unknown)\n",
       "  exp1(unknown) & mw(unknown)\n",
       "  exp1(unknown) & so(unknown)\n",
       "  exp1(unknown) & we(unknown)\n",
       "  exp2(unknown) & shs(unknown)\n",
       "  exp2(unknown) & hsg(unknown)\n",
       "  exp2(unknown) & scl(unknown)\n",
       "  exp2(unknown) & clg(unknown)\n",
       "  exp2(unknown) & occ2(unknown)\n",
       "  exp2(unknown) & ind2(unknown)\n",
       "  exp2(unknown) & mw(unknown)\n",
       "  exp2(unknown) & so(unknown)\n",
       "  exp2(unknown) & we(unknown)\n",
       "  exp3(unknown) & shs(unknown)\n",
       "  exp3(unknown) & hsg(unknown)\n",
       "  exp3(unknown) & scl(unknown)\n",
       "  exp3(unknown) & clg(unknown)\n",
       "  exp3(unknown) & occ2(unknown)\n",
       "  exp3(unknown) & ind2(unknown)\n",
       "  exp3(unknown) & mw(unknown)\n",
       "  exp3(unknown) & so(unknown)\n",
       "  exp3(unknown) & we(unknown)\n",
       "  exp4(unknown) & shs(unknown)\n",
       "  exp4(unknown) & hsg(unknown)\n",
       "  exp4(unknown) & scl(unknown)\n",
       "  exp4(unknown) & clg(unknown)\n",
       "  exp4(unknown) & occ2(unknown)\n",
       "  exp4(unknown) & ind2(unknown)\n",
       "  exp4(unknown) & mw(unknown)\n",
       "  exp4(unknown) & so(unknown)\n",
       "  exp4(unknown) & we(unknown)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula_basic = @formula(lwage ~ (sex + exp1 + exp2+ shs + hsg+ scl + clg + mw + so + we + occ2+ ind2) )\n",
    "formula_flex = @formula(lwage ~ (sex + exp1 + exp2 + shs+hsg+scl+clg+occ2+ind2+mw+so+we + (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_X_basic_train = ModelMatrix(ModelFrame(formula_basic,data_train)).m\n",
    "model_X_basic_test = ModelMatrix(ModelFrame(formula_basic,data_test)).m\n",
    "p_basic = size(model_X_basic_test)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_X_flex_train = ModelMatrix(ModelFrame(formula_flex,data_train)).m\n",
    "model_X_flex_test = ModelMatrix(ModelFrame(formula_flex,data_test)).m\n",
    "p_flex = size(model_X_flex_test)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>1,288 rows × 1 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>lwage</th></tr><tr><th></th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>2.63493</td></tr><tr><th>2</th><td>2.95651</td></tr><tr><th>3</th><td>2.48651</td></tr><tr><th>4</th><td>3.07269</td></tr><tr><th>5</th><td>2.44569</td></tr><tr><th>6</th><td>2.87855</td></tr><tr><th>7</th><td>2.48491</td></tr><tr><th>8</th><td>2.97911</td></tr><tr><th>9</th><td>1.90669</td></tr><tr><th>10</th><td>2.64066</td></tr><tr><th>11</th><td>2.73337</td></tr><tr><th>12</th><td>2.95651</td></tr><tr><th>13</th><td>2.75501</td></tr><tr><th>14</th><td>3.14991</td></tr><tr><th>15</th><td>3.11778</td></tr><tr><th>16</th><td>3.36198</td></tr><tr><th>17</th><td>2.83873</td></tr><tr><th>18</th><td>2.93119</td></tr><tr><th>19</th><td>3.16681</td></tr><tr><th>20</th><td>3.07429</td></tr><tr><th>21</th><td>2.87195</td></tr><tr><th>22</th><td>3.08434</td></tr><tr><th>23</th><td>3.17966</td></tr><tr><th>24</th><td>2.48651</td></tr><tr><th>25</th><td>2.38077</td></tr><tr><th>26</th><td>3.06984</td></tr><tr><th>27</th><td>2.73337</td></tr><tr><th>28</th><td>2.48651</td></tr><tr><th>29</th><td>2.29154</td></tr><tr><th>30</th><td>2.57922</td></tr><tr><th>&vellip;</th><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& lwage\\\\\n",
       "\t\\hline\n",
       "\t& Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2.63493 \\\\\n",
       "\t2 & 2.95651 \\\\\n",
       "\t3 & 2.48651 \\\\\n",
       "\t4 & 3.07269 \\\\\n",
       "\t5 & 2.44569 \\\\\n",
       "\t6 & 2.87855 \\\\\n",
       "\t7 & 2.48491 \\\\\n",
       "\t8 & 2.97911 \\\\\n",
       "\t9 & 1.90669 \\\\\n",
       "\t10 & 2.64066 \\\\\n",
       "\t11 & 2.73337 \\\\\n",
       "\t12 & 2.95651 \\\\\n",
       "\t13 & 2.75501 \\\\\n",
       "\t14 & 3.14991 \\\\\n",
       "\t15 & 3.11778 \\\\\n",
       "\t16 & 3.36198 \\\\\n",
       "\t17 & 2.83873 \\\\\n",
       "\t18 & 2.93119 \\\\\n",
       "\t19 & 3.16681 \\\\\n",
       "\t20 & 3.07429 \\\\\n",
       "\t21 & 2.87195 \\\\\n",
       "\t22 & 3.08434 \\\\\n",
       "\t23 & 3.17966 \\\\\n",
       "\t24 & 2.48651 \\\\\n",
       "\t25 & 2.38077 \\\\\n",
       "\t26 & 3.06984 \\\\\n",
       "\t27 & 2.73337 \\\\\n",
       "\t28 & 2.48651 \\\\\n",
       "\t29 & 2.29154 \\\\\n",
       "\t30 & 2.57922 \\\\\n",
       "\t$\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1288×1 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m lwage   \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64 \u001b[0m\n",
       "──────┼─────────\n",
       "    1 │ 2.63493\n",
       "    2 │ 2.95651\n",
       "    3 │ 2.48651\n",
       "    4 │ 3.07269\n",
       "    5 │ 2.44569\n",
       "    6 │ 2.87855\n",
       "    7 │ 2.48491\n",
       "    8 │ 2.97911\n",
       "    9 │ 1.90669\n",
       "   10 │ 2.64066\n",
       "   11 │ 2.73337\n",
       "  ⋮   │    ⋮\n",
       " 1279 │ 2.50453\n",
       " 1280 │ 2.76414\n",
       " 1281 │ 3.36198\n",
       " 1282 │ 2.48651\n",
       " 1283 │ 2.56347\n",
       " 1284 │ 2.9812\n",
       " 1285 │ 3.81874\n",
       " 1286 │ 2.62801\n",
       " 1287 │ 3.13883\n",
       " 1288 │ 2.85115\n",
       "\u001b[36m1267 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = data_train[!, [\"lwage\"]] # Dataframe format\n",
    "Y_test = data_test[ !,  [\"lwage\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_basic\n",
    "p_flex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037704,
     "end_time": "2021-02-13T18:19:45.622370",
     "exception": false,
     "start_time": "2021-02-13T18:19:45.584666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As known from our first lab, the basic model consists of $10$ regressors and the flexible model of $246$ regressors. Let us fit our models to the training sample using the two different model specifications. We are starting by running a simple ols regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038763,
     "end_time": "2021-02-13T18:19:45.699126",
     "exception": false,
     "start_time": "2021-02-13T18:19:45.660363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039458,
     "end_time": "2021-02-13T18:19:45.779460",
     "exception": false,
     "start_time": "2021-02-13T18:19:45.740002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We fit the basic model to our training data by running an ols regression and compute the mean squared error on the test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3,862 rows × 20 columns (omitted printing of 11 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>wage</th><th>lwage</th><th>sex</th><th>shs</th><th>hsg</th><th>scl</th><th>clg</th><th>ad</th><th>mw</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>14.9573</td><td>2.7052</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>2</th><td>76.0073</td><td>4.33083</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>3</th><td>30.0</td><td>3.4012</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>22.1154</td><td>3.09627</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>5</th><td>40.1709</td><td>3.69314</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td></tr><tr><th>6</th><td>24.9202</td><td>3.21568</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td></tr><tr><th>7</th><td>34.6154</td><td>3.5443</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>13.4615</td><td>2.59984</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>7.21154</td><td>1.97568</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>17.094</td><td>2.83873</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>9.61538</td><td>2.26336</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>12.5</td><td>2.52573</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>12.9371</td><td>2.5601</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>10.5769</td><td>2.35867</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>13.6752</td><td>2.61558</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>16</th><td>16.25</td><td>2.78809</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>22.5962</td><td>3.11778</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>29.021</td><td>3.36802</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>19</th><td>9.61538</td><td>2.26336</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>48.0769</td><td>3.8728</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>43.2692</td><td>3.76744</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>22</th><td>14.4231</td><td>2.66883</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>13.7363</td><td>2.62004</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>8.24176</td><td>2.10921</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>25</th><td>86.5385</td><td>4.46059</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>26</th><td>36.8627</td><td>3.6072</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>27</th><td>17.6208</td><td>2.86908</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>20.0</td><td>2.99573</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>26.4423</td><td>3.27497</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>21.6346</td><td>3.07429</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& wage & lwage & sex & shs & hsg & scl & clg & ad & mw & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 14.9573 & 2.7052 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t2 & 76.0073 & 4.33083 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 30.0 & 3.4012 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 22.1154 & 3.09627 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 40.1709 & 3.69314 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t6 & 24.9202 & 3.21568 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 1.0 & $\\dots$ \\\\\n",
       "\t7 & 34.6154 & 3.5443 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 13.4615 & 2.59984 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 7.21154 & 1.97568 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 17.094 & 2.83873 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & 9.61538 & 2.26336 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & 12.5 & 2.52573 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 12.9371 & 2.5601 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 10.5769 & 2.35867 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 13.6752 & 2.61558 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t16 & 16.25 & 2.78809 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 22.5962 & 3.11778 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & 29.021 & 3.36802 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t19 & 9.61538 & 2.26336 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 48.0769 & 3.8728 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 43.2692 & 3.76744 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & 14.4231 & 2.66883 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 13.7363 & 2.62004 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 8.24176 & 2.10921 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t25 & 86.5385 & 4.46059 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 36.8627 & 3.6072 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t27 & 17.6208 & 2.86908 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & 20.0 & 2.99573 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 26.4423 & 3.27497 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 21.6346 & 3.07429 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3862×20 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m wage     \u001b[0m\u001b[1m lwage   \u001b[0m\u001b[1m sex     \u001b[0m\u001b[1m shs     \u001b[0m\u001b[1m hsg     \u001b[0m\u001b[1m scl     \u001b[0m\u001b[1m clg     \u001b[0m\u001b[1m ad    \u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float6\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │ 14.9573   2.7052       1.0      0.0      0.0      1.0      0.0      0. ⋯\n",
       "    2 │ 76.0073   4.33083      1.0      0.0      0.0      0.0      0.0      1.\n",
       "    3 │ 30.0      3.4012       1.0      0.0      0.0      0.0      1.0      0.\n",
       "    4 │ 22.1154   3.09627      0.0      0.0      0.0      0.0      0.0      1.\n",
       "    5 │ 40.1709   3.69314      1.0      0.0      0.0      0.0      1.0      0. ⋯\n",
       "    6 │ 24.9202   3.21568      0.0      0.0      0.0      0.0      0.0      1.\n",
       "    7 │ 34.6154   3.5443       0.0      0.0      0.0      1.0      0.0      0.\n",
       "    8 │ 13.4615   2.59984      1.0      0.0      1.0      0.0      0.0      0.\n",
       "    9 │  7.21154  1.97568      1.0      0.0      1.0      0.0      0.0      0. ⋯\n",
       "   10 │ 17.094    2.83873      0.0      0.0      1.0      0.0      0.0      0.\n",
       "   11 │  9.61538  2.26336      0.0      0.0      1.0      0.0      0.0      0.\n",
       "  ⋮   │    ⋮         ⋮        ⋮        ⋮        ⋮        ⋮        ⋮        ⋮   ⋱\n",
       " 3853 │ 24.0385   3.17966      0.0      0.0      0.0      0.0      1.0      0.\n",
       " 3854 │ 14.4231   2.66883      1.0      0.0      0.0      0.0      1.0      0. ⋯\n",
       " 3855 │ 15.0      2.70805      0.0      0.0      0.0      0.0      1.0      0.\n",
       " 3856 │ 12.0192   2.48651      0.0      0.0      1.0      0.0      0.0      0.\n",
       " 3857 │ 32.0513   3.46734      1.0      0.0      0.0      0.0      1.0      0.\n",
       " 3858 │ 14.9038   2.70162      0.0      0.0      1.0      0.0      0.0      0. ⋯\n",
       " 3859 │ 14.4231   2.66883      1.0      0.0      0.0      0.0      1.0      0.\n",
       " 3860 │ 24.0385   3.17966      1.0      0.0      0.0      1.0      0.0      0.\n",
       " 3861 │ 12.2378   2.50453      0.0      0.0      0.0      0.0      1.0      0.\n",
       " 3862 │ 17.6923   2.87313      0.0      0.0      0.0      0.0      1.0      0. ⋯\n",
       "\u001b[36m                                                13 columns and 3841 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3862, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size( data_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "lwage ~ 1 + sex + exp1 + exp2 + shs + hsg + scl + clg + mw + so + we + occ2 + ind2\n",
       "\n",
       "Coefficients:\n",
       "───────────────────────────────────────────────────────────────────────────────\n",
       "                  Coef.  Std. Error       t  Pr(>|t|)   Lower 95%     Upper 95%\n",
       "───────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   3.72493    0.0947232    39.32    <1e-99   3.53922     3.91064\n",
       "sex          -0.0857578  0.0171823    -4.99    <1e-06  -0.119445   -0.0520705\n",
       "exp1          0.0240811  0.00272753    8.83    <1e-17   0.0187335   0.0294286\n",
       "exp2         -0.0414908  0.00711992   -5.83    <1e-08  -0.05545    -0.0275316\n",
       "shs          -0.650317   0.058419    -11.13    <1e-27  -0.764853   -0.535782\n",
       "hsg          -0.545943   0.0315438   -17.31    <1e-63  -0.607787   -0.484099\n",
       "scl          -0.465867   0.0290968   -16.01    <1e-55  -0.522914   -0.408821\n",
       "clg          -0.212608   0.0262945    -8.09    <1e-15  -0.264161   -0.161055\n",
       "mw           -0.0356639  0.0223575    -1.60    0.1108  -0.0794977   0.0081699\n",
       "so           -0.0293433  0.0214036    -1.37    0.1705  -0.0713069   0.0126203\n",
       "we            0.0241892  0.0231266     1.05    0.2957  -0.0211525   0.0695309\n",
       "occ2: 2      -0.084896   0.038554     -2.20    0.0277  -0.160484   -0.00930762\n",
       "occ2: 3      -0.0359861  0.0435257    -0.83    0.4084  -0.121322    0.0493498\n",
       "occ2: 4      -0.0964861  0.0601289    -1.60    0.1087  -0.214374    0.0214018\n",
       "occ2: 5      -0.205915   0.0682447    -3.02    0.0026  -0.339715   -0.0721156\n",
       "occ2: 6      -0.414052   0.0572012    -7.24    <1e-12  -0.5262     -0.301904\n",
       "occ2: 7      -0.0474721  0.0643674    -0.74    0.4609  -0.17367     0.0787258\n",
       "occ2: 8      -0.367984   0.0504217    -7.30    <1e-12  -0.46684    -0.269128\n",
       "occ2: 9      -0.217033   0.0526504    -4.12    <1e-04  -0.320259   -0.113808\n",
       "occ2: 10      0.0154122  0.0454747     0.34    0.7347  -0.073745    0.104569\n",
       "occ2: 11     -0.437326   0.0671343    -6.51    <1e-10  -0.568948   -0.305703\n",
       "occ2: 12     -0.299328   0.0658003    -4.55    <1e-05  -0.428335   -0.170321\n",
       "occ2: 13     -0.369866   0.0522467    -7.08    <1e-11  -0.4723     -0.267432\n",
       "occ2: 14     -0.474306   0.0583061    -8.13    <1e-15  -0.588621   -0.359992\n",
       "occ2: 15     -0.425391   0.0598978    -7.10    <1e-11  -0.542826   -0.307956\n",
       "occ2: 16     -0.198936   0.0369176    -5.39    <1e-07  -0.271316   -0.126556\n",
       "occ2: 17     -0.391245   0.0318563   -12.28    <1e-33  -0.453702   -0.328788\n",
       "occ2: 18     -0.469325   0.239396     -1.96    0.0500  -0.938681    3.05025e-5\n",
       "occ2: 19     -0.230151   0.056321     -4.09    <1e-04  -0.340573   -0.119729\n",
       "occ2: 20     -0.21454    0.047578     -4.51    <1e-05  -0.30782    -0.121259\n",
       "occ2: 21     -0.27903    0.0430279    -6.48    <1e-09  -0.363389   -0.19467\n",
       "occ2: 22     -0.40081    0.0472639    -8.48    <1e-16  -0.493475   -0.308144\n",
       "ind2: 3      -0.111372   0.118027     -0.94    0.3454  -0.342774    0.12003\n",
       "ind2: 4      -0.32191    0.0899168    -3.58    0.0003  -0.4982     -0.14562\n",
       "ind2: 5      -0.363758   0.094994     -3.83    0.0001  -0.550002   -0.177514\n",
       "ind2: 6      -0.289287   0.0910682    -3.18    0.0015  -0.467834   -0.110739\n",
       "ind2: 7      -0.202859   0.107023     -1.90    0.0581  -0.412688    0.00696937\n",
       "ind2: 8      -0.295158   0.108952     -2.71    0.0068  -0.508769   -0.0815478\n",
       "ind2: 9      -0.458654   0.0896838    -5.11    <1e-06  -0.634486   -0.282821\n",
       "ind2: 10     -0.26564    0.0995401    -2.67    0.0076  -0.460797   -0.0704825\n",
       "ind2: 11     -0.192202   0.0966449    -1.99    0.0468  -0.381683   -0.00272102\n",
       "ind2: 12     -0.115501   0.0923497    -1.25    0.2111  -0.29656     0.0655589\n",
       "ind2: 13     -0.178461   0.105697     -1.69    0.0914  -0.38569     0.0287678\n",
       "ind2: 14     -0.225217   0.0898881    -2.51    0.0123  -0.40145    -0.0489833\n",
       "ind2: 15     -0.321236   0.163472     -1.97    0.0495  -0.641738   -0.000735043\n",
       "ind2: 16     -0.373897   0.0957944    -3.90    <1e-04  -0.56171    -0.186084\n",
       "ind2: 17     -0.36251    0.0942837    -3.84    0.0001  -0.547361   -0.177658\n",
       "ind2: 18     -0.381004   0.0912533    -4.18    <1e-04  -0.559914   -0.202094\n",
       "ind2: 19     -0.436282   0.10223      -4.27    <1e-04  -0.636713   -0.235851\n",
       "ind2: 20     -0.604035   0.0951916    -6.35    <1e-09  -0.790667   -0.417404\n",
       "ind2: 21     -0.381323   0.0936141    -4.07    <1e-04  -0.564862   -0.197784\n",
       "ind2: 22     -0.180741   0.0925818    -1.95    0.0510  -0.362255    0.000774065\n",
       "───────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_lm_basic = lm(formula_basic, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) using the basic model is equal to 0.23776317494032084"
     ]
    }
   ],
   "source": [
    "# Compute the Out-Of-Sample Performance\n",
    "yhat_lm_basic = GLM.predict( fit_lm_basic , data_test )\n",
    "res_lm_basic = ( Y_test[!,1] - yhat_lm_basic ).^ 2\n",
    "print(\"The mean squared error (MSE) using the basic model is equal to \" , mean( res_lm_basic ) ) # MSE OLS (basic model)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052764,
     "end_time": "2021-02-13T18:19:46.122829",
     "exception": false,
     "start_time": "2021-02-13T18:19:46.070065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To determine the out-of-sample $MSE$ and the standard error in one step, we can use the function *lm*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Vector{Float64}}:\n",
       " [0.23776317494032076]\n",
       " [0.015051846145404524]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_ones = ones( size(res_lm_basic)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_lm_basic )   # first argument (X), secind argument (Y)\n",
    "MSE_lm_basic = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "MSE_lm_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039088,
     "end_time": "2021-02-13T18:19:46.317915",
     "exception": false,
     "start_time": "2021-02-13T18:19:46.278827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also compute the out-of-sample $R^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 using the basic model is equal to 0.2549832909790051"
     ]
    }
   ],
   "source": [
    "R2_lm_basic = 1 .- ( MSE_lm_basic[1] / var( Y_test[!,1] ) )\n",
    "print( \"The R^2 using the basic model is equal to \", R2_lm_basic[1] ) # MSE OLS (basic model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039585,
     "end_time": "2021-02-13T18:19:46.492903",
     "exception": false,
     "start_time": "2021-02-13T18:19:46.453318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We repeat the same procedure for the flexible model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 using the basic model is equal to 0.2124995571215672"
     ]
    }
   ],
   "source": [
    "# ols (flexible model)\n",
    "fit_lm_flex = lm( formula_flex, data_train ) \n",
    "yhat_lm_flex = GLM.predict( fit_lm_flex, data_test)\n",
    "\n",
    "res_lm_flex = ( Y_test[!,1] - yhat_lm_flex ) .^ 2\n",
    "mean_residuals = lm(  matrix_ones, res_lm_flex )\n",
    "MSE_lm_flex = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "\n",
    "R2_lm_flex = 1 .- ( MSE_lm_flex[1] / var( Y_test[!,1] ) )\n",
    "print( \"The R^2 using the basic model is equal to \", R2_lm_flex[1] ) # MSE OLS (flex model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051953,
     "end_time": "2021-02-13T18:19:46.853182",
     "exception": false,
     "start_time": "2021-02-13T18:19:46.801229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We observe that ols regression works better for the basic model with smaller $p/n$ ratio. We are proceeding by running lasso regressions and its versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042521,
     "end_time": "2021-02-13T18:19:46.935859",
     "exception": false,
     "start_time": "2021-02-13T18:19:46.893338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Lasso, Ridge and Elastic Net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040161,
     "end_time": "2021-02-13T18:19:47.015626",
     "exception": false,
     "start_time": "2021-02-13T18:19:46.975465",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Considering the basic model, we run a lasso/post-lasso regression first and then we compute the measures for the out-of-sample performance. Note that applying the package *hdm* and the function *rlasso* we rely on a theoretical based choice of the penalty level $\\lambda$ in the lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load HDM package\n",
    "\n",
    "include(\"../hdmjl/hdmjl.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3,862 rows × 52 columns (omitted printing of 43 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>(Intercept)</th><th>sex</th><th>exp1</th><th>exp2</th><th>shs</th><th>hsg</th><th>scl</th><th>clg</th><th>mw</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>1.0</td><td>1.0</td><td>9.0</td><td>0.81</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td></tr><tr><th>2</th><td>1.0</td><td>1.0</td><td>14.0</td><td>1.96</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>1.0</td><td>1.0</td><td>16.0</td><td>2.56</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>4</th><td>1.0</td><td>0.0</td><td>3.0</td><td>0.09</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>1.0</td><td>1.0</td><td>31.0</td><td>9.61</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td></tr><tr><th>6</th><td>1.0</td><td>0.0</td><td>7.0</td><td>0.49</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>7</th><td>1.0</td><td>0.0</td><td>26.5</td><td>7.0225</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>1.0</td><td>1.0</td><td>34.0</td><td>11.56</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>1.0</td><td>1.0</td><td>15.0</td><td>2.25</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>1.0</td><td>0.0</td><td>22.0</td><td>4.84</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>1.0</td><td>0.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>1.0</td><td>1.0</td><td>39.0</td><td>15.21</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>1.0</td><td>0.0</td><td>34.5</td><td>11.9025</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>1.0</td><td>0.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>1.0</td><td>0.0</td><td>26.0</td><td>6.76</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>16</th><td>1.0</td><td>1.0</td><td>8.0</td><td>0.64</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>17</th><td>1.0</td><td>0.0</td><td>21.0</td><td>4.41</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>1.0</td><td>0.0</td><td>16.0</td><td>2.56</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>19</th><td>1.0</td><td>0.0</td><td>20.0</td><td>4.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>1.0</td><td>0.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>1.0</td><td>0.0</td><td>18.0</td><td>3.24</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>22</th><td>1.0</td><td>0.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>1.0</td><td>1.0</td><td>4.0</td><td>0.16</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>24</th><td>1.0</td><td>1.0</td><td>5.0</td><td>0.25</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>25</th><td>1.0</td><td>0.0</td><td>12.0</td><td>1.44</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>1.0</td><td>0.0</td><td>14.0</td><td>1.96</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td></tr><tr><th>27</th><td>1.0</td><td>0.0</td><td>20.0</td><td>4.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>28</th><td>1.0</td><td>0.0</td><td>8.5</td><td>0.7225</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>1.0</td><td>1.0</td><td>23.0</td><td>5.29</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>30</th><td>1.0</td><td>1.0</td><td>6.0</td><td>0.36</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& (Intercept) & sex & exp1 & exp2 & shs & hsg & scl & clg & mw & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1.0 & 1.0 & 9.0 & 0.81 & 0.0 & 0.0 & 1.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t2 & 1.0 & 1.0 & 14.0 & 1.96 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 1.0 & 1.0 & 16.0 & 2.56 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 1.0 & 0.0 & 3.0 & 0.09 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 1.0 & 1.0 & 31.0 & 9.61 & 0.0 & 0.0 & 0.0 & 1.0 & 1.0 & $\\dots$ \\\\\n",
       "\t6 & 1.0 & 0.0 & 7.0 & 0.49 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t7 & 1.0 & 0.0 & 26.5 & 7.0225 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 1.0 & 1.0 & 34.0 & 11.56 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 1.0 & 1.0 & 15.0 & 2.25 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 1.0 & 0.0 & 22.0 & 4.84 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & 1.0 & 0.0 & 10.0 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & 1.0 & 1.0 & 39.0 & 15.21 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 1.0 & 0.0 & 34.5 & 11.9025 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 1.0 & 0.0 & 10.0 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 1.0 & 0.0 & 26.0 & 6.76 & 0.0 & 1.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t16 & 1.0 & 1.0 & 8.0 & 0.64 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 1.0 & 0.0 & 21.0 & 4.41 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & 1.0 & 0.0 & 16.0 & 2.56 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t19 & 1.0 & 0.0 & 20.0 & 4.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 1.0 & 0.0 & 10.0 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 1.0 & 0.0 & 18.0 & 3.24 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & 1.0 & 0.0 & 10.0 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 1.0 & 1.0 & 4.0 & 0.16 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 1.0 & 1.0 & 5.0 & 0.25 & 0.0 & 1.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t25 & 1.0 & 0.0 & 12.0 & 1.44 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 1.0 & 0.0 & 14.0 & 1.96 & 0.0 & 0.0 & 1.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t27 & 1.0 & 0.0 & 20.0 & 4.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & 1.0 & 0.0 & 8.5 & 0.7225 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 1.0 & 1.0 & 23.0 & 5.29 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 1.0 & 1.0 & 6.0 & 0.36 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3862×52 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m (Intercept) \u001b[0m\u001b[1m sex     \u001b[0m\u001b[1m exp1    \u001b[0m\u001b[1m exp2    \u001b[0m\u001b[1m shs     \u001b[0m\u001b[1m hsg     \u001b[0m\u001b[1m scl     \u001b[0m\u001b[1m clg\u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Flo\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │         1.0      1.0      9.0   0.81        0.0      0.0      1.0      ⋯\n",
       "    2 │         1.0      1.0     14.0   1.96        0.0      0.0      0.0\n",
       "    3 │         1.0      1.0     16.0   2.56        0.0      0.0      0.0\n",
       "    4 │         1.0      0.0      3.0   0.09        0.0      0.0      0.0\n",
       "    5 │         1.0      1.0     31.0   9.61        0.0      0.0      0.0      ⋯\n",
       "    6 │         1.0      0.0      7.0   0.49        0.0      0.0      0.0\n",
       "    7 │         1.0      0.0     26.5   7.0225      0.0      0.0      1.0\n",
       "    8 │         1.0      1.0     34.0  11.56        0.0      1.0      0.0\n",
       "    9 │         1.0      1.0     15.0   2.25        0.0      1.0      0.0      ⋯\n",
       "   10 │         1.0      0.0     22.0   4.84        0.0      1.0      0.0\n",
       "   11 │         1.0      0.0     10.0   1.0         0.0      1.0      0.0\n",
       "  ⋮   │      ⋮          ⋮        ⋮        ⋮        ⋮        ⋮        ⋮         ⋱\n",
       " 3853 │         1.0      0.0      4.0   0.16        0.0      0.0      0.0\n",
       " 3854 │         1.0      1.0     10.0   1.0         0.0      0.0      0.0      ⋯\n",
       " 3855 │         1.0      0.0      3.0   0.09        0.0      0.0      0.0\n",
       " 3856 │         1.0      0.0     32.0  10.24        0.0      1.0      0.0\n",
       " 3857 │         1.0      1.0      3.0   0.09        0.0      0.0      0.0\n",
       " 3858 │         1.0      0.0     40.0  16.0         0.0      1.0      0.0      ⋯\n",
       " 3859 │         1.0      1.0     34.0  11.56        0.0      0.0      0.0\n",
       " 3860 │         1.0      1.0     16.5   2.7225      0.0      0.0      1.0\n",
       " 3861 │         1.0      0.0      5.0   0.25        0.0      0.0      0.0\n",
       " 3862 │         1.0      0.0      3.0   0.09        0.0      0.0      0.0      ⋯\n",
       "\u001b[36m                                                45 columns and 3841 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_col1 = Symbol.(coefnames(fit_lm_basic))\n",
    "X1 = DataFrame(model_X_basic_train, names_col1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 using the basic model is  0.16606153507508836 for lasso and 0.21948405408319804for Post - lasso"
     ]
    }
   ],
   "source": [
    "# basic model \n",
    "# not post - lasso (HDM)\n",
    "# first false for Not post lasso, second false for not intercetp\n",
    "\n",
    "\n",
    "rlasso_basic  = rlasso_arg( X1, Y_train, nothing, false, false, true, false, false, \n",
    "                    nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true )\n",
    "\n",
    "fit_rlasso_basic = rlasso(rlasso_basic)\n",
    "\n",
    "\n",
    "# post - lasso (HDM)\n",
    "rlasso_basic_post  = rlasso_arg( X1, Y_train, nothing, true, false, true, false, false, \n",
    "                    nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true )\n",
    "\n",
    "fit_rlasso_basic_post = rlasso(rlasso_basic_post)\n",
    "\n",
    "yhat_rlasso = model_X_basic_test*fit_rlasso_basic[\"coefficients\"] \n",
    "yhat_rlasso_post = model_X_basic_test*fit_rlasso_basic_post[\"coefficients\"] \n",
    "\n",
    "\n",
    "res_rlasso_basic = ( Y_test[!,1] - yhat_rlasso ).^ 2\n",
    "matrix_ones = ones( size(res_rlasso_basic)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_rlasso_basic )  \n",
    "MSE_rlasso_basic = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_rlasso_basic = 1 .- ( MSE_rlasso_basic[1] / var(Y_test[!,1]) ) \n",
    "\n",
    "res_rlasso_basic_post = ( Y_test[!,1] - yhat_rlasso_post ).^ 2\n",
    "matrix_ones = ones( size(res_rlasso_basic_post)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_rlasso_basic_post )  \n",
    "MSE_rlasso_basic_post = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_rlasso_basic_post = 1 .- ( MSE_rlasso_basic_post[1] / var(Y_test[!,1]) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 using the basic model is  0.16606153507508836 for lasso and 0.21948405408319804 for Post - lasso"
     ]
    }
   ],
   "source": [
    "print( \"The R^2 using the basic model is  \", R2_rlasso_basic[1] ,\" for lasso and \", R2_rlasso_basic_post[1] , \" for Post - lasso\") # MSE OLS (basic model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexible Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3,862 rows × 246 columns (omitted printing of 237 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>(Intercept)</th><th>sex</th><th>exp1</th><th>exp2</th><th>shs</th><th>hsg</th><th>scl</th><th>clg</th><th>occ2: 2</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>1.0</td><td>1.0</td><td>9.0</td><td>0.81</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>1.0</td><td>1.0</td><td>14.0</td><td>1.96</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>3</th><td>1.0</td><td>1.0</td><td>16.0</td><td>2.56</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>4</th><td>1.0</td><td>0.0</td><td>3.0</td><td>0.09</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>1.0</td><td>1.0</td><td>31.0</td><td>9.61</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>6</th><td>1.0</td><td>0.0</td><td>7.0</td><td>0.49</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>1.0</td><td>0.0</td><td>26.5</td><td>7.0225</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>1.0</td><td>1.0</td><td>34.0</td><td>11.56</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>9</th><td>1.0</td><td>1.0</td><td>15.0</td><td>2.25</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>1.0</td><td>0.0</td><td>22.0</td><td>4.84</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>1.0</td><td>0.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>1.0</td><td>1.0</td><td>39.0</td><td>15.21</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>1.0</td><td>0.0</td><td>34.5</td><td>11.9025</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>1.0</td><td>0.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>1.0</td><td>0.0</td><td>26.0</td><td>6.76</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>1.0</td><td>1.0</td><td>8.0</td><td>0.64</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>17</th><td>1.0</td><td>0.0</td><td>21.0</td><td>4.41</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>1.0</td><td>0.0</td><td>16.0</td><td>2.56</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>19</th><td>1.0</td><td>0.0</td><td>20.0</td><td>4.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>1.0</td><td>0.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>1.0</td><td>0.0</td><td>18.0</td><td>3.24</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>22</th><td>1.0</td><td>0.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>1.0</td><td>1.0</td><td>4.0</td><td>0.16</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>24</th><td>1.0</td><td>1.0</td><td>5.0</td><td>0.25</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>1.0</td><td>0.0</td><td>12.0</td><td>1.44</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>1.0</td><td>0.0</td><td>14.0</td><td>1.96</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>27</th><td>1.0</td><td>0.0</td><td>20.0</td><td>4.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>28</th><td>1.0</td><td>0.0</td><td>8.5</td><td>0.7225</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>1.0</td><td>1.0</td><td>23.0</td><td>5.29</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>30</th><td>1.0</td><td>1.0</td><td>6.0</td><td>0.36</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& (Intercept) & sex & exp1 & exp2 & shs & hsg & scl & clg & occ2: 2 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1.0 & 1.0 & 9.0 & 0.81 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 1.0 & 1.0 & 14.0 & 1.96 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t3 & 1.0 & 1.0 & 16.0 & 2.56 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 1.0 & 0.0 & 3.0 & 0.09 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 1.0 & 1.0 & 31.0 & 9.61 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 1.0 & 0.0 & 7.0 & 0.49 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 1.0 & 0.0 & 26.5 & 7.0225 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 1.0 & 1.0 & 34.0 & 11.56 & 0.0 & 1.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t9 & 1.0 & 1.0 & 15.0 & 2.25 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 1.0 & 0.0 & 22.0 & 4.84 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & 1.0 & 0.0 & 10.0 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & 1.0 & 1.0 & 39.0 & 15.21 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 1.0 & 0.0 & 34.5 & 11.9025 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 1.0 & 0.0 & 10.0 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 1.0 & 0.0 & 26.0 & 6.76 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t16 & 1.0 & 1.0 & 8.0 & 0.64 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 1.0 & 0.0 & 21.0 & 4.41 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & 1.0 & 0.0 & 16.0 & 2.56 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t19 & 1.0 & 0.0 & 20.0 & 4.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 1.0 & 0.0 & 10.0 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 1.0 & 0.0 & 18.0 & 3.24 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & 1.0 & 0.0 & 10.0 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 1.0 & 1.0 & 4.0 & 0.16 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 1.0 & 1.0 & 5.0 & 0.25 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & 1.0 & 0.0 & 12.0 & 1.44 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 1.0 & 0.0 & 14.0 & 1.96 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & 1.0 & 0.0 & 20.0 & 4.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & 1.0 & 0.0 & 8.5 & 0.7225 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 1.0 & 1.0 & 23.0 & 5.29 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 1.0 & 1.0 & 6.0 & 0.36 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3862×246 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m (Intercept) \u001b[0m\u001b[1m sex     \u001b[0m\u001b[1m exp1    \u001b[0m\u001b[1m exp2    \u001b[0m\u001b[1m shs     \u001b[0m\u001b[1m hsg     \u001b[0m\u001b[1m scl     \u001b[0m\u001b[1m clg\u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Flo\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │         1.0      1.0      9.0   0.81        0.0      0.0      1.0      ⋯\n",
       "    2 │         1.0      1.0     14.0   1.96        0.0      0.0      0.0\n",
       "    3 │         1.0      1.0     16.0   2.56        0.0      0.0      0.0\n",
       "    4 │         1.0      0.0      3.0   0.09        0.0      0.0      0.0\n",
       "    5 │         1.0      1.0     31.0   9.61        0.0      0.0      0.0      ⋯\n",
       "    6 │         1.0      0.0      7.0   0.49        0.0      0.0      0.0\n",
       "    7 │         1.0      0.0     26.5   7.0225      0.0      0.0      1.0\n",
       "    8 │         1.0      1.0     34.0  11.56        0.0      1.0      0.0\n",
       "    9 │         1.0      1.0     15.0   2.25        0.0      1.0      0.0      ⋯\n",
       "   10 │         1.0      0.0     22.0   4.84        0.0      1.0      0.0\n",
       "   11 │         1.0      0.0     10.0   1.0         0.0      1.0      0.0\n",
       "  ⋮   │      ⋮          ⋮        ⋮        ⋮        ⋮        ⋮        ⋮         ⋱\n",
       " 3853 │         1.0      0.0      4.0   0.16        0.0      0.0      0.0\n",
       " 3854 │         1.0      1.0     10.0   1.0         0.0      0.0      0.0      ⋯\n",
       " 3855 │         1.0      0.0      3.0   0.09        0.0      0.0      0.0\n",
       " 3856 │         1.0      0.0     32.0  10.24        0.0      1.0      0.0\n",
       " 3857 │         1.0      1.0      3.0   0.09        0.0      0.0      0.0\n",
       " 3858 │         1.0      0.0     40.0  16.0         0.0      1.0      0.0      ⋯\n",
       " 3859 │         1.0      1.0     34.0  11.56        0.0      0.0      0.0\n",
       " 3860 │         1.0      1.0     16.5   2.7225      0.0      0.0      1.0\n",
       " 3861 │         1.0      0.0      5.0   0.25        0.0      0.0      0.0\n",
       " 3862 │         1.0      0.0      3.0   0.09        0.0      0.0      0.0      ⋯\n",
       "\u001b[36m                                               239 columns and 3841 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_col2 = Symbol.(coefnames(fit_lm_flex))\n",
    "X2 = DataFrame(model_X_flex_train, names_col2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.2097170383689323"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flex - model\n",
    "# Not post - lasso (HDM)\n",
    "\n",
    "\n",
    "rlasso_flex  = rlasso_arg( X2, Y_train, nothing, false, false, true, false, false, \n",
    "                    nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true )\n",
    "\n",
    "fit_rlasso_flex = rlasso(rlasso_flex)\n",
    "\n",
    "\n",
    "# post - lasso (HDM)\n",
    "rlasso_flex_post  = rlasso_arg( X2, Y_train, nothing, true, false, true, false, false, \n",
    "                    nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true )\n",
    "\n",
    "fit_rlasso_flex_post = rlasso(rlasso_flex_post)\n",
    "\n",
    "yhat_rlasso_flex = model_X_flex_test*fit_rlasso_flex[\"coefficients\"] \n",
    "yhat_rlasso_flex_post = model_X_flex_test*fit_rlasso_flex_post[\"coefficients\"] \n",
    "\n",
    "\n",
    "res_rlasso_flex = ( Y_test[!,1] - yhat_rlasso_flex ).^ 2\n",
    "matrix_ones = ones( size(res_rlasso_flex)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_rlasso_flex )  \n",
    "MSE_rlasso_flex = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_rlasso_flex = 1 .- ( MSE_rlasso_flex[1] / var(Y_test[!,1]) ) \n",
    "\n",
    "res_rlasso_flex_post = ( Y_test[!,1] - yhat_rlasso_flex_post ).^ 2\n",
    "matrix_ones = ones( size(res_rlasso_flex_post)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_rlasso_flex_post )  \n",
    "MSE_rlasso_flex_post = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_rlasso_flex_post = 1 .- ( MSE_rlasso_flex_post[1] / var(Y_test[!,1]) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 using the basic model is  0.15318351227901894 for lasso and 0.2097170383689323 for Post - lasso"
     ]
    }
   ],
   "source": [
    "print( \"The R^2 using the basic model is  \", R2_rlasso_flex[1] ,\" for lasso and \", R2_rlasso_flex_post[1] , \" for Post - lasso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049543,
     "end_time": "2021-02-13T18:19:47.757271",
     "exception": false,
     "start_time": "2021-02-13T18:19:47.707728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we repeat the same procedure for the flexible model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04206,
     "end_time": "2021-02-13T18:19:51.353816",
     "exception": false,
     "start_time": "2021-02-13T18:19:51.311756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is worth to notice that lasso regression works better for the more complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041452,
     "end_time": "2021-02-13T18:19:51.436401",
     "exception": false,
     "start_time": "2021-02-13T18:19:51.394949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In contrast to a theoretical based choice of the tuning parameter $\\lambda$ in the lasso regression, we can also use cross-validation to determine the penalty level by applying the package *glmnet* and the function cv.glmnet. In this context, we also run a ridge and a elastic net regression by adjusting the parameter *alpha*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using GLMNet.coef in module Main conflicts with an existing identifier.\n",
      "WARNING: using GLMNet.predict in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "#import Pkg; Pkg.add(\"GLMNet\")\n",
    "using GLMNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.2559340995565249"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_lasso_cv   = GLMNet.glmnetcv(model_X_basic_train, Y_train[!,1], alpha=1)\n",
    "fit_ridge   = GLMNet.glmnetcv(model_X_basic_train, Y_train[!,1], alpha=0)\n",
    "fit_elnet   = GLMNet.glmnetcv(model_X_basic_train, Y_train[!,1], alpha= 0.5)\n",
    "\n",
    "yhat_lasso_cv    = GLMNet.predict(fit_lasso_cv,  model_X_basic_test)\n",
    "yhat_ridge   = GLMNet.predict(fit_ridge,  model_X_basic_test)\n",
    "yhat_elnet   = GLMNet.predict(fit_elnet,  model_X_basic_test)\n",
    "\n",
    "res_lasso_cv = ( Y_test[!,1] - yhat_lasso_cv ) .^ 2\n",
    "mean_residuals = lm(  matrix_ones, res_lasso_cv )\n",
    "MSE_lasso_cv = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "\n",
    "res_ridge = ( Y_test[!,1] - yhat_ridge ) .^ 2\n",
    "mean_residuals = lm(  matrix_ones, res_ridge )\n",
    "MSE_ridge = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "\n",
    "res_elnet = ( Y_test[!,1] - yhat_elnet ) .^ 2\n",
    "mean_residuals = lm(  matrix_ones, res_elnet )\n",
    "MSE_elnet = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "\n",
    "R2_lasso_cv = 1 .- ( MSE_lasso_cv[1] / var( Y_test[!,1] ) )\n",
    "R2_ridge = 1 .- ( MSE_ridge[1] / var( Y_test[!,1] ) )\n",
    "R2_elnet = 1 .- ( MSE_elnet[1] / var( Y_test[!,1] ) )\n",
    "\n",
    "print(\"R^2 using cross-validation for lasso, ridge and elastic net in the basic model:\"\n",
    "    , R2_lasso_cv[1],\"; \",R2_ridge[1],\" y \\n\",R2_elnet[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042613,
     "end_time": "2021-02-13T18:19:53.812553",
     "exception": false,
     "start_time": "2021-02-13T18:19:53.769940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that the following calculations for the flexible model need some computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 using cross-validation for lasso, ridge and elastic net in the flex model:0.2619562967048481; 0.24744964861051177y \n",
      "0.26179773864821876"
     ]
    }
   ],
   "source": [
    "fit_lasso_cv_flex   = GLMNet.glmnetcv(model_X_flex_train, Y_train[!,1], alpha=1)\n",
    "fit_ridge_flex   = GLMNet.glmnetcv(model_X_flex_train, Y_train[!,1], alpha=0)\n",
    "fit_elnet_flex   = GLMNet.glmnetcv(model_X_flex_train, Y_train[!,1], alpha= 0.5)\n",
    "\n",
    "yhat_lasso_cv_flex    = GLMNet.predict(fit_lasso_cv_flex,  model_X_flex_test)\n",
    "yhat_ridge_flex   = GLMNet.predict(fit_ridge_flex,  model_X_flex_test)\n",
    "yhat_elnet_flex   = GLMNet.predict(fit_elnet_flex,  model_X_flex_test)\n",
    "\n",
    "res_lasso_cv_flex = ( Y_test[!,1] - yhat_lasso_cv_flex ) .^ 2\n",
    "mean_residuals = lm(  matrix_ones, res_lasso_cv_flex )\n",
    "MSE_lasso_cv_flex = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "\n",
    "res_ridge_flex = ( Y_test[!,1] - yhat_ridge_flex ) .^ 2\n",
    "mean_residuals = lm(  matrix_ones, res_ridge_flex )\n",
    "MSE_ridge_flex = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "\n",
    "res_elnet_flex = ( Y_test[!,1] - yhat_elnet_flex ) .^ 2\n",
    "mean_residuals = lm(  matrix_ones, res_elnet_flex )\n",
    "MSE_elnet_flex = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "\n",
    "R2_lasso_cv_flex = ( 1 .- ( MSE_lasso_cv_flex[1] / var( Y_test[!,1] ) ) )[1]\n",
    "R2_ridge_flex = ( 1 .- ( MSE_ridge_flex[1] / var( Y_test[!,1] ) ) )[1]\n",
    "R2_elnet_flex = ( 1 .- ( MSE_elnet_flex[1] / var( Y_test[!,1] ) ) )[1]\n",
    "\n",
    "print(\"R^2 using cross-validation for lasso, ridge and elastic net in the flex model:\"\n",
    "    ,R2_lasso_cv_flex[1],\"; \",R2_ridge_flex[1],\"y \\n\",R2_elnet_flex[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04263,
     "end_time": "2021-02-13T18:20:07.529566",
     "exception": false,
     "start_time": "2021-02-13T18:20:07.486936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The performance of the lasso regression with cross-validated penalty is quite similar to the performance of lasso using a theoretical based choice of the tuning parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042859,
     "end_time": "2021-02-13T18:20:07.614751",
     "exception": false,
     "start_time": "2021-02-13T18:20:07.571892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Non-linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042125,
     "end_time": "2021-02-13T18:20:07.699092",
     "exception": false,
     "start_time": "2021-02-13T18:20:07.656967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Besides linear regression models, we consider nonlinear regression models to build a predictive model. We are applying regression trees, random forests, boosted trees and neural nets to estimate the regression function $g(X)$. First, we load the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pkg; Pkg.add( \"MLJ\" )\n",
    "\n",
    "# import Pkg; Pkg.add( \"MLJModels\" )\n",
    "\n",
    "#import Pkg; Pkg.add( \"ScikitLearn\" )\n",
    "\n",
    "#import Pkg; Pkg.add(\"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lathe has no model for random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using MLJ # using the MLJ framework\n",
    "#using MLJModels # loads the modesl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using DecisionTree.predict in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using ScikitLearn, DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor\n",
       "max_depth:                -1\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.001\n",
       "pruning_purity_threshold: 1.0\n",
       "n_subfeatures:            0\n",
       "root:                     nothing"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor(min_purity_increase = 0.001, min_samples_leaf=1, min_samples_split = 2, rng = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor\n",
       "max_depth:                -1\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.001\n",
       "pruning_purity_threshold: 1.0\n",
       "n_subfeatures:            0\n",
       "root:                     Decision Tree\n",
       "Leaves: 3073\n",
       "Depth:  45"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_fit =  ScikitLearn.fit!(tree, model_X_basic_train, Y_train[!,1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important method to improve predictive performance is called \"Pruning the Tree\". This\n",
    "means the process of cutting down the branches of a tree. We apply pruning to the complex tree above to reduce the depth. Initially, we determine the optimal complexity of the regression tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can prune the tree and visualize the prediction rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor\n",
       "max_depth:                -1\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.0\n",
       "pruning_purity_threshold: 0.001007\n",
       "n_subfeatures:            0\n",
       "root:                     Decision Leaf\n",
       "Majority: 2.9565115604007097\n",
       "Samples:  3862"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using prun purity parameter = 0.001007\n",
    "\n",
    "tree1 = DecisionTreeRegressor( min_samples_leaf=1, min_samples_split = 2, rng = 0, pruning_purity_threshold = 0.001007 )\n",
    "trees_fit1 =  ScikitLearn.fit!(tree1, model_X_basic_train, Y_train[!,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ScikitLearn.GridSearch: GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV\n",
       "  estimator: DecisionTreeRegressor\n",
       "  param_grid: Dict{Symbol, AbstractRange}\n",
       "  scoring: Nothing nothing\n",
       "  loss_func: Nothing nothing\n",
       "  score_func: Nothing nothing\n",
       "  fit_params: Dict{Any, Any}\n",
       "  n_jobs: Int64 1\n",
       "  iid: Bool true\n",
       "  refit: Bool true\n",
       "  cv: Nothing nothing\n",
       "  verbose: Int64 0\n",
       "  error_score: String \"raise\"\n",
       "  scorer_: Nothing nothing\n",
       "  best_params_: Nothing nothing\n",
       "  best_score_: Nothing nothing\n",
       "  grid_scores_: Nothing nothing\n",
       "  best_estimator_: Nothing nothing\n"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch = GridSearchCV(DecisionTreeRegressor(), Dict(:max_depth => 5:2:15 , :min_samples_split => 2:10:300,\n",
    "                                            :pruning_purity_threshold => 0.001:0.001:0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV\n",
       "  estimator: DecisionTreeRegressor\n",
       "  param_grid: Dict{Symbol, AbstractRange}\n",
       "  scoring: Nothing nothing\n",
       "  loss_func: Nothing nothing\n",
       "  score_func: Nothing nothing\n",
       "  fit_params: Dict{Any, Any}\n",
       "  n_jobs: Int64 1\n",
       "  iid: Bool true\n",
       "  refit: Bool true\n",
       "  cv: Nothing nothing\n",
       "  verbose: Int64 0\n",
       "  error_score: String \"raise\"\n",
       "  scorer_: score (function of type typeof(ScikitLearnBase.score))\n",
       "  best_params_: Dict{Symbol, Any}\n",
       "  best_score_: Float64 -0.3275878655882837\n",
       "  grid_scores_: Array{ScikitLearn.Skcore.CVScoreTuple}((900,))\n",
       "  best_estimator_: DecisionTreeRegressor\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ScikitLearn.fit!(gridsearch,  model_X_basic_train, Y_train[!,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: Dict{Symbol, Any}(:min_samples_split => 2, :pruning_purity_threshold => 0.001, :max_depth => 5)\n"
     ]
    }
   ],
   "source": [
    " println(\"Best hyper-parameters: $(gridsearch.best_params_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor\n",
       "max_depth:                13\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        162\n",
       "min_purity_increase:      0.0\n",
       "pruning_purity_threshold: 0.001\n",
       "n_subfeatures:            0\n",
       "root:                     Decision Leaf\n",
       "Majority: 2.9565115604007097\n",
       "Samples:  3862"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_prune = DecisionTreeRegressor(max_depth =13, min_samples_leaf=1, min_samples_split = 162, \n",
    "                                    pruning_purity_threshold = 0.001 )\n",
    "tree_prune_tree =  ScikitLearn.fit!(tree_prune, model_X_basic_train, Y_train[!,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1288-element Vector{Float64}:\n",
       " 4.605170185988092\n",
       " 2.7044210198770484\n",
       " 2.486507931154974\n",
       " 3.5925003271207063\n",
       " 2.44360025689705\n",
       " 3.3420702569416663\n",
       " 2.668829487948929\n",
       " 2.486507931154974\n",
       " 2.158003864182938\n",
       " 2.0963102951775983\n",
       " 3.1796551117149194\n",
       " 3.2228750042602554\n",
       " 2.7641396677532537\n",
       " ⋮\n",
       " 3.138833117194664\n",
       " 2.3121545440101965\n",
       " 3.1796551117149194\n",
       " 2.194371508353813\n",
       " 3.3451695501924927\n",
       " 2.1484344131667874\n",
       " 2.158003864182938\n",
       " 2.873129951461659\n",
       " 3.324236340526027\n",
       " 3.074294596057093\n",
       " 2.3513752571634776\n",
       " 3.274965291519244"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_pt = ScikitLearn.predict(trees_fit, model_X_basic_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1288-element Vector{Float64}:\n",
       " 3.881854522561412\n",
       " 0.06354964062151172\n",
       " 0.0\n",
       " 0.27019933017201236\n",
       " 4.350059968122748e-6\n",
       " 0.21485101104546672\n",
       " 0.03382761039717112\n",
       " 0.24265816994974418\n",
       " 0.06315894186215859\n",
       " 0.29631508891934183\n",
       " 0.19917217797246936\n",
       " 0.07094948422471735\n",
       " 8.340225603344558e-5\n",
       " ⋮\n",
       " 0.6086473749178336\n",
       " 0.6148425414957617\n",
       " 0.4557987278845807\n",
       " 0.32463575546542633\n",
       " 0.00028247922610083486\n",
       " 0.11429370356490876\n",
       " 0.16440195389316561\n",
       " 0.011680037359190612\n",
       " 0.2445289944449097\n",
       " 0.19917217797246936\n",
       " 0.6200898813248958\n",
       " 0.17961851577061405"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_prune_tree = ( Y_test[!,1] - y_hat_pt ) .^ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Vector{Float64}}:\n",
       " [0.4464158774349118]\n",
       " [0.025023389101739863]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_residuals = lm(  matrix_ones, res_prune_tree )\n",
    "MSE_prune_tree = [ coef( mean_residuals ) , stderror( mean_residuals ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 using Prune - tree:-0.398817491164299"
     ]
    }
   ],
   "source": [
    "res_prune_tree = ( Y_test[!,1] - y_hat_pt ) .^ 2\n",
    "mean_residuals = lm(  matrix_ones, res_prune_tree )\n",
    "MSE_prune_tree = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "\n",
    "R2_prune_tree = ( 1 .- ( MSE_prune_tree[1] / var( Y_test[!,1] ) ) )[1]\n",
    "\n",
    "print(\"R^2 using Prune - tree:\", R2_prune_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Mean Squared Error:     0.33199503951302295\n",
      "Correlation Coeff:      7.889640170806501e-16\n",
      "Coeff of Determination: -0.0006586720382191213\n",
      "\n",
      "Fold 2\n",
      "Mean Squared Error:     0.3167380431383805\n",
      "Correlation Coeff:      -1.9361044089917132e-16\n",
      "Coeff of Determination: -0.004450009510445607\n",
      "\n",
      "Fold 3\n",
      "Mean Squared Error:     0.2996077786601606\n",
      "Correlation Coeff:      -1.1576904102715225e-16\n",
      "Coeff of Determination: -0.002874859612382652\n",
      "\n",
      "Fold 4\n",
      "Mean Squared Error:     0.34302669704592265\n",
      "Correlation Coeff:      -2.980364138256173e-16\n",
      "Coeff of Determination: -0.009594212084622633\n",
      "\n",
      "Fold 5\n",
      "Mean Squared Error:     0.32079313217527805\n",
      "Correlation Coeff:      3.7378810969887676e-16\n",
      "Coeff of Determination: -0.00017166663586998254\n",
      "\n",
      "Fold 6\n",
      "Mean Squared Error:     0.3444513256875172\n",
      "Correlation Coeff:      3.1575486946711486e-16\n",
      "Coeff of Determination: -0.000945402696214348\n",
      "\n",
      "Fold 7\n",
      "Mean Squared Error:     0.33538606673777555\n",
      "Correlation Coeff:      1.4128281343671021e-16\n",
      "Coeff of Determination: -0.003323894549560835\n",
      "\n",
      "Fold 8\n",
      "Mean Squared Error:     0.3217617154875268\n",
      "Correlation Coeff:      8.336890029200232e-16\n",
      "Coeff of Determination: -0.00021425009209852242\n",
      "\n",
      "Fold 9\n",
      "Mean Squared Error:     0.32472908461336947\n",
      "Correlation Coeff:      -3.1928540353426044e-16\n",
      "Coeff of Determination: -0.001842176289200248\n",
      "\n",
      "Fold 10\n",
      "Mean Squared Error:     0.3328120338678832\n",
      "Correlation Coeff:      -6.747111358159029e-16\n",
      "Coeff of Determination: -0.001925762641473927\n",
      "\n",
      "Mean Coeff of Determination: -0.0026000906150087876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " -0.0006586720382191213\n",
       " -0.004450009510445607\n",
       " -0.002874859612382652\n",
       " -0.009594212084622633\n",
       " -0.00017166663586998254\n",
       " -0.000945402696214348\n",
       " -0.003323894549560835\n",
       " -0.00021425009209852242\n",
       " -0.001842176289200248\n",
       " -0.001925762641473927"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = nfoldCV_tree( Y_train[!,1], model_X_basic_train, 10, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 2\n",
       "Depth:  1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_tree(Y_train[!,1], model_X_basic_train, 13, 1, 162)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision Tree\n",
       "Leaves: 602\n",
       "Depth:  32"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_tree(Y_train[!,1], model_X_basic_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/bensadeghi/DecisionTree.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04206,
     "end_time": "2021-02-13T18:19:51.353816",
     "exception": false,
     "start_time": "2021-02-13T18:19:51.311756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is worth to notice that lasso regression works better for the more complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041452,
     "end_time": "2021-02-13T18:19:51.436401",
     "exception": false,
     "start_time": "2021-02-13T18:19:51.394949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In contrast to a theoretical based choice of the tuning parameter $\\lambda$ in the lasso regression, we can also use cross-validation to determine the penalty level by applying the package *glmnet* and the function cv.glmnet. In this context, we also run a ridge and a elastic net regression by adjusting the parameter *alpha*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1288-element Vector{Float64}:\n",
       " 3.8797387879840413\n",
       " 3.4466918895668868\n",
       " 2.7744241519741353\n",
       " 2.8442338500469626\n",
       " 2.3022926400689454\n",
       " 3.356590786133148\n",
       " 2.6831266710083246\n",
       " 2.860480535296299\n",
       " 2.5554762680365153\n",
       " 2.546646546243107\n",
       " 3.159244114454792\n",
       " 2.8116993655910383\n",
       " 2.8528396571436785\n",
       " ⋮\n",
       " 3.640692598055447\n",
       " 3.3942764208302636\n",
       " 3.267956521158524\n",
       " 2.6341389458042337\n",
       " 3.419478066830038\n",
       " 3.183170231815611\n",
       " 3.0419428098749615\n",
       " 3.0443948152073177\n",
       " 2.963615200701442\n",
       " 2.8381624487853214\n",
       " 2.816136514212979\n",
       " 3.4167706291202258"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_tree = apply_tree(model, model_X_basic_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 using Prune - tree:0.053541698873348254"
     ]
    }
   ],
   "source": [
    "res_tree = ( Y_test[!,1] - y_hat_tree ) .^ 2\n",
    "mean_residuals = lm(  matrix_ones, res_tree )\n",
    "MSE_tree = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "\n",
    "R2_tree = ( 1 .- ( MSE_tree[1] / var( Y_test[!,1] ) ) )[1]\n",
    "\n",
    "print(\"R^2 using Prune - tree:\", R2_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052287,
     "end_time": "2021-02-13T18:20:11.566330",
     "exception": false,
     "start_time": "2021-02-13T18:20:11.514043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Random Forest and Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050794,
     "end_time": "2021-02-13T18:20:11.667980",
     "exception": false,
     "start_time": "2021-02-13T18:20:11.617186",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the next step, we apply the more advanced tree-based methods random forest and boosted trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor\n",
       "n_trees:             500\n",
       "n_subfeatures:       52\n",
       "partial_sampling:    0.7\n",
       "max_depth:           -1\n",
       "min_samples_leaf:    5\n",
       "min_samples_split:   2\n",
       "min_purity_increase: 0.0\n",
       "ensemble:            Ensemble of Decision Trees\n",
       "Trees:      500\n",
       "Avg Leaves: 411.184\n",
       "Avg Depth:  26.946"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_trees = 500, n_subfeatures = p_basic, min_samples_leaf = 5, rng =0)\n",
    "rf_fit = ScikitLearn.fit!(rf, model_X_basic_train, Y_train[!,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 using Random Forest:0.24789411290764862"
     ]
    }
   ],
   "source": [
    "y_hat_rf = ScikitLearn.predict(rf_fit, model_X_basic_test)\n",
    "#y_hat_boost = ScikitLearn.predict(rf_fit, model_X_basic_test)\n",
    "\n",
    "res_rf = ( Y_test[!,1] - y_hat_rf ) .^ 2\n",
    "mean_residuals = lm(  matrix_ones, res_rf )\n",
    "MSE_rf = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_rf = ( 1 .- ( MSE_rf[1] / var( Y_test[!,1] ) ) )[1]\n",
    "\n",
    "print(\"R^2 using Random Forest:\", R2_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3,862 rows × 53 columns (omitted printing of 44 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>x1</th><th>x2</th><th>x3</th><th>x4</th><th>x5</th><th>x6</th><th>x7</th><th>x8</th><th>x9</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>2.7052</td><td>1.0</td><td>1.0</td><td>9.0</td><td>0.81</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>2</th><td>4.33083</td><td>1.0</td><td>1.0</td><td>14.0</td><td>1.96</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>3.4012</td><td>1.0</td><td>1.0</td><td>16.0</td><td>2.56</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>4</th><td>3.09627</td><td>1.0</td><td>0.0</td><td>3.0</td><td>0.09</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>3.69314</td><td>1.0</td><td>1.0</td><td>31.0</td><td>9.61</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>6</th><td>3.21568</td><td>1.0</td><td>0.0</td><td>7.0</td><td>0.49</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>3.5443</td><td>1.0</td><td>0.0</td><td>26.5</td><td>7.0225</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>8</th><td>2.59984</td><td>1.0</td><td>1.0</td><td>34.0</td><td>11.56</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>1.97568</td><td>1.0</td><td>1.0</td><td>15.0</td><td>2.25</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>2.83873</td><td>1.0</td><td>0.0</td><td>22.0</td><td>4.84</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>2.26336</td><td>1.0</td><td>0.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>2.52573</td><td>1.0</td><td>1.0</td><td>39.0</td><td>15.21</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>2.5601</td><td>1.0</td><td>0.0</td><td>34.5</td><td>11.9025</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>14</th><td>2.35867</td><td>1.0</td><td>0.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>2.61558</td><td>1.0</td><td>0.0</td><td>26.0</td><td>6.76</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>2.78809</td><td>1.0</td><td>1.0</td><td>8.0</td><td>0.64</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>17</th><td>3.11778</td><td>1.0</td><td>0.0</td><td>21.0</td><td>4.41</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>18</th><td>3.36802</td><td>1.0</td><td>0.0</td><td>16.0</td><td>2.56</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>19</th><td>2.26336</td><td>1.0</td><td>0.0</td><td>20.0</td><td>4.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>3.8728</td><td>1.0</td><td>0.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>21</th><td>3.76744</td><td>1.0</td><td>0.0</td><td>18.0</td><td>3.24</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>22</th><td>2.66883</td><td>1.0</td><td>0.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>2.62004</td><td>1.0</td><td>1.0</td><td>4.0</td><td>0.16</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>24</th><td>2.10921</td><td>1.0</td><td>1.0</td><td>5.0</td><td>0.25</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>4.46059</td><td>1.0</td><td>0.0</td><td>12.0</td><td>1.44</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>3.6072</td><td>1.0</td><td>0.0</td><td>14.0</td><td>1.96</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>27</th><td>2.86908</td><td>1.0</td><td>0.0</td><td>20.0</td><td>4.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>28</th><td>2.99573</td><td>1.0</td><td>0.0</td><td>8.5</td><td>0.7225</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>29</th><td>3.27497</td><td>1.0</td><td>1.0</td><td>23.0</td><td>5.29</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>30</th><td>3.07429</td><td>1.0</td><td>1.0</td><td>6.0</td><td>0.36</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& x1 & x2 & x3 & x4 & x5 & x6 & x7 & x8 & x9 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 2.7052 & 1.0 & 1.0 & 9.0 & 0.81 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 4.33083 & 1.0 & 1.0 & 14.0 & 1.96 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 3.4012 & 1.0 & 1.0 & 16.0 & 2.56 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t4 & 3.09627 & 1.0 & 0.0 & 3.0 & 0.09 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 3.69314 & 1.0 & 1.0 & 31.0 & 9.61 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t6 & 3.21568 & 1.0 & 0.0 & 7.0 & 0.49 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 3.5443 & 1.0 & 0.0 & 26.5 & 7.0225 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 2.59984 & 1.0 & 1.0 & 34.0 & 11.56 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 1.97568 & 1.0 & 1.0 & 15.0 & 2.25 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 2.83873 & 1.0 & 0.0 & 22.0 & 4.84 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & 2.26336 & 1.0 & 0.0 & 10.0 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & 2.52573 & 1.0 & 1.0 & 39.0 & 15.21 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 2.5601 & 1.0 & 0.0 & 34.5 & 11.9025 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 2.35867 & 1.0 & 0.0 & 10.0 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 2.61558 & 1.0 & 0.0 & 26.0 & 6.76 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t16 & 2.78809 & 1.0 & 1.0 & 8.0 & 0.64 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t17 & 3.11778 & 1.0 & 0.0 & 21.0 & 4.41 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & 3.36802 & 1.0 & 0.0 & 16.0 & 2.56 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t19 & 2.26336 & 1.0 & 0.0 & 20.0 & 4.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 3.8728 & 1.0 & 0.0 & 10.0 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 3.76744 & 1.0 & 0.0 & 18.0 & 3.24 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t22 & 2.66883 & 1.0 & 0.0 & 10.0 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 2.62004 & 1.0 & 1.0 & 4.0 & 0.16 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t24 & 2.10921 & 1.0 & 1.0 & 5.0 & 0.25 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & 4.46059 & 1.0 & 0.0 & 12.0 & 1.44 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 3.6072 & 1.0 & 0.0 & 14.0 & 1.96 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & 2.86908 & 1.0 & 0.0 & 20.0 & 4.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t28 & 2.99573 & 1.0 & 0.0 & 8.5 & 0.7225 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 3.27497 & 1.0 & 1.0 & 23.0 & 5.29 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t30 & 3.07429 & 1.0 & 1.0 & 6.0 & 0.36 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3862×53 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m x1      \u001b[0m\u001b[1m x2      \u001b[0m\u001b[1m x3      \u001b[0m\u001b[1m x4      \u001b[0m\u001b[1m x5      \u001b[0m\u001b[1m x6      \u001b[0m\u001b[1m x7      \u001b[0m\u001b[1m x8     \u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │ 2.7052       1.0      1.0      9.0   0.81        0.0      0.0      1.0 ⋯\n",
       "    2 │ 4.33083      1.0      1.0     14.0   1.96        0.0      0.0      0.0\n",
       "    3 │ 3.4012       1.0      1.0     16.0   2.56        0.0      0.0      0.0\n",
       "    4 │ 3.09627      1.0      0.0      3.0   0.09        0.0      0.0      0.0\n",
       "    5 │ 3.69314      1.0      1.0     31.0   9.61        0.0      0.0      0.0 ⋯\n",
       "    6 │ 3.21568      1.0      0.0      7.0   0.49        0.0      0.0      0.0\n",
       "    7 │ 3.5443       1.0      0.0     26.5   7.0225      0.0      0.0      1.0\n",
       "    8 │ 2.59984      1.0      1.0     34.0  11.56        0.0      1.0      0.0\n",
       "    9 │ 1.97568      1.0      1.0     15.0   2.25        0.0      1.0      0.0 ⋯\n",
       "   10 │ 2.83873      1.0      0.0     22.0   4.84        0.0      1.0      0.0\n",
       "   11 │ 2.26336      1.0      0.0     10.0   1.0         0.0      1.0      0.0\n",
       "  ⋮   │    ⋮        ⋮        ⋮        ⋮        ⋮        ⋮        ⋮        ⋮    ⋱\n",
       " 3853 │ 3.17966      1.0      0.0      4.0   0.16        0.0      0.0      0.0\n",
       " 3854 │ 2.66883      1.0      1.0     10.0   1.0         0.0      0.0      0.0 ⋯\n",
       " 3855 │ 2.70805      1.0      0.0      3.0   0.09        0.0      0.0      0.0\n",
       " 3856 │ 2.48651      1.0      0.0     32.0  10.24        0.0      1.0      0.0\n",
       " 3857 │ 3.46734      1.0      1.0      3.0   0.09        0.0      0.0      0.0\n",
       " 3858 │ 2.70162      1.0      0.0     40.0  16.0         0.0      1.0      0.0 ⋯\n",
       " 3859 │ 2.66883      1.0      1.0     34.0  11.56        0.0      0.0      0.0\n",
       " 3860 │ 3.17966      1.0      1.0     16.5   2.7225      0.0      0.0      1.0\n",
       " 3861 │ 2.50453      1.0      0.0      5.0   0.25        0.0      0.0      0.0\n",
       " 3862 │ 2.87313      1.0      0.0      3.0   0.09        0.0      0.0      0.0 ⋯\n",
       "\u001b[36m                                                45 columns and 3841 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DataFrame(hcat(Y_train[!,1], model_X_basic_train), :auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051225,
     "end_time": "2021-02-13T18:21:08.500313",
     "exception": false,
     "start_time": "2021-02-13T18:21:08.449088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To conclude, let us have a look at our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052403,
     "end_time": "2021-02-13T18:21:08.603976",
     "exception": false,
     "start_time": "2021-02-13T18:21:08.551573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<meta charset=\"UTF-8\">\n",
       "<style>\n",
       "  table, td, th {\n",
       "      border-collapse: collapse;\n",
       "      font-family: sans-serif;\n",
       "  }\n",
       "\n",
       "  td, th {\n",
       "      border-bottom: 0;\n",
       "      padding: 4px\n",
       "  }\n",
       "\n",
       "  tr:nth-child(odd) {\n",
       "      background: #eee;\n",
       "  }\n",
       "\n",
       "  tr:nth-child(even) {\n",
       "      background: #fff;\n",
       "  }\n",
       "\n",
       "  tr.header {\n",
       "      background: navy !important;\n",
       "      color: white;\n",
       "      font-weight: bold;\n",
       "  }\n",
       "\n",
       "  tr.subheader {\n",
       "      background: lightgray !important;\n",
       "      color: black;\n",
       "  }\n",
       "\n",
       "  tr.headerLastRow {\n",
       "      border-bottom: 2px solid black;\n",
       "  }\n",
       "\n",
       "  th.rowNumber, td.rowNumber {\n",
       "      text-align: right;\n",
       "  }\n",
       "\n",
       "</style>\n",
       "<body>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr class = \"header headerLastRow\">\n",
       "      <th style = \"text-align: center;\">Model</th>\n",
       "      <th style = \"text-align: center;\">MSE</th>\n",
       "      <th style = \"text-align: center;\">S.E. for MSE</th>\n",
       "      <th style = \"text-align: center;\">R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Least Squares (basic)</td>\n",
       "      <td style = \"text-align: center;\">0.2378</td>\n",
       "      <td style = \"text-align: center;\">0.0151</td>\n",
       "      <td style = \"text-align: center;\">0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Least Squares (flexible)</td>\n",
       "      <td style = \"text-align: center;\">0.2513</td>\n",
       "      <td style = \"text-align: center;\">0.0148</td>\n",
       "      <td style = \"text-align: center;\">0.2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Lasso</td>\n",
       "      <td style = \"text-align: center;\">0.2661</td>\n",
       "      <td style = \"text-align: center;\">0.0147</td>\n",
       "      <td style = \"text-align: center;\">0.1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Post-Lasso</td>\n",
       "      <td style = \"text-align: center;\">0.2491</td>\n",
       "      <td style = \"text-align: center;\">0.014</td>\n",
       "      <td style = \"text-align: center;\">0.2195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Lasso (flexible)</td>\n",
       "      <td style = \"text-align: center;\">0.2703</td>\n",
       "      <td style = \"text-align: center;\">0.0148</td>\n",
       "      <td style = \"text-align: center;\">0.1532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Post-Lasso (flexible)</td>\n",
       "      <td style = \"text-align: center;\">0.2522</td>\n",
       "      <td style = \"text-align: center;\">0.0147</td>\n",
       "      <td style = \"text-align: center;\">0.2097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Cross-Validated lasso</td>\n",
       "      <td style = \"text-align: center;\">0.2376</td>\n",
       "      <td style = \"text-align: center;\">0.015</td>\n",
       "      <td style = \"text-align: center;\">0.2555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Cross-Validated ridge</td>\n",
       "      <td style = \"text-align: center;\">0.2359</td>\n",
       "      <td style = \"text-align: center;\">0.015</td>\n",
       "      <td style = \"text-align: center;\">0.2608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Cross-Validated elnet</td>\n",
       "      <td style = \"text-align: center;\">0.2376</td>\n",
       "      <td style = \"text-align: center;\">0.015</td>\n",
       "      <td style = \"text-align: center;\">0.2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Cross-Validated lasso (flexible)</td>\n",
       "      <td style = \"text-align: center;\">0.2355</td>\n",
       "      <td style = \"text-align: center;\">0.015</td>\n",
       "      <td style = \"text-align: center;\">0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Cross-Validated ridge (flexible)</td>\n",
       "      <td style = \"text-align: center;\">0.2402</td>\n",
       "      <td style = \"text-align: center;\">0.015</td>\n",
       "      <td style = \"text-align: center;\">0.2474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Cross-Validated elnet (flexible)</td>\n",
       "      <td style = \"text-align: center;\">0.2356</td>\n",
       "      <td style = \"text-align: center;\">0.015</td>\n",
       "      <td style = \"text-align: center;\">0.2618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Pruned Tree</td>\n",
       "      <td style = \"text-align: center;\">0.4464</td>\n",
       "      <td style = \"text-align: center;\">0.025</td>\n",
       "      <td style = \"text-align: center;\">-0.3988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Random Forest</td>\n",
       "      <td style = \"text-align: center;\">0.24</td>\n",
       "      <td style = \"text-align: center;\">0.0135</td>\n",
       "      <td style = \"text-align: center;\">0.2479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Boosted Trees</td>\n",
       "      <td style = \"text-align: center;\">0.0</td>\n",
       "      <td style = \"text-align: center;\">0.0</td>\n",
       "      <td style = \"text-align: center;\">0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</body>\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = NamedArray(zeros(15, 4))\n",
    "\n",
    "table[1,2:3] = [MSE_lm_basic[1][1], MSE_lm_basic[2][1]]\n",
    "table[2,2:3] = [MSE_lm_flex[1][1], MSE_lm_flex[2][1]]\n",
    "table[3,2:3] = [MSE_rlasso_basic[1][1], MSE_rlasso_basic[2][1]]\n",
    "table[4,2:3] = [MSE_rlasso_basic_post[1][1], MSE_rlasso_basic_post[2][1]]\n",
    "table[5,2:3] = [MSE_rlasso_flex[1][1], MSE_rlasso_flex[2][1]]\n",
    "table[6,2:3] = [MSE_rlasso_flex_post[1][1], MSE_rlasso_flex_post[2][1]]\n",
    "table[7,2:3] = [MSE_lasso_cv[1][1], MSE_lasso_cv[2][1]]\n",
    "table[8,2:3] = [MSE_ridge[1][1], MSE_ridge[2][1]]\n",
    "table[9,2:3] = [MSE_elnet[1][1], MSE_elnet[2][1]]\n",
    "table[10,2:3] = [MSE_lasso_cv_flex[1][1], MSE_lasso_cv_flex[2][1]]\n",
    "table[11,2:3] = [MSE_ridge_flex[1][1], MSE_ridge_flex[2][1]]\n",
    "table[12,2:3] = [MSE_elnet_flex[1][1], MSE_elnet_flex[2][1]]\n",
    "table[13,2:3] = [MSE_prune_tree[1][1], MSE_prune_tree[2][1]]\n",
    "table[14,2:3] = [MSE_rf[1][1], MSE_rf[2][1]]\n",
    "#table[15,2:3] = [0,0]\n",
    "\n",
    "table[1,4] = R2_lm_basic[1]\n",
    "table[2,4] = R2_lm_flex[1]\n",
    "table[3,4] = R2_rlasso_basic[1]\n",
    "table[4,4] = R2_rlasso_basic_post[1]\n",
    "table[5,4] = R2_rlasso_flex[1]\n",
    "table[6,4] = R2_rlasso_flex_post[1]\n",
    "table[7,4] = R2_lasso_cv[1]\n",
    "table[8,4] = R2_ridge[1]\n",
    "table[9,4] = R2_elnet[1]\n",
    "table[10,4] = R2_lasso_cv_flex[1]\n",
    "table[11,4] = R2_ridge_flex[1]\n",
    "table[12,4] = R2_elnet_flex[1]\n",
    "table[13,4] = R2_prune_tree[1]\n",
    "table[14,4] = R2_rf[1]\n",
    "#table[15,4] = 0\n",
    "\n",
    "T = DataFrame(table, [ :\"Model\",:\"MSE\", :\"S.E. for MSE\", :\"R-squared\"]) \n",
    "T[!,:Model] = string.(T[!,:Model]) \n",
    "\n",
    "T[1,1] = \"Least Squares (basic)\"\n",
    "T[2,1] = \"Least Squares (flexible)\"\n",
    "T[3,1] = \"Lasso\"\n",
    "T[4,1] = \"Post-Lasso\"\n",
    "T[5,1] = \"Lasso (flexible)\"\n",
    "T[6,1] = \"Post-Lasso (flexible)\"\n",
    "T[7,1] = \"Cross-Validated lasso\"\n",
    "T[8,1] = \"Cross-Validated ridge\"\n",
    "T[9,1] = \"Cross-Validated elnet\"\n",
    "T[10,1] = \"Cross-Validated lasso (flexible)\"\n",
    "T[11,1] = \"Cross-Validated ridge (flexible)\"\n",
    "T[12,1] = \"Cross-Validated elnet (flexible)\"\n",
    "T[13,1] = \"Pruned Tree\"\n",
    "T[14,1] = \"Random Forest\"\n",
    "T[15,1] = \"Boosted Trees\"\n",
    "\n",
    "header = ([\"Model\", \"MSE\", \"S.E. for MSE\", \"R-squared\"])\n",
    "\n",
    "pretty_table(T; backend = Val(:html), header = header, formatters=ft_round(4), alignment=:c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052897,
     "end_time": "2021-02-13T18:21:08.930888",
     "exception": false,
     "start_time": "2021-02-13T18:21:08.877991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Above, we displayed the results for a single split of data into the training and testing part. The table shows the test MSE in column 1 as well as the standard error in column 2 and the test $R^2$\n",
    "in column 3. We see that the prediction rule produced by Elastic Net using the flexible model performs the best here, giving the lowest test MSE. Cross-Validated Lasso and Ridge, perform nearly as well. For any two of these methods, their testing MSEs are within one standard error of each other. Remarkably, OLS on a simple model performs extremely well, almost as well as best tree based method Random Forest. On the other hand, OLS on a flexible model with many regressors performs very poorly giving the highest test MSE. It is worth to notice that the nonlinear models, e.g. Random Forest, are not tuned. Thus, there is a lot of potential to improve the performance of the nonlinear methods we used in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052594,
     "end_time": "2021-02-13T18:21:09.036009",
     "exception": false,
     "start_time": "2021-02-13T18:21:08.983415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.053134,
     "end_time": "2021-02-13T18:21:09.146558",
     "exception": false,
     "start_time": "2021-02-13T18:21:09.093424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the final step, we can build a prediction model by combing the strengths of the models we considered so far. This ensemble method is of the form\n",
    "\t$$ f(x) = \\sum_{k=1}^K \\alpha_k f_k(x) $$\n",
    "where the $f_k$'s denote our prediction rules from the table above and the $\\alpha_k$'s are the corresponding weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.053696,
     "end_time": "2021-02-13T18:21:09.254342",
     "exception": false,
     "start_time": "2021-02-13T18:21:09.200646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We focus on the prediction rules based on OLS, Post-Lasso, Elastic Net, Pruned Tree, Random Forest, Boosted Trees, and Neural Network and combine these methods into an ensemble method. The weights can be determined by a simple ols regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.054822,
     "end_time": "2021-02-13T18:21:09.498067",
     "exception": false,
     "start_time": "2021-02-13T18:21:09.443245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Alternatively, we can determine the weights via lasso regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>1,288 rows × 6 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>Y_test</th><th>yhat_lm_basic</th><th>yhat_rlasso_flex_post</th><th>yhat_elnet_flex</th><th>y_hat_rf</th><th>y_hat_pt</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>2.63493</td><td>3.86638</td><td>3.34819</td><td>3.76754</td><td>3.62113</td><td>4.60517</td></tr><tr><th>2</th><td>2.95651</td><td>2.75627</td><td>2.97851</td><td>3.44927</td><td>3.01505</td><td>2.70442</td></tr><tr><th>3</th><td>2.48651</td><td>2.67269</td><td>2.45364</td><td>2.63565</td><td>2.6978</td><td>2.48651</td></tr><tr><th>4</th><td>3.07269</td><td>2.97464</td><td>2.94083</td><td>3.01012</td><td>3.0009</td><td>3.5925</td></tr><tr><th>5</th><td>2.44569</td><td>2.52969</td><td>2.57542</td><td>2.52012</td><td>2.50731</td><td>2.4436</td></tr><tr><th>6</th><td>2.87855</td><td>3.12336</td><td>3.01731</td><td>3.05738</td><td>3.21051</td><td>3.34207</td></tr><tr><th>7</th><td>2.48491</td><td>2.80696</td><td>2.91624</td><td>2.83661</td><td>2.63065</td><td>2.66883</td></tr><tr><th>8</th><td>2.97911</td><td>3.4356</td><td>3.41703</td><td>3.46876</td><td>3.2742</td><td>2.48651</td></tr><tr><th>9</th><td>1.90669</td><td>2.54276</td><td>2.471</td><td>2.52212</td><td>2.70799</td><td>2.158</td></tr><tr><th>10</th><td>2.64066</td><td>2.62608</td><td>2.61309</td><td>2.61003</td><td>2.5933</td><td>2.09631</td></tr><tr><th>11</th><td>2.73337</td><td>2.86539</td><td>3.0134</td><td>2.89925</td><td>2.98295</td><td>3.17966</td></tr><tr><th>12</th><td>2.95651</td><td>2.67039</td><td>2.6936</td><td>2.75625</td><td>2.9887</td><td>3.22288</td></tr><tr><th>13</th><td>2.75501</td><td>2.70082</td><td>2.73517</td><td>2.73713</td><td>2.83155</td><td>2.76414</td></tr><tr><th>14</th><td>3.14991</td><td>3.74454</td><td>3.46678</td><td>3.67887</td><td>3.47561</td><td>3.66116</td></tr><tr><th>15</th><td>3.11778</td><td>3.14683</td><td>3.35718</td><td>3.31877</td><td>3.2337</td><td>3.80023</td></tr><tr><th>16</th><td>3.36198</td><td>2.95351</td><td>2.98921</td><td>2.9642</td><td>2.90368</td><td>2.95651</td></tr><tr><th>17</th><td>2.83873</td><td>3.18299</td><td>2.99996</td><td>3.06392</td><td>2.89445</td><td>3.06506</td></tr><tr><th>18</th><td>2.93119</td><td>2.81313</td><td>3.13075</td><td>2.82792</td><td>2.74197</td><td>2.87313</td></tr><tr><th>19</th><td>3.16681</td><td>2.91843</td><td>2.87632</td><td>2.86517</td><td>2.83799</td><td>3.00105</td></tr><tr><th>20</th><td>3.07429</td><td>3.22587</td><td>3.29334</td><td>3.24497</td><td>3.52638</td><td>3.07429</td></tr><tr><th>21</th><td>2.87195</td><td>3.12605</td><td>3.20554</td><td>3.47733</td><td>3.23148</td><td>3.53188</td></tr><tr><th>22</th><td>3.08434</td><td>3.11892</td><td>2.81988</td><td>2.9953</td><td>2.84203</td><td>3.06506</td></tr><tr><th>23</th><td>3.17966</td><td>3.16905</td><td>3.4951</td><td>3.33721</td><td>3.26523</td><td>3.04941</td></tr><tr><th>24</th><td>2.48651</td><td>2.72959</td><td>2.63569</td><td>2.82648</td><td>3.01117</td><td>2.80991</td></tr><tr><th>25</th><td>2.38077</td><td>2.80628</td><td>2.58862</td><td>2.75213</td><td>2.72097</td><td>2.26336</td></tr><tr><th>26</th><td>3.06984</td><td>3.25769</td><td>3.25457</td><td>3.31657</td><td>3.31314</td><td>3.36198</td></tr><tr><th>27</th><td>2.73337</td><td>2.94037</td><td>3.04252</td><td>2.93815</td><td>2.78307</td><td>2.59987</td></tr><tr><th>28</th><td>2.48651</td><td>2.9246</td><td>2.95942</td><td>3.16821</td><td>3.07665</td><td>2.95651</td></tr><tr><th>29</th><td>2.29154</td><td>2.8622</td><td>2.85213</td><td>2.8372</td><td>2.77308</td><td>2.73337</td></tr><tr><th>30</th><td>2.57922</td><td>2.2707</td><td>2.30387</td><td>2.30164</td><td>2.61577</td><td>2.35867</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& Y\\_test & yhat\\_lm\\_basic & yhat\\_rlasso\\_flex\\_post & yhat\\_elnet\\_flex & y\\_hat\\_rf & y\\_hat\\_pt\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64? & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2.63493 & 3.86638 & 3.34819 & 3.76754 & 3.62113 & 4.60517 \\\\\n",
       "\t2 & 2.95651 & 2.75627 & 2.97851 & 3.44927 & 3.01505 & 2.70442 \\\\\n",
       "\t3 & 2.48651 & 2.67269 & 2.45364 & 2.63565 & 2.6978 & 2.48651 \\\\\n",
       "\t4 & 3.07269 & 2.97464 & 2.94083 & 3.01012 & 3.0009 & 3.5925 \\\\\n",
       "\t5 & 2.44569 & 2.52969 & 2.57542 & 2.52012 & 2.50731 & 2.4436 \\\\\n",
       "\t6 & 2.87855 & 3.12336 & 3.01731 & 3.05738 & 3.21051 & 3.34207 \\\\\n",
       "\t7 & 2.48491 & 2.80696 & 2.91624 & 2.83661 & 2.63065 & 2.66883 \\\\\n",
       "\t8 & 2.97911 & 3.4356 & 3.41703 & 3.46876 & 3.2742 & 2.48651 \\\\\n",
       "\t9 & 1.90669 & 2.54276 & 2.471 & 2.52212 & 2.70799 & 2.158 \\\\\n",
       "\t10 & 2.64066 & 2.62608 & 2.61309 & 2.61003 & 2.5933 & 2.09631 \\\\\n",
       "\t11 & 2.73337 & 2.86539 & 3.0134 & 2.89925 & 2.98295 & 3.17966 \\\\\n",
       "\t12 & 2.95651 & 2.67039 & 2.6936 & 2.75625 & 2.9887 & 3.22288 \\\\\n",
       "\t13 & 2.75501 & 2.70082 & 2.73517 & 2.73713 & 2.83155 & 2.76414 \\\\\n",
       "\t14 & 3.14991 & 3.74454 & 3.46678 & 3.67887 & 3.47561 & 3.66116 \\\\\n",
       "\t15 & 3.11778 & 3.14683 & 3.35718 & 3.31877 & 3.2337 & 3.80023 \\\\\n",
       "\t16 & 3.36198 & 2.95351 & 2.98921 & 2.9642 & 2.90368 & 2.95651 \\\\\n",
       "\t17 & 2.83873 & 3.18299 & 2.99996 & 3.06392 & 2.89445 & 3.06506 \\\\\n",
       "\t18 & 2.93119 & 2.81313 & 3.13075 & 2.82792 & 2.74197 & 2.87313 \\\\\n",
       "\t19 & 3.16681 & 2.91843 & 2.87632 & 2.86517 & 2.83799 & 3.00105 \\\\\n",
       "\t20 & 3.07429 & 3.22587 & 3.29334 & 3.24497 & 3.52638 & 3.07429 \\\\\n",
       "\t21 & 2.87195 & 3.12605 & 3.20554 & 3.47733 & 3.23148 & 3.53188 \\\\\n",
       "\t22 & 3.08434 & 3.11892 & 2.81988 & 2.9953 & 2.84203 & 3.06506 \\\\\n",
       "\t23 & 3.17966 & 3.16905 & 3.4951 & 3.33721 & 3.26523 & 3.04941 \\\\\n",
       "\t24 & 2.48651 & 2.72959 & 2.63569 & 2.82648 & 3.01117 & 2.80991 \\\\\n",
       "\t25 & 2.38077 & 2.80628 & 2.58862 & 2.75213 & 2.72097 & 2.26336 \\\\\n",
       "\t26 & 3.06984 & 3.25769 & 3.25457 & 3.31657 & 3.31314 & 3.36198 \\\\\n",
       "\t27 & 2.73337 & 2.94037 & 3.04252 & 2.93815 & 2.78307 & 2.59987 \\\\\n",
       "\t28 & 2.48651 & 2.9246 & 2.95942 & 3.16821 & 3.07665 & 2.95651 \\\\\n",
       "\t29 & 2.29154 & 2.8622 & 2.85213 & 2.8372 & 2.77308 & 2.73337 \\\\\n",
       "\t30 & 2.57922 & 2.2707 & 2.30387 & 2.30164 & 2.61577 & 2.35867 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1288×6 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m Y_test  \u001b[0m\u001b[1m yhat_lm_basic \u001b[0m\u001b[1m yhat_rlasso_flex_post \u001b[0m\u001b[1m yhat_elnet_flex \u001b[0m\u001b[1m y_hat_\u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64?      \u001b[0m\u001b[90m Float64               \u001b[0m\u001b[90m Float64         \u001b[0m\u001b[90m Float6\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │ 2.63493        3.86638                3.34819          3.76754   3.621 ⋯\n",
       "    2 │ 2.95651        2.75627                2.97851          3.44927   3.015\n",
       "    3 │ 2.48651        2.67269                2.45364          2.63565   2.697\n",
       "    4 │ 3.07269        2.97464                2.94083          3.01012   3.000\n",
       "    5 │ 2.44569        2.52969                2.57542          2.52012   2.507 ⋯\n",
       "    6 │ 2.87855        3.12336                3.01731          3.05738   3.210\n",
       "    7 │ 2.48491        2.80696                2.91624          2.83661   2.630\n",
       "    8 │ 2.97911        3.4356                 3.41703          3.46876   3.274\n",
       "    9 │ 1.90669        2.54276                2.471            2.52212   2.707 ⋯\n",
       "   10 │ 2.64066        2.62608                2.61309          2.61003   2.593\n",
       "   11 │ 2.73337        2.86539                3.0134           2.89925   2.982\n",
       "  ⋮   │    ⋮           ⋮                  ⋮                   ⋮            ⋮   ⋱\n",
       " 1279 │ 2.50453        3.31284                3.18348          3.27626   3.334\n",
       " 1280 │ 2.76414        3.06513                2.95362          3.022     2.803 ⋯\n",
       " 1281 │ 3.36198        3.22815                3.24233          3.2579    3.276\n",
       " 1282 │ 2.48651        2.85762                2.92501          2.88139   2.772\n",
       " 1283 │ 2.56347        2.87624                3.09921          2.91369   2.994\n",
       " 1284 │ 2.9812         3.0344                 2.99315          3.02559   3.031 ⋯\n",
       " 1285 │ 3.81874        3.19519                3.27449          3.16278   3.172\n",
       " 1286 │ 2.62801        3.32902                3.23453          3.33376   3.061\n",
       " 1287 │ 3.13883        2.45282                2.54546          2.46377   2.522\n",
       " 1288 │ 2.85115        3.5738                 3.22162          3.53775   3.791 ⋯\n",
       "\u001b[36m                                                 2 columns and 1267 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLS \n",
    "columns = Any[Y_test[!,1], yhat_lm_basic, yhat_rlasso_flex_post, yhat_elnet_flex, y_hat_rf, y_hat_pt]\n",
    "\n",
    "data_ensemble = DataFrame(columns, [:Y_test, :yhat_lm_basic, :yhat_rlasso_flex_post,\n",
    "                            :yhat_elnet_flex, :y_hat_rf, :y_hat_pt]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Vector{Float64}:\n",
       " -0.015931874550676385\n",
       "  0.27051493674737964\n",
       "  0.15662449221785998\n",
       "  0.18951915506222738\n",
       "  0.3353442569788442\n",
       "  0.041983459746318695"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_ols = lm( @formula(Y_test ~ yhat_lm_basic + yhat_rlasso_flex_post + yhat_elnet_flex+ y_hat_rf +y_hat_pt), data_ensemble ) \n",
    "\n",
    "GLM.coeftable(ensemble_ols).cols[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>6 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>x1</th><th>x2</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>Intercept</td><td>-0.0390474</td></tr><tr><th>2</th><td>yhat_lm_basic</td><td>0.26759</td></tr><tr><th>3</th><td>yhat_rlasso_flex_post</td><td>0.157965</td></tr><tr><th>4</th><td>yhat_elnet_flex</td><td>0.180986</td></tr><tr><th>5</th><td>y_hat_rf</td><td>0.394802</td></tr><tr><th>6</th><td>y_hat_pt</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& x1 & x2\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & Intercept & -0.0390474 \\\\\n",
       "\t2 & yhat\\_lm\\_basic & 0.26759 \\\\\n",
       "\t3 & yhat\\_rlasso\\_flex\\_post & 0.157965 \\\\\n",
       "\t4 & yhat\\_elnet\\_flex & 0.180986 \\\\\n",
       "\t5 & y\\_hat\\_rf & 0.394802 \\\\\n",
       "\t6 & y\\_hat\\_pt & 0.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m6×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m x1                    \u001b[0m\u001b[1m x2         \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String                \u001b[0m\u001b[90m Float64    \u001b[0m\n",
       "─────┼───────────────────────────────────\n",
       "   1 │ Intercept              -0.0390474\n",
       "   2 │ yhat_lm_basic           0.26759\n",
       "   3 │ yhat_rlasso_flex_post   0.157965\n",
       "   4 │ yhat_elnet_flex         0.180986\n",
       "   5 │ y_hat_rf                0.394802\n",
       "   6 │ y_hat_pt                0.0"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso - HDM \n",
    "\n",
    "ensemble_lasso_hdm  = rlasso_arg( data_ensemble[!,2:end], Y_test, nothing, true, true, true, false, false, \n",
    "                    nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true )\n",
    "\n",
    "coef_ensemble_lasso_hdm = rlasso(ensemble_lasso_hdm)[\"coefficients\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<meta charset=\"UTF-8\">\n",
       "<style>\n",
       "  table, td, th {\n",
       "      border-collapse: collapse;\n",
       "      font-family: sans-serif;\n",
       "  }\n",
       "\n",
       "  td, th {\n",
       "      border-bottom: 0;\n",
       "      padding: 4px\n",
       "  }\n",
       "\n",
       "  tr:nth-child(odd) {\n",
       "      background: #eee;\n",
       "  }\n",
       "\n",
       "  tr:nth-child(even) {\n",
       "      background: #fff;\n",
       "  }\n",
       "\n",
       "  tr.header {\n",
       "      background: navy !important;\n",
       "      color: white;\n",
       "      font-weight: bold;\n",
       "  }\n",
       "\n",
       "  tr.subheader {\n",
       "      background: lightgray !important;\n",
       "      color: black;\n",
       "  }\n",
       "\n",
       "  tr.headerLastRow {\n",
       "      border-bottom: 2px solid black;\n",
       "  }\n",
       "\n",
       "  th.rowNumber, td.rowNumber {\n",
       "      text-align: right;\n",
       "  }\n",
       "\n",
       "</style>\n",
       "<body>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr class = \"header headerLastRow\">\n",
       "      <th style = \"text-align: center;\">Model</th>\n",
       "      <th style = \"text-align: center;\">Weight OLS</th>\n",
       "      <th style = \"text-align: center;\">Weight Lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Constant</td>\n",
       "      <td style = \"text-align: center;\">-0.0159</td>\n",
       "      <td style = \"text-align: center;\">-0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Least Squares (basic)</td>\n",
       "      <td style = \"text-align: center;\">0.2705</td>\n",
       "      <td style = \"text-align: center;\">0.2676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Post-Lasso (flexible)</td>\n",
       "      <td style = \"text-align: center;\">0.1566</td>\n",
       "      <td style = \"text-align: center;\">0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Cross-Validated elnet (flexible)</td>\n",
       "      <td style = \"text-align: center;\">0.1895</td>\n",
       "      <td style = \"text-align: center;\">0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Random Forest</td>\n",
       "      <td style = \"text-align: center;\">0.3353</td>\n",
       "      <td style = \"text-align: center;\">0.3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Prune tree</td>\n",
       "      <td style = \"text-align: center;\">0.042</td>\n",
       "      <td style = \"text-align: center;\">0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</body>\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HDM - Lasso \n",
    "table = NamedArray(zeros(6, 3))\n",
    "\n",
    "table[1:6,2] = GLM.coeftable(ensemble_ols).cols[1]\n",
    "table[1:6,3] = coef_ensemble_lasso_hdm[!,2]\n",
    "\n",
    "T = DataFrame(table, [ :\"Model\", :\"Weight OLS\",:\"Weight Lasso\"]) \n",
    "T[!,:Model] = string.(T[!,:Model]) \n",
    "\n",
    "T[1,1] = \"Constant\"\n",
    "T[2,1] = \"Least Squares (basic)\"\n",
    "T[3,1] = \"Post-Lasso (flexible)\"\n",
    "T[4,1] = \"Cross-Validated elnet (flexible)\"\n",
    "T[5,1] = \"Random Forest\"\n",
    "T[6,1] = \"Prune tree\"\n",
    "\n",
    "header = ([\"Model\", \"Weight OLS\", \"Weight Lasso\"])\n",
    "\n",
    "pretty_table(T; backend = Val(:html), header = header, formatters=ft_round(4), alignment=:c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.055874,
     "end_time": "2021-02-13T18:21:09.838636",
     "exception": false,
     "start_time": "2021-02-13T18:21:09.782762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The estimated weights are shown in the following table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056002,
     "end_time": "2021-02-13T18:21:10.101284",
     "exception": false,
     "start_time": "2021-02-13T18:21:10.045282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Further, the $R^2$ for the test sample gets improved from $30\\%$ obtained by OLS to about $31\\%$ obtained by the ensemble method. We see that it is very powerful to aggregate prediction rules into an ensemble rule. Nevertheless, it is worth to notice that we should compare the ensemble method and the single rules on an additional validation set to ensure a fair comparison."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
