{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Project.toml`\n",
      "  \u001b[90m[587475ba] \u001b[39m\u001b[92m+ Flux v0.16.5\u001b[39m\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "using Pkg\n",
    "\n",
    "# Install required packages\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"StatsModels\")\n",
    "Pkg.add(\"GLM\")\n",
    "Pkg.add(\"Random\")\n",
    "Pkg.add(\"MLDataUtils\")\n",
    "Pkg.add(\"MLBase\")\n",
    "Pkg.add(\"FixedEffectModels\")\n",
    "Pkg.add(\"Lasso\")\n",
    "Pkg.add(\"MLJ\")\n",
    "Pkg.add(\"DecisionTree\")\n",
    "Pkg.add(\"RData\")\n",
    "Pkg.add(\"GLMNet\")\n",
    "Pkg.add(\"PrettyTables\")\n",
    "Pkg.add(\"MLJScikitLearnInterface\")\n",
    "Pkg.add(\"MLJFlux\")\n",
    "Pkg.add(\"Flux\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, StatsModels, GLM, Random, MLDataUtils, MLBase, FixedEffectModels, Lasso, MLJ, DecisionTree, RData, GLMNet, PrettyTables, MLJScikitLearnInterface, MLJFlux, Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, StatsModels, GLM, Random, RData, MLBase, MLJ, PrettyTables, FixedEffectModels\n",
    "using MLDataUtils, FixedEffectModels, DecisionTree, Lasso, GLMNet, MLJScikitLearnInterface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debiased ML for Partially Linear Model in Julia\n",
    "\n",
    "This is a simple implementation of Debiased Machine Learning for the Partially Linear Regression Model.\n",
    "\n",
    "Reference: \n",
    "\n",
    "https://arxiv.org/abs/1608.00060\n",
    "\n",
    "\n",
    "https://www.amazon.com/Business-Data-Science-Combining-Accelerate/dp/1260452778\n",
    "\n",
    "The code is based on the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows : 90\n",
      "Number of Columns : 63\n"
     ]
    }
   ],
   "source": [
    "url = \"https://github.com/d2cml-ai/14.388_jl/raw/main/data/GrowthData.RData\"\n",
    "download(url, \"data.RData\")\n",
    "rdata_read = RData.load(\"data.RData\")\n",
    "data = rdata_read[\"GrowthData\"]\n",
    "names(data)\n",
    "println(\"Number of Rows : \", size(data)[1],\"\\n\",\"Number of Columns : \", size(data)[2],) #rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>90Ã—63 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">65 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Outcome</th><th style = \"text-align: left;\">intercept</th><th style = \"text-align: left;\">gdpsh465</th><th style = \"text-align: left;\">bmp1l</th><th style = \"text-align: left;\">freeop</th><th style = \"text-align: left;\">freetar</th><th style = \"text-align: left;\">h65</th><th style = \"text-align: left;\">hm65</th><th style = \"text-align: left;\">hf65</th><th style = \"text-align: left;\">p65</th><th style = \"text-align: left;\">pm65</th><th style = \"text-align: left;\">pf65</th><th style = \"text-align: left;\">s65</th><th style = \"text-align: left;\">sm65</th><th style = \"text-align: left;\">sf65</th><th style = \"text-align: left;\">fert65</th><th style = \"text-align: left;\">mort65</th><th style = \"text-align: left;\">lifee065</th><th style = \"text-align: left;\">gpop1</th><th style = \"text-align: left;\">fert1</th><th style = \"text-align: left;\">mort1</th><th style = \"text-align: left;\">invsh41</th><th style = \"text-align: left;\">geetot1</th><th style = \"text-align: left;\">geerec1</th><th style = \"text-align: left;\">gde1</th><th style = \"text-align: left;\">govwb1</th><th style = \"text-align: left;\">govsh41</th><th style = \"text-align: left;\">gvxdxe41</th><th style = \"text-align: left;\">high65</th><th style = \"text-align: left;\">highm65</th><th style = \"text-align: left;\">highf65</th><th style = \"text-align: left;\">highc65</th><th style = \"text-align: left;\">highcm65</th><th style = \"text-align: left;\">highcf65</th><th style = \"text-align: left;\">human65</th><th style = \"text-align: left;\">humanm65</th><th style = \"text-align: left;\">humanf65</th><th style = \"text-align: left;\">hyr65</th><th style = \"text-align: left;\">hyrm65</th><th style = \"text-align: left;\">hyrf65</th><th style = \"text-align: left;\">no65</th><th style = \"text-align: left;\">nom65</th><th style = \"text-align: left;\">nof65</th><th style = \"text-align: left;\">pinstab1</th><th style = \"text-align: left;\">pop65</th><th style = \"text-align: left;\">worker65</th><th style = \"text-align: left;\">pop1565</th><th style = \"text-align: left;\">pop6565</th><th style = \"text-align: left;\">sec65</th><th style = \"text-align: left;\">secm65</th><th style = \"text-align: left;\">secf65</th><th style = \"text-align: left;\">secc65</th><th style = \"text-align: left;\">seccm65</th><th style = \"text-align: left;\">seccf65</th><th style = \"text-align: left;\">syr65</th><th style = \"text-align: left;\">syrm65</th><th style = \"text-align: left;\">syrf65</th><th style = \"text-align: left;\">teapri65</th><th style = \"text-align: left;\">teasec65</th><th style = \"text-align: left;\">ex1</th><th style = \"text-align: left;\">im1</th><th style = \"text-align: left;\">xr65</th><th style = \"text-align: left;\">tot1</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int32\" style = \"text-align: left;\">Int32</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int32\" style = \"text-align: left;\">Int32</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">-0.0243358</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">6.59167</td><td style = \"text-align: right;\">0.2837</td><td style = \"text-align: right;\">0.153491</td><td style = \"text-align: right;\">0.043888</td><td style = \"text-align: right;\">0.007</td><td style = \"text-align: right;\">0.013</td><td style = \"text-align: right;\">0.001</td><td style = \"text-align: right;\">0.29</td><td style = \"text-align: right;\">0.37</td><td style = \"text-align: right;\">0.21</td><td style = \"text-align: right;\">0.04</td><td style = \"text-align: right;\">0.06</td><td style = \"text-align: right;\">0.02</td><td style = \"text-align: right;\">6.67</td><td style = \"text-align: right;\">0.16</td><td style = \"text-align: right;\">3.69387</td><td style = \"text-align: right;\">0.0203</td><td style = \"text-align: right;\">6.68</td><td style = \"text-align: right;\">0.165</td><td style = \"text-align: right;\">0.11898</td><td style = \"text-align: right;\">0.0195</td><td style = \"text-align: right;\">0.0176</td><td style = \"text-align: right;\">0.019</td><td style = \"text-align: right;\">0.0931</td><td style = \"text-align: right;\">0.1158</td><td style = \"text-align: right;\">0.07877</td><td style = \"text-align: right;\">0.12</td><td style = \"text-align: right;\">0.23</td><td style = \"text-align: right;\">0.01</td><td style = \"text-align: right;\">0.09</td><td style = \"text-align: right;\">0.18</td><td style = \"text-align: right;\">0.01</td><td style = \"text-align: right;\">0.301</td><td style = \"text-align: right;\">0.568</td><td style = \"text-align: right;\">0.043</td><td style = \"text-align: right;\">0.004</td><td style = \"text-align: right;\">0.008</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">89.46</td><td style = \"text-align: right;\">79.98</td><td style = \"text-align: right;\">98.61</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">12359</td><td style = \"text-align: right;\">0.3469</td><td style = \"text-align: right;\">0.4441</td><td style = \"text-align: right;\">0.0275912</td><td style = \"text-align: right;\">0.45</td><td style = \"text-align: right;\">0.75</td><td style = \"text-align: right;\">0.17</td><td style = \"text-align: right;\">0.13</td><td style = \"text-align: right;\">0.21</td><td style = \"text-align: right;\">0.04</td><td style = \"text-align: right;\">0.033</td><td style = \"text-align: right;\">0.057</td><td style = \"text-align: right;\">0.01</td><td style = \"text-align: right;\">47.6</td><td style = \"text-align: right;\">17.3</td><td style = \"text-align: right;\">0.0729</td><td style = \"text-align: right;\">0.0667</td><td style = \"text-align: right;\">0.348</td><td style = \"text-align: right;\">-0.014727</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">0.100473</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">6.82979</td><td style = \"text-align: right;\">0.6141</td><td style = \"text-align: right;\">0.313509</td><td style = \"text-align: right;\">0.061827</td><td style = \"text-align: right;\">0.019</td><td style = \"text-align: right;\">0.032</td><td style = \"text-align: right;\">0.007</td><td style = \"text-align: right;\">0.91</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.65</td><td style = \"text-align: right;\">0.16</td><td style = \"text-align: right;\">0.23</td><td style = \"text-align: right;\">0.09</td><td style = \"text-align: right;\">6.97</td><td style = \"text-align: right;\">0.145</td><td style = \"text-align: right;\">3.93378</td><td style = \"text-align: right;\">0.0185</td><td style = \"text-align: right;\">7.114</td><td style = \"text-align: right;\">0.154</td><td style = \"text-align: right;\">0.12048</td><td style = \"text-align: right;\">0.0556</td><td style = \"text-align: right;\">0.0369</td><td style = \"text-align: right;\">0.019</td><td style = \"text-align: right;\">0.1589</td><td style = \"text-align: right;\">0.156</td><td style = \"text-align: right;\">0.09999</td><td style = \"text-align: right;\">0.7</td><td style = \"text-align: right;\">1.18</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: right;\">0.63</td><td style = \"text-align: right;\">1.04</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: right;\">0.706</td><td style = \"text-align: right;\">1.138</td><td style = \"text-align: right;\">0.257</td><td style = \"text-align: right;\">0.027</td><td style = \"text-align: right;\">0.045</td><td style = \"text-align: right;\">0.008</td><td style = \"text-align: right;\">89.1</td><td style = \"text-align: right;\">82.35</td><td style = \"text-align: right;\">96.1</td><td style = \"text-align: right;\">0.02325</td><td style = \"text-align: right;\">4630</td><td style = \"text-align: right;\">0.2703</td><td style = \"text-align: right;\">0.4474</td><td style = \"text-align: right;\">0.0356371</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.74</td><td style = \"text-align: right;\">1.2</td><td style = \"text-align: right;\">1.36</td><td style = \"text-align: right;\">2.05</td><td style = \"text-align: right;\">0.64</td><td style = \"text-align: right;\">0.173</td><td style = \"text-align: right;\">0.274</td><td style = \"text-align: right;\">0.067</td><td style = \"text-align: right;\">57.1</td><td style = \"text-align: right;\">18.0</td><td style = \"text-align: right;\">0.094</td><td style = \"text-align: right;\">0.1438</td><td style = \"text-align: right;\">0.525</td><td style = \"text-align: right;\">0.00575</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">0.0670515</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">8.89508</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.204244</td><td style = \"text-align: right;\">0.009186</td><td style = \"text-align: right;\">0.26</td><td style = \"text-align: right;\">0.325</td><td style = \"text-align: right;\">0.201</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.56</td><td style = \"text-align: right;\">0.62</td><td style = \"text-align: right;\">0.51</td><td style = \"text-align: right;\">3.11</td><td style = \"text-align: right;\">0.024</td><td style = \"text-align: right;\">4.27388</td><td style = \"text-align: right;\">0.0188</td><td style = \"text-align: right;\">3.662</td><td style = \"text-align: right;\">0.027</td><td style = \"text-align: right;\">0.23098</td><td style = \"text-align: right;\">0.0465</td><td style = \"text-align: right;\">0.0365</td><td style = \"text-align: right;\">0.04</td><td style = \"text-align: right;\">0.1442</td><td style = \"text-align: right;\">0.1367</td><td style = \"text-align: right;\">0.06</td><td style = \"text-align: right;\">16.67</td><td style = \"text-align: right;\">17.95</td><td style = \"text-align: right;\">15.41</td><td style = \"text-align: right;\">4.5</td><td style = \"text-align: right;\">5.7</td><td style = \"text-align: right;\">3.31</td><td style = \"text-align: right;\">8.317</td><td style = \"text-align: right;\">8.249</td><td style = \"text-align: right;\">8.384</td><td style = \"text-align: right;\">0.424</td><td style = \"text-align: right;\">0.473</td><td style = \"text-align: right;\">0.375</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">19678</td><td style = \"text-align: right;\">0.3874</td><td style = \"text-align: right;\">0.3175</td><td style = \"text-align: right;\">0.0766846</td><td style = \"text-align: right;\">36.74</td><td style = \"text-align: right;\">33.5</td><td style = \"text-align: right;\">39.95</td><td style = \"text-align: right;\">15.68</td><td style = \"text-align: right;\">13.19</td><td style = \"text-align: right;\">18.14</td><td style = \"text-align: right;\">2.573</td><td style = \"text-align: right;\">2.478</td><td style = \"text-align: right;\">2.667</td><td style = \"text-align: right;\">26.5</td><td style = \"text-align: right;\">20.7</td><td style = \"text-align: right;\">0.1741</td><td style = \"text-align: right;\">0.175</td><td style = \"text-align: right;\">1.082</td><td style = \"text-align: right;\">-0.01004</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">0.0640892</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">7.56528</td><td style = \"text-align: right;\">0.1997</td><td style = \"text-align: right;\">0.248714</td><td style = \"text-align: right;\">0.03627</td><td style = \"text-align: right;\">0.061</td><td style = \"text-align: right;\">0.07</td><td style = \"text-align: right;\">0.051</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.24</td><td style = \"text-align: right;\">0.22</td><td style = \"text-align: right;\">0.31</td><td style = \"text-align: right;\">6.26</td><td style = \"text-align: right;\">0.072</td><td style = \"text-align: right;\">4.16821</td><td style = \"text-align: right;\">0.0345</td><td style = \"text-align: right;\">6.83</td><td style = \"text-align: right;\">0.085</td><td style = \"text-align: right;\">0.12928</td><td style = \"text-align: right;\">0.0375</td><td style = \"text-align: right;\">0.035</td><td style = \"text-align: right;\">0.011</td><td style = \"text-align: right;\">0.1165</td><td style = \"text-align: right;\">0.2018</td><td style = \"text-align: right;\">0.15616</td><td style = \"text-align: right;\">3.1</td><td style = \"text-align: right;\">3.4</td><td style = \"text-align: right;\">2.8</td><td style = \"text-align: right;\">2.11</td><td style = \"text-align: right;\">2.28</td><td style = \"text-align: right;\">1.95</td><td style = \"text-align: right;\">3.833</td><td style = \"text-align: right;\">3.86</td><td style = \"text-align: right;\">3.807</td><td style = \"text-align: right;\">0.104</td><td style = \"text-align: right;\">0.114</td><td style = \"text-align: right;\">0.095</td><td style = \"text-align: right;\">20.6</td><td style = \"text-align: right;\">20.6</td><td style = \"text-align: right;\">20.6</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1482</td><td style = \"text-align: right;\">0.3011</td><td style = \"text-align: right;\">0.4671</td><td style = \"text-align: right;\">0.0310391</td><td style = \"text-align: right;\">7.6</td><td style = \"text-align: right;\">7.5</td><td style = \"text-align: right;\">7.7</td><td style = \"text-align: right;\">2.76</td><td style = \"text-align: right;\">2.89</td><td style = \"text-align: right;\">2.63</td><td style = \"text-align: right;\">0.438</td><td style = \"text-align: right;\">0.453</td><td style = \"text-align: right;\">0.424</td><td style = \"text-align: right;\">27.8</td><td style = \"text-align: right;\">22.7</td><td style = \"text-align: right;\">0.1265</td><td style = \"text-align: right;\">0.1496</td><td style = \"text-align: right;\">6.625</td><td style = \"text-align: right;\">-0.002195</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">0.0279295</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">7.1624</td><td style = \"text-align: right;\">0.174</td><td style = \"text-align: right;\">0.299252</td><td style = \"text-align: right;\">0.037367</td><td style = \"text-align: right;\">0.017</td><td style = \"text-align: right;\">0.027</td><td style = \"text-align: right;\">0.007</td><td style = \"text-align: right;\">0.82</td><td style = \"text-align: right;\">0.85</td><td style = \"text-align: right;\">0.81</td><td style = \"text-align: right;\">0.17</td><td style = \"text-align: right;\">0.15</td><td style = \"text-align: right;\">0.13</td><td style = \"text-align: right;\">6.71</td><td style = \"text-align: right;\">0.12</td><td style = \"text-align: right;\">3.9982</td><td style = \"text-align: right;\">0.031</td><td style = \"text-align: right;\">6.816</td><td style = \"text-align: right;\">0.131</td><td style = \"text-align: right;\">0.07932</td><td style = \"text-align: right;\">0.0257</td><td style = \"text-align: right;\">0.0224</td><td style = \"text-align: right;\">0.012</td><td style = \"text-align: right;\">0.0971</td><td style = \"text-align: right;\">0.169</td><td style = \"text-align: right;\">0.13427</td><td style = \"text-align: right;\">0.67</td><td style = \"text-align: right;\">0.98</td><td style = \"text-align: right;\">0.36</td><td style = \"text-align: right;\">0.45</td><td style = \"text-align: right;\">0.66</td><td style = \"text-align: right;\">0.25</td><td style = \"text-align: right;\">1.9</td><td style = \"text-align: right;\">2.084</td><td style = \"text-align: right;\">1.72</td><td style = \"text-align: right;\">0.022</td><td style = \"text-align: right;\">0.033</td><td style = \"text-align: right;\">0.012</td><td style = \"text-align: right;\">58.73</td><td style = \"text-align: right;\">55.56</td><td style = \"text-align: right;\">61.82</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: right;\">3006</td><td style = \"text-align: right;\">0.3314</td><td style = \"text-align: right;\">0.4561</td><td style = \"text-align: right;\">0.0262808</td><td style = \"text-align: right;\">5.07</td><td style = \"text-align: right;\">5.37</td><td style = \"text-align: right;\">4.78</td><td style = \"text-align: right;\">2.17</td><td style = \"text-align: right;\">2.23</td><td style = \"text-align: right;\">2.11</td><td style = \"text-align: right;\">0.257</td><td style = \"text-align: right;\">0.287</td><td style = \"text-align: right;\">0.229</td><td style = \"text-align: right;\">34.5</td><td style = \"text-align: right;\">17.6</td><td style = \"text-align: right;\">0.1211</td><td style = \"text-align: right;\">0.1308</td><td style = \"text-align: right;\">2.5</td><td style = \"text-align: right;\">0.003283</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">0.0464074</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">7.21891</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.258865</td><td style = \"text-align: right;\">0.02088</td><td style = \"text-align: right;\">0.023</td><td style = \"text-align: right;\">0.038</td><td style = \"text-align: right;\">0.006</td><td style = \"text-align: right;\">0.5</td><td style = \"text-align: right;\">0.55</td><td style = \"text-align: right;\">0.5</td><td style = \"text-align: right;\">0.08</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">0.07</td><td style = \"text-align: right;\">6.7</td><td style = \"text-align: right;\">0.112</td><td style = \"text-align: right;\">3.88978</td><td style = \"text-align: right;\">0.0303</td><td style = \"text-align: right;\">6.83</td><td style = \"text-align: right;\">0.119</td><td style = \"text-align: right;\">0.07608</td><td style = \"text-align: right;\">0.0151</td><td style = \"text-align: right;\">0.0156</td><td style = \"text-align: right;\">0.009</td><td style = \"text-align: right;\">0.0713</td><td style = \"text-align: right;\">0.0734</td><td style = \"text-align: right;\">0.04899</td><td style = \"text-align: right;\">0.7</td><td style = \"text-align: right;\">1.09</td><td style = \"text-align: right;\">0.3</td><td style = \"text-align: right;\">0.48</td><td style = \"text-align: right;\">0.74</td><td style = \"text-align: right;\">0.21</td><td style = \"text-align: right;\">1.426</td><td style = \"text-align: right;\">1.622</td><td style = \"text-align: right;\">1.227</td><td style = \"text-align: right;\">0.024</td><td style = \"text-align: right;\">0.037</td><td style = \"text-align: right;\">0.01</td><td style = \"text-align: right;\">69.2</td><td style = \"text-align: right;\">64.27</td><td style = \"text-align: right;\">74.2</td><td style = \"text-align: right;\">0.4242</td><td style = \"text-align: right;\">4568</td><td style = \"text-align: right;\">0.3105</td><td style = \"text-align: right;\">0.4599</td><td style = \"text-align: right;\">0.0273643</td><td style = \"text-align: right;\">3.5</td><td style = \"text-align: right;\">3.6</td><td style = \"text-align: right;\">3.4</td><td style = \"text-align: right;\">1.02</td><td style = \"text-align: right;\">0.59</td><td style = \"text-align: right;\">1.46</td><td style = \"text-align: right;\">0.16</td><td style = \"text-align: right;\">0.174</td><td style = \"text-align: right;\">0.146</td><td style = \"text-align: right;\">34.3</td><td style = \"text-align: right;\">8.1</td><td style = \"text-align: right;\">0.0634</td><td style = \"text-align: right;\">0.0762</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">-0.001747</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">0.0673323</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">7.8536</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.182525</td><td style = \"text-align: right;\">0.014385</td><td style = \"text-align: right;\">0.039</td><td style = \"text-align: right;\">0.063</td><td style = \"text-align: right;\">0.014</td><td style = \"text-align: right;\">0.92</td><td style = \"text-align: right;\">0.94</td><td style = \"text-align: right;\">0.92</td><td style = \"text-align: right;\">0.17</td><td style = \"text-align: right;\">0.21</td><td style = \"text-align: right;\">0.12</td><td style = \"text-align: right;\">6.72</td><td style = \"text-align: right;\">0.082</td><td style = \"text-align: right;\">4.08766</td><td style = \"text-align: right;\">0.032</td><td style = \"text-align: right;\">6.744</td><td style = \"text-align: right;\">0.087</td><td style = \"text-align: right;\">0.17044</td><td style = \"text-align: right;\">0.0139</td><td style = \"text-align: right;\">0.0134</td><td style = \"text-align: right;\">0.007</td><td style = \"text-align: right;\">0.0615</td><td style = \"text-align: right;\">0.0675</td><td style = \"text-align: right;\">0.0471</td><td style = \"text-align: right;\">1.85</td><td style = \"text-align: right;\">3.11</td><td style = \"text-align: right;\">0.66</td><td style = \"text-align: right;\">1.09</td><td style = \"text-align: right;\">1.74</td><td style = \"text-align: right;\">0.46</td><td style = \"text-align: right;\">2.789</td><td style = \"text-align: right;\">3.426</td><td style = \"text-align: right;\">2.182</td><td style = \"text-align: right;\">0.059</td><td style = \"text-align: right;\">0.097</td><td style = \"text-align: right;\">0.022</td><td style = \"text-align: right;\">42.07</td><td style = \"text-align: right;\">34.56</td><td style = \"text-align: right;\">49.23</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">44752</td><td style = \"text-align: right;\">0.2822</td><td style = \"text-align: right;\">0.4612</td><td style = \"text-align: right;\">0.0334287</td><td style = \"text-align: right;\">5.28</td><td style = \"text-align: right;\">6.64</td><td style = \"text-align: right;\">3.98</td><td style = \"text-align: right;\">2.42</td><td style = \"text-align: right;\">3.28</td><td style = \"text-align: right;\">1.59</td><td style = \"text-align: right;\">0.342</td><td style = \"text-align: right;\">0.484</td><td style = \"text-align: right;\">0.207</td><td style = \"text-align: right;\">46.6</td><td style = \"text-align: right;\">14.7</td><td style = \"text-align: right;\">0.0342</td><td style = \"text-align: right;\">0.0428</td><td style = \"text-align: right;\">12.499</td><td style = \"text-align: right;\">0.009092</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">0.0209777</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">7.70391</td><td style = \"text-align: right;\">0.2776</td><td style = \"text-align: right;\">0.215275</td><td style = \"text-align: right;\">0.029713</td><td style = \"text-align: right;\">0.024</td><td style = \"text-align: right;\">0.035</td><td style = \"text-align: right;\">0.013</td><td style = \"text-align: right;\">0.69</td><td style = \"text-align: right;\">0.69</td><td style = \"text-align: right;\">0.69</td><td style = \"text-align: right;\">0.14</td><td style = \"text-align: right;\">0.14</td><td style = \"text-align: right;\">0.13</td><td style = \"text-align: right;\">7.19</td><td style = \"text-align: right;\">0.121</td><td style = \"text-align: right;\">3.91999</td><td style = \"text-align: right;\">0.0268</td><td style = \"text-align: right;\">7.302</td><td style = \"text-align: right;\">0.131</td><td style = \"text-align: right;\">0.13006</td><td style = \"text-align: right;\">0.0173</td><td style = \"text-align: right;\">0.0165</td><td style = \"text-align: right;\">0.018</td><td style = \"text-align: right;\">0.0796</td><td style = \"text-align: right;\">0.1137</td><td style = \"text-align: right;\">0.07942</td><td style = \"text-align: right;\">0.6</td><td style = \"text-align: right;\">1.13</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">0.41</td><td style = \"text-align: right;\">0.77</td><td style = \"text-align: right;\">0.07</td><td style = \"text-align: right;\">2.148</td><td style = \"text-align: right;\">2.21</td><td style = \"text-align: right;\">2.09</td><td style = \"text-align: right;\">0.02</td><td style = \"text-align: right;\">0.038</td><td style = \"text-align: right;\">0.003</td><td style = \"text-align: right;\">49.6</td><td style = \"text-align: right;\">49.6</td><td style = \"text-align: right;\">49.6</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1750</td><td style = \"text-align: right;\">0.2984</td><td style = \"text-align: right;\">0.4812</td><td style = \"text-align: right;\">0.0234286</td><td style = \"text-align: right;\">4.3</td><td style = \"text-align: right;\">4.83</td><td style = \"text-align: right;\">3.8</td><td style = \"text-align: right;\">1.25</td><td style = \"text-align: right;\">0.85</td><td style = \"text-align: right;\">1.63</td><td style = \"text-align: right;\">0.184</td><td style = \"text-align: right;\">0.219</td><td style = \"text-align: right;\">0.152</td><td style = \"text-align: right;\">34.0</td><td style = \"text-align: right;\">16.1</td><td style = \"text-align: right;\">0.0864</td><td style = \"text-align: right;\">0.0931</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">0.01163</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">0.0335512</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">9.06346</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.109614</td><td style = \"text-align: right;\">0.002171</td><td style = \"text-align: right;\">0.402</td><td style = \"text-align: right;\">0.488</td><td style = \"text-align: right;\">0.314</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.9</td><td style = \"text-align: right;\">0.9</td><td style = \"text-align: right;\">0.9</td><td style = \"text-align: right;\">2.91</td><td style = \"text-align: right;\">0.025</td><td style = \"text-align: right;\">4.25135</td><td style = \"text-align: right;\">0.0146</td><td style = \"text-align: right;\">3.448</td><td style = \"text-align: right;\">0.025</td><td style = \"text-align: right;\">0.20156</td><td style = \"text-align: right;\">0.0474</td><td style = \"text-align: right;\">0.0383</td><td style = \"text-align: right;\">0.088</td><td style = \"text-align: right;\">0.1985</td><td style = \"text-align: right;\">0.1842</td><td style = \"text-align: right;\">0.05831</td><td style = \"text-align: right;\">19.18</td><td style = \"text-align: right;\">22.0</td><td style = \"text-align: right;\">16.59</td><td style = \"text-align: right;\">11.6</td><td style = \"text-align: right;\">14.14</td><td style = \"text-align: right;\">9.27</td><td style = \"text-align: right;\">9.359</td><td style = \"text-align: right;\">9.389</td><td style = \"text-align: right;\">9.332</td><td style = \"text-align: right;\">0.616</td><td style = \"text-align: right;\">0.723</td><td style = \"text-align: right;\">0.517</td><td style = \"text-align: right;\">2.27</td><td style = \"text-align: right;\">2.25</td><td style = \"text-align: right;\">2.29</td><td style = \"text-align: right;\">0.001585</td><td style = \"text-align: right;\">194303</td><td style = \"text-align: right;\">0.4111</td><td style = \"text-align: right;\">0.2956</td><td style = \"text-align: right;\">0.0947283</td><td style = \"text-align: right;\">46.48</td><td style = \"text-align: right;\">42.06</td><td style = \"text-align: right;\">50.55</td><td style = \"text-align: right;\">22.01</td><td style = \"text-align: right;\">19.07</td><td style = \"text-align: right;\">24.72</td><td style = \"text-align: right;\">3.206</td><td style = \"text-align: right;\">3.154</td><td style = \"text-align: right;\">3.253</td><td style = \"text-align: right;\">28.2</td><td style = \"text-align: right;\">20.6</td><td style = \"text-align: right;\">0.0594</td><td style = \"text-align: right;\">0.046</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.008169</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">0.0391465</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">8.15191</td><td style = \"text-align: right;\">0.1484</td><td style = \"text-align: right;\">0.110885</td><td style = \"text-align: right;\">0.028579</td><td style = \"text-align: right;\">0.145</td><td style = \"text-align: right;\">0.173</td><td style = \"text-align: right;\">0.114</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.28</td><td style = \"text-align: right;\">0.26</td><td style = \"text-align: right;\">0.4</td><td style = \"text-align: right;\">3.07</td><td style = \"text-align: right;\">0.058</td><td style = \"text-align: right;\">4.18662</td><td style = \"text-align: right;\">0.0155</td><td style = \"text-align: right;\">3.08</td><td style = \"text-align: right;\">0.06</td><td style = \"text-align: right;\">0.25374</td><td style = \"text-align: right;\">0.0236</td><td style = \"text-align: right;\">0.0223</td><td style = \"text-align: right;\">0.021</td><td style = \"text-align: right;\">0.0998</td><td style = \"text-align: right;\">0.0984</td><td style = \"text-align: right;\">0.05517</td><td style = \"text-align: right;\">3.74</td><td style = \"text-align: right;\">5.22</td><td style = \"text-align: right;\">2.24</td><td style = \"text-align: right;\">2.25</td><td style = \"text-align: right;\">3.06</td><td style = \"text-align: right;\">1.43</td><td style = \"text-align: right;\">5.336</td><td style = \"text-align: right;\">5.549</td><td style = \"text-align: right;\">5.122</td><td style = \"text-align: right;\">0.12</td><td style = \"text-align: right;\">0.166</td><td style = \"text-align: right;\">0.074</td><td style = \"text-align: right;\">10.5</td><td style = \"text-align: right;\">9.01</td><td style = \"text-align: right;\">12.01</td><td style = \"text-align: right;\">0.90485</td><td style = \"text-align: right;\">22283</td><td style = \"text-align: right;\">0.3906</td><td style = \"text-align: right;\">0.3007</td><td style = \"text-align: right;\">0.0622448</td><td style = \"text-align: right;\">13.07</td><td style = \"text-align: right;\">13.72</td><td style = \"text-align: right;\">12.41</td><td style = \"text-align: right;\">6.19</td><td style = \"text-align: right;\">5.62</td><td style = \"text-align: right;\">6.76</td><td style = \"text-align: right;\">0.703</td><td style = \"text-align: right;\">0.785</td><td style = \"text-align: right;\">0.62</td><td style = \"text-align: right;\">20.3</td><td style = \"text-align: right;\">7.2</td><td style = \"text-align: right;\">0.0524</td><td style = \"text-align: right;\">0.0523</td><td style = \"text-align: right;\">2.119</td><td style = \"text-align: right;\">0.007584</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">0.0761265</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">6.92952</td><td style = \"text-align: right;\">0.0296</td><td style = \"text-align: right;\">0.165784</td><td style = \"text-align: right;\">0.020115</td><td style = \"text-align: right;\">0.046</td><td style = \"text-align: right;\">0.066</td><td style = \"text-align: right;\">0.025</td><td style = \"text-align: right;\">0.73</td><td style = \"text-align: right;\">0.86</td><td style = \"text-align: right;\">0.63</td><td style = \"text-align: right;\">0.18</td><td style = \"text-align: right;\">0.21</td><td style = \"text-align: right;\">0.14</td><td style = \"text-align: right;\">6.59</td><td style = \"text-align: right;\">0.16</td><td style = \"text-align: right;\">3.79324</td><td style = \"text-align: right;\">0.0228</td><td style = \"text-align: right;\">6.628</td><td style = \"text-align: right;\">0.164</td><td style = \"text-align: right;\">0.12702</td><td style = \"text-align: right;\">0.0161</td><td style = \"text-align: right;\">0.0158</td><td style = \"text-align: right;\">0.016</td><td style = \"text-align: right;\">0.0682</td><td style = \"text-align: right;\">0.1386</td><td style = \"text-align: right;\">0.10658</td><td style = \"text-align: right;\">3.69</td><td style = \"text-align: right;\">4.45</td><td style = \"text-align: right;\">2.97</td><td style = \"text-align: right;\">2.51</td><td style = \"text-align: right;\">2.98</td><td style = \"text-align: right;\">2.07</td><td style = \"text-align: right;\">3.774</td><td style = \"text-align: right;\">5.054</td><td style = \"text-align: right;\">2.568</td><td style = \"text-align: right;\">0.124</td><td style = \"text-align: right;\">0.149</td><td style = \"text-align: right;\">0.101</td><td style = \"text-align: right;\">53.44</td><td style = \"text-align: right;\">34.3</td><td style = \"text-align: right;\">71.48</td><td style = \"text-align: right;\">0.32665</td><td style = \"text-align: right;\">3841</td><td style = \"text-align: right;\">0.3367</td><td style = \"text-align: right;\">0.4287</td><td style = \"text-align: right;\">0.0325436</td><td style = \"text-align: right;\">23.21</td><td style = \"text-align: right;\">30.17</td><td style = \"text-align: right;\">16.66</td><td style = \"text-align: right;\">8.29</td><td style = \"text-align: right;\">10.49</td><td style = \"text-align: right;\">6.21</td><td style = \"text-align: right;\">1.316</td><td style = \"text-align: right;\">1.683</td><td style = \"text-align: right;\">0.969</td><td style = \"text-align: right;\">27.8</td><td style = \"text-align: right;\">17.2</td><td style = \"text-align: right;\">0.056</td><td style = \"text-align: right;\">0.0826</td><td style = \"text-align: right;\">11.879</td><td style = \"text-align: right;\">0.086032</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">0.127951</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">7.23778</td><td style = \"text-align: right;\">0.2151</td><td style = \"text-align: right;\">0.078488</td><td style = \"text-align: right;\">0.011581</td><td style = \"text-align: right;\">0.022</td><td style = \"text-align: right;\">0.031</td><td style = \"text-align: right;\">0.014</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.73</td><td style = \"text-align: right;\">0.72</td><td style = \"text-align: right;\">0.16</td><td style = \"text-align: right;\">0.17</td><td style = \"text-align: right;\">0.19</td><td style = \"text-align: right;\">5.65</td><td style = \"text-align: right;\">0.104</td><td style = \"text-align: right;\">4.0448</td><td style = \"text-align: right;\">0.0299</td><td style = \"text-align: right;\">6.048</td><td style = \"text-align: right;\">0.109</td><td style = \"text-align: right;\">0.2378</td><td style = \"text-align: right;\">0.0179</td><td style = \"text-align: right;\">0.0041</td><td style = \"text-align: right;\">0.017</td><td style = \"text-align: right;\">0.1251</td><td style = \"text-align: right;\">0.1908</td><td style = \"text-align: right;\">0.16935</td><td style = \"text-align: right;\">1.82</td><td style = \"text-align: right;\">2.82</td><td style = \"text-align: right;\">0.83</td><td style = \"text-align: right;\">1.23</td><td style = \"text-align: right;\">1.94</td><td style = \"text-align: right;\">0.53</td><td style = \"text-align: right;\">2.605</td><td style = \"text-align: right;\">2.857</td><td style = \"text-align: right;\">2.356</td><td style = \"text-align: right;\">0.061</td><td style = \"text-align: right;\">0.095</td><td style = \"text-align: right;\">0.027</td><td style = \"text-align: right;\">47.32</td><td style = \"text-align: right;\">43.25</td><td style = \"text-align: right;\">51.34</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: right;\">84292</td><td style = \"text-align: right;\">0.3219</td><td style = \"text-align: right;\">0.4287</td><td style = \"text-align: right;\">0.03164</td><td style = \"text-align: right;\">8.83</td><td style = \"text-align: right;\">9.21</td><td style = \"text-align: right;\">8.46</td><td style = \"text-align: right;\">3.79</td><td style = \"text-align: right;\">3.61</td><td style = \"text-align: right;\">3.96</td><td style = \"text-align: right;\">0.594</td><td style = \"text-align: right;\">0.674</td><td style = \"text-align: right;\">0.515</td><td style = \"text-align: right;\">28.2</td><td style = \"text-align: right;\">14.8</td><td style = \"text-align: right;\">0.027</td><td style = \"text-align: right;\">0.0275</td><td style = \"text-align: right;\">1.938</td><td style = \"text-align: right;\">0.007666</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">-0.0243261</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">8.11582</td><td style = \"text-align: right;\">0.4318</td><td style = \"text-align: right;\">0.137482</td><td style = \"text-align: right;\">0.026547</td><td style = \"text-align: right;\">0.059</td><td style = \"text-align: right;\">0.073</td><td style = \"text-align: right;\">0.045</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.34</td><td style = \"text-align: right;\">0.31</td><td style = \"text-align: right;\">0.35</td><td style = \"text-align: right;\">4.78</td><td style = \"text-align: right;\">0.101</td><td style = \"text-align: right;\">4.08766</td><td style = \"text-align: right;\">0.023</td><td style = \"text-align: right;\">5.18</td><td style = \"text-align: right;\">0.116</td><td style = \"text-align: right;\">0.3459</td><td style = \"text-align: right;\">0.0335</td><td style = \"text-align: right;\">0.0262</td><td style = \"text-align: right;\">0.023</td><td style = \"text-align: right;\">0.0987</td><td style = \"text-align: right;\">0.1689</td><td style = \"text-align: right;\">0.11969</td><td style = \"text-align: right;\">2.75</td><td style = \"text-align: right;\">3.8</td><td style = \"text-align: right;\">1.77</td><td style = \"text-align: right;\">1.87</td><td style = \"text-align: right;\">2.56</td><td style = \"text-align: right;\">1.23</td><td style = \"text-align: right;\">5.018</td><td style = \"text-align: right;\">5.186</td><td style = \"text-align: right;\">4.864</td><td style = \"text-align: right;\">0.092</td><td style = \"text-align: right;\">0.127</td><td style = \"text-align: right;\">0.06</td><td style = \"text-align: right;\">17.22</td><td style = \"text-align: right;\">15.74</td><td style = \"text-align: right;\">18.58</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">8579</td><td style = \"text-align: right;\">0.3153</td><td style = \"text-align: right;\">0.3896</td><td style = \"text-align: right;\">0.049423</td><td style = \"text-align: right;\">21.98</td><td style = \"text-align: right;\">20.84</td><td style = \"text-align: right;\">23.03</td><td style = \"text-align: right;\">10.26</td><td style = \"text-align: right;\">9.08</td><td style = \"text-align: right;\">11.36</td><td style = \"text-align: right;\">1.132</td><td style = \"text-align: right;\">1.126</td><td style = \"text-align: right;\">1.138</td><td style = \"text-align: right;\">52.1</td><td style = \"text-align: right;\">18.8</td><td style = \"text-align: right;\">0.0804</td><td style = \"text-align: right;\">0.093</td><td style = \"text-align: right;\">0.003</td><td style = \"text-align: right;\">0.016968</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">79</td><td style = \"text-align: right;\">0.0931049</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">7.89469</td><td style = \"text-align: right;\">0.1062</td><td style = \"text-align: right;\">0.247626</td><td style = \"text-align: right;\">0.037392</td><td style = \"text-align: right;\">0.121</td><td style = \"text-align: right;\">0.175</td><td style = \"text-align: right;\">0.063</td><td style = \"text-align: right;\">0.96</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.78</td><td style = \"text-align: right;\">0.43</td><td style = \"text-align: right;\">0.57</td><td style = \"text-align: right;\">0.28</td><td style = \"text-align: right;\">7.54</td><td style = \"text-align: right;\">0.077</td><td style = \"text-align: right;\">4.07414</td><td style = \"text-align: right;\">0.0345</td><td style = \"text-align: right;\">7.672</td><td style = \"text-align: right;\">0.125</td><td style = \"text-align: right;\">0.1433</td><td style = \"text-align: right;\">0.0361</td><td style = \"text-align: right;\">0.0352</td><td style = \"text-align: right;\">0.114</td><td style = \"text-align: right;\">0.1834</td><td style = \"text-align: right;\">0.1304</td><td style = \"text-align: right;\">0.01</td><td style = \"text-align: right;\">2.74</td><td style = \"text-align: right;\">4.45</td><td style = \"text-align: right;\">1.01</td><td style = \"text-align: right;\">1.83</td><td style = \"text-align: right;\">3.03</td><td style = \"text-align: right;\">0.61</td><td style = \"text-align: right;\">2.278</td><td style = \"text-align: right;\">3.534</td><td style = \"text-align: right;\">1.017</td><td style = \"text-align: right;\">0.091</td><td style = \"text-align: right;\">0.15</td><td style = \"text-align: right;\">0.033</td><td style = \"text-align: right;\">62.25</td><td style = \"text-align: right;\">41.99</td><td style = \"text-align: right;\">82.57</td><td style = \"text-align: right;\">0.3</td><td style = \"text-align: right;\">7438</td><td style = \"text-align: right;\">0.2487</td><td style = \"text-align: right;\">0.4818</td><td style = \"text-align: right;\">0.0369723</td><td style = \"text-align: right;\">7.1</td><td style = \"text-align: right;\">11.01</td><td style = \"text-align: right;\">3.17</td><td style = \"text-align: right;\">3.46</td><td style = \"text-align: right;\">5.45</td><td style = \"text-align: right;\">1.47</td><td style = \"text-align: right;\">0.481</td><td style = \"text-align: right;\">0.761</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: right;\">33.8</td><td style = \"text-align: right;\">19.6</td><td style = \"text-align: right;\">0.0797</td><td style = \"text-align: right;\">0.1018</td><td style = \"text-align: right;\">3.017</td><td style = \"text-align: right;\">0.207492</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">80</td><td style = \"text-align: right;\">0.0652286</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">7.17549</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.179933</td><td style = \"text-align: right;\">0.046376</td><td style = \"text-align: right;\">0.035</td><td style = \"text-align: right;\">0.04</td><td style = \"text-align: right;\">0.027</td><td style = \"text-align: right;\">0.83</td><td style = \"text-align: right;\">0.82</td><td style = \"text-align: right;\">0.81</td><td style = \"text-align: right;\">0.26</td><td style = \"text-align: right;\">0.28</td><td style = \"text-align: right;\">0.23</td><td style = \"text-align: right;\">4.5</td><td style = \"text-align: right;\">0.06</td><td style = \"text-align: right;\">4.10429</td><td style = \"text-align: right;\">0.0292</td><td style = \"text-align: right;\">4.948</td><td style = \"text-align: right;\">0.096</td><td style = \"text-align: right;\">0.19124</td><td style = \"text-align: right;\">0.0305</td><td style = \"text-align: right;\">0.0223</td><td style = \"text-align: right;\">0.032</td><td style = \"text-align: right;\">0.1055</td><td style = \"text-align: right;\">0.117</td><td style = \"text-align: right;\">0.06266</td><td style = \"text-align: right;\">1.8</td><td style = \"text-align: right;\">2.31</td><td style = \"text-align: right;\">1.32</td><td style = \"text-align: right;\">1.8</td><td style = \"text-align: right;\">2.3</td><td style = \"text-align: right;\">1.31</td><td style = \"text-align: right;\">3.764</td><td style = \"text-align: right;\">4.329</td><td style = \"text-align: right;\">3.226</td><td style = \"text-align: right;\">0.072</td><td style = \"text-align: right;\">0.092</td><td style = \"text-align: right;\">0.053</td><td style = \"text-align: right;\">28.75</td><td style = \"text-align: right;\">22.18</td><td style = \"text-align: right;\">35.0</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: right;\">41359</td><td style = \"text-align: right;\">0.4964</td><td style = \"text-align: right;\">0.4215</td><td style = \"text-align: right;\">0.0299088</td><td style = \"text-align: right;\">5.59</td><td style = \"text-align: right;\">7.85</td><td style = \"text-align: right;\">3.43</td><td style = \"text-align: right;\">1.87</td><td style = \"text-align: right;\">2.55</td><td style = \"text-align: right;\">1.23</td><td style = \"text-align: right;\">0.332</td><td style = \"text-align: right;\">0.451</td><td style = \"text-align: right;\">0.219</td><td style = \"text-align: right;\">27.9</td><td style = \"text-align: right;\">27.2</td><td style = \"text-align: right;\">0.0636</td><td style = \"text-align: right;\">0.0721</td><td style = \"text-align: right;\">20.379</td><td style = \"text-align: right;\">0.018019</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">81</td><td style = \"text-align: right;\">0.038095</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">9.03097</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.293138</td><td style = \"text-align: right;\">0.005517</td><td style = \"text-align: right;\">0.245</td><td style = \"text-align: right;\">0.251</td><td style = \"text-align: right;\">0.238</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.82</td><td style = \"text-align: right;\">0.82</td><td style = \"text-align: right;\">0.85</td><td style = \"text-align: right;\">1.93</td><td style = \"text-align: right;\">0.014</td><td style = \"text-align: right;\">4.2932</td><td style = \"text-align: right;\">0.0075</td><td style = \"text-align: right;\">2.374</td><td style = \"text-align: right;\">0.026</td><td style = \"text-align: right;\">0.29424</td><td style = \"text-align: right;\">0.0442</td><td style = \"text-align: right;\">0.0304</td><td style = \"text-align: right;\">0.039</td><td style = \"text-align: right;\">0.1537</td><td style = \"text-align: right;\">0.1216</td><td style = \"text-align: right;\">0.05199</td><td style = \"text-align: right;\">4.97</td><td style = \"text-align: right;\">6.87</td><td style = \"text-align: right;\">3.25</td><td style = \"text-align: right;\">2.55</td><td style = \"text-align: right;\">3.99</td><td style = \"text-align: right;\">1.23</td><td style = \"text-align: right;\">5.223</td><td style = \"text-align: right;\">5.363</td><td style = \"text-align: right;\">5.096</td><td style = \"text-align: right;\">0.15</td><td style = \"text-align: right;\">0.217</td><td style = \"text-align: right;\">0.09</td><td style = \"text-align: right;\">0.86</td><td style = \"text-align: right;\">0.85</td><td style = \"text-align: right;\">0.88</td><td style = \"text-align: right;\">0.00197</td><td style = \"text-align: right;\">52699</td><td style = \"text-align: right;\">0.4278</td><td style = \"text-align: right;\">0.2351</td><td style = \"text-align: right;\">0.134746</td><td style = \"text-align: right;\">15.66</td><td style = \"text-align: right;\">14.3</td><td style = \"text-align: right;\">16.9</td><td style = \"text-align: right;\">6.42</td><td style = \"text-align: right;\">5.23</td><td style = \"text-align: right;\">7.5</td><td style = \"text-align: right;\">1.167</td><td style = \"text-align: right;\">1.21</td><td style = \"text-align: right;\">1.128</td><td style = \"text-align: right;\">22.5</td><td style = \"text-align: right;\">15.5</td><td style = \"text-align: right;\">0.1662</td><td style = \"text-align: right;\">0.1617</td><td style = \"text-align: right;\">4.286</td><td style = \"text-align: right;\">-0.006642</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">82</td><td style = \"text-align: right;\">0.034213</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">8.99554</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.30472</td><td style = \"text-align: right;\">0.011658</td><td style = \"text-align: right;\">0.246</td><td style = \"text-align: right;\">0.26</td><td style = \"text-align: right;\">0.19</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.42</td><td style = \"text-align: right;\">0.42</td><td style = \"text-align: right;\">0.42</td><td style = \"text-align: right;\">1.45</td><td style = \"text-align: right;\">0.02</td><td style = \"text-align: right;\">4.2711</td><td style = \"text-align: right;\">0.0038</td><td style = \"text-align: right;\">1.742</td><td style = \"text-align: right;\">0.029</td><td style = \"text-align: right;\">0.30212</td><td style = \"text-align: right;\">0.0426</td><td style = \"text-align: right;\">0.032</td><td style = \"text-align: right;\">0.034</td><td style = \"text-align: right;\">0.1733</td><td style = \"text-align: right;\">0.1516</td><td style = \"text-align: right;\">0.08538</td><td style = \"text-align: right;\">5.5</td><td style = \"text-align: right;\">8.46</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">3.12</td><td style = \"text-align: right;\">5.15</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">8.208</td><td style = \"text-align: right;\">8.57</td><td style = \"text-align: right;\">7.903</td><td style = \"text-align: right;\">0.172</td><td style = \"text-align: right;\">0.272</td><td style = \"text-align: right;\">0.088</td><td style = \"text-align: right;\">0.6</td><td style = \"text-align: right;\">0.48</td><td style = \"text-align: right;\">0.7</td><td style = \"text-align: right;\">0.004845</td><td style = \"text-align: right;\">61829</td><td style = \"text-align: right;\">0.4466</td><td style = \"text-align: right;\">0.2034</td><td style = \"text-align: right;\">0.144544</td><td style = \"text-align: right;\">15.6</td><td style = \"text-align: right;\">15.13</td><td style = \"text-align: right;\">16.0</td><td style = \"text-align: right;\">6.75</td><td style = \"text-align: right;\">6.76</td><td style = \"text-align: right;\">6.75</td><td style = \"text-align: right;\">0.667</td><td style = \"text-align: right;\">0.776</td><td style = \"text-align: right;\">0.575</td><td style = \"text-align: right;\">23.5</td><td style = \"text-align: right;\">15.0</td><td style = \"text-align: right;\">0.2597</td><td style = \"text-align: right;\">0.2288</td><td style = \"text-align: right;\">2.46</td><td style = \"text-align: right;\">-0.003241</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">83</td><td style = \"text-align: right;\">0.0527591</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">8.23483</td><td style = \"text-align: right;\">0.0363</td><td style = \"text-align: right;\">0.288405</td><td style = \"text-align: right;\">0.011589</td><td style = \"text-align: right;\">0.183</td><td style = \"text-align: right;\">0.222</td><td style = \"text-align: right;\">0.142</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.78</td><td style = \"text-align: right;\">0.87</td><td style = \"text-align: right;\">0.69</td><td style = \"text-align: right;\">2.36</td><td style = \"text-align: right;\">0.024</td><td style = \"text-align: right;\">4.28909</td><td style = \"text-align: right;\">0.0057</td><td style = \"text-align: right;\">2.326</td><td style = \"text-align: right;\">0.039</td><td style = \"text-align: right;\">0.35272</td><td style = \"text-align: right;\">0.018</td><td style = \"text-align: right;\">0.0158</td><td style = \"text-align: right;\">0.045</td><td style = \"text-align: right;\">0.1251</td><td style = \"text-align: right;\">0.1259</td><td style = \"text-align: right;\">0.06501</td><td style = \"text-align: right;\">5.44</td><td style = \"text-align: right;\">7.97</td><td style = \"text-align: right;\">3.16</td><td style = \"text-align: right;\">5.22</td><td style = \"text-align: right;\">7.6</td><td style = \"text-align: right;\">3.08</td><td style = \"text-align: right;\">5.849</td><td style = \"text-align: right;\">6.603</td><td style = \"text-align: right;\">5.17</td><td style = \"text-align: right;\">0.213</td><td style = \"text-align: right;\">0.311</td><td style = \"text-align: right;\">0.125</td><td style = \"text-align: right;\">13.68</td><td style = \"text-align: right;\">5.66</td><td style = \"text-align: right;\">20.89</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">9047</td><td style = \"text-align: right;\">0.391</td><td style = \"text-align: right;\">0.2382</td><td style = \"text-align: right;\">0.122361</td><td style = \"text-align: right;\">14.43</td><td style = \"text-align: right;\">16.17</td><td style = \"text-align: right;\">12.87</td><td style = \"text-align: right;\">8.36</td><td style = \"text-align: right;\">8.56</td><td style = \"text-align: right;\">8.18</td><td style = \"text-align: right;\">1.01</td><td style = \"text-align: right;\">1.22</td><td style = \"text-align: right;\">0.821</td><td style = \"text-align: right;\">30.2</td><td style = \"text-align: right;\">28.3</td><td style = \"text-align: right;\">0.1044</td><td style = \"text-align: right;\">0.1796</td><td style = \"text-align: right;\">32.051</td><td style = \"text-align: right;\">-0.034352</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">84</td><td style = \"text-align: right;\">0.0384156</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">8.33255</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.345485</td><td style = \"text-align: right;\">0.006503</td><td style = \"text-align: right;\">0.188</td><td style = \"text-align: right;\">0.248</td><td style = \"text-align: right;\">0.136</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.86</td><td style = \"text-align: right;\">0.85</td><td style = \"text-align: right;\">0.92</td><td style = \"text-align: right;\">3.39</td><td style = \"text-align: right;\">0.018</td><td style = \"text-align: right;\">4.27249</td><td style = \"text-align: right;\">0.0148</td><td style = \"text-align: right;\">3.81</td><td style = \"text-align: right;\">0.029</td><td style = \"text-align: right;\">0.28634</td><td style = \"text-align: right;\">0.0499</td><td style = \"text-align: right;\">0.0421</td><td style = \"text-align: right;\">0.015</td><td style = \"text-align: right;\">0.1664</td><td style = \"text-align: right;\">0.1681</td><td style = \"text-align: right;\">0.11142</td><td style = \"text-align: right;\">5.72</td><td style = \"text-align: right;\">7.18</td><td style = \"text-align: right;\">4.32</td><td style = \"text-align: right;\">3.24</td><td style = \"text-align: right;\">4.52</td><td style = \"text-align: right;\">2.02</td><td style = \"text-align: right;\">6.729</td><td style = \"text-align: right;\">6.806</td><td style = \"text-align: right;\">6.656</td><td style = \"text-align: right;\">0.179</td><td style = \"text-align: right;\">0.234</td><td style = \"text-align: right;\">0.127</td><td style = \"text-align: right;\">3.11</td><td style = \"text-align: right;\">3.09</td><td style = \"text-align: right;\">3.14</td><td style = \"text-align: right;\">0.032</td><td style = \"text-align: right;\">3177</td><td style = \"text-align: right;\">0.3744</td><td style = \"text-align: right;\">0.3088</td><td style = \"text-align: right;\">0.110167</td><td style = \"text-align: right;\">28.67</td><td style = \"text-align: right;\">26.18</td><td style = \"text-align: right;\">31.07</td><td style = \"text-align: right;\">12.42</td><td style = \"text-align: right;\">11.69</td><td style = \"text-align: right;\">13.12</td><td style = \"text-align: right;\">1.576</td><td style = \"text-align: right;\">1.567</td><td style = \"text-align: right;\">1.585</td><td style = \"text-align: right;\">31.0</td><td style = \"text-align: right;\">14.3</td><td style = \"text-align: right;\">0.2866</td><td style = \"text-align: right;\">0.35</td><td style = \"text-align: right;\">0.452</td><td style = \"text-align: right;\">-0.00166</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">85</td><td style = \"text-align: right;\">0.0318948</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">8.64559</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.28844</td><td style = \"text-align: right;\">0.005995</td><td style = \"text-align: right;\">0.256</td><td style = \"text-align: right;\">0.301</td><td style = \"text-align: right;\">0.199</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.7</td><td style = \"text-align: right;\">0.75</td><td style = \"text-align: right;\">0.66</td><td style = \"text-align: right;\">2.19</td><td style = \"text-align: right;\">0.021</td><td style = \"text-align: right;\">4.28496</td><td style = \"text-align: right;\">0.0065</td><td style = \"text-align: right;\">2.366</td><td style = \"text-align: right;\">0.041</td><td style = \"text-align: right;\">0.26852</td><td style = \"text-align: right;\">0.0392</td><td style = \"text-align: right;\">0.0363</td><td style = \"text-align: right;\">0.029</td><td style = \"text-align: right;\">0.1378</td><td style = \"text-align: right;\">0.1465</td><td style = \"text-align: right;\">0.08144</td><td style = \"text-align: right;\">4.27</td><td style = \"text-align: right;\">5.94</td><td style = \"text-align: right;\">2.76</td><td style = \"text-align: right;\">2.42</td><td style = \"text-align: right;\">3.67</td><td style = \"text-align: right;\">1.29</td><td style = \"text-align: right;\">5.314</td><td style = \"text-align: right;\">5.788</td><td style = \"text-align: right;\">4.887</td><td style = \"text-align: right;\">0.134</td><td style = \"text-align: right;\">0.192</td><td style = \"text-align: right;\">0.081</td><td style = \"text-align: right;\">6.43</td><td style = \"text-align: right;\">4.91</td><td style = \"text-align: right;\">7.82</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">55441</td><td style = \"text-align: right;\">0.3867</td><td style = \"text-align: right;\">0.2311</td><td style = \"text-align: right;\">0.120452</td><td style = \"text-align: right;\">19.02</td><td style = \"text-align: right;\">21.81</td><td style = \"text-align: right;\">16.5</td><td style = \"text-align: right;\">7.89</td><td style = \"text-align: right;\">8.98</td><td style = \"text-align: right;\">6.91</td><td style = \"text-align: right;\">1.307</td><td style = \"text-align: right;\">1.579</td><td style = \"text-align: right;\">1.062</td><td style = \"text-align: right;\">18.9</td><td style = \"text-align: right;\">11.3</td><td style = \"text-align: right;\">0.1296</td><td style = \"text-align: right;\">0.1458</td><td style = \"text-align: right;\">652.85</td><td style = \"text-align: right;\">-0.046278</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">86</td><td style = \"text-align: right;\">0.031196</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">8.99106</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.371898</td><td style = \"text-align: right;\">0.014586</td><td style = \"text-align: right;\">0.255</td><td style = \"text-align: right;\">0.336</td><td style = \"text-align: right;\">0.17</td><td style = \"text-align: right;\">0.98</td><td style = \"text-align: right;\">0.99</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.88</td><td style = \"text-align: right;\">0.92</td><td style = \"text-align: right;\">0.85</td><td style = \"text-align: right;\">1.67</td><td style = \"text-align: right;\">0.011</td><td style = \"text-align: right;\">4.30946</td><td style = \"text-align: right;\">0.0094</td><td style = \"text-align: right;\">2.168</td><td style = \"text-align: right;\">0.017</td><td style = \"text-align: right;\">0.29184</td><td style = \"text-align: right;\">0.0748</td><td style = \"text-align: right;\">0.0599</td><td style = \"text-align: right;\">0.034</td><td style = \"text-align: right;\">0.1577</td><td style = \"text-align: right;\">0.1233</td><td style = \"text-align: right;\">0.02952</td><td style = \"text-align: right;\">9.07</td><td style = \"text-align: right;\">12.59</td><td style = \"text-align: right;\">5.7</td><td style = \"text-align: right;\">5.14</td><td style = \"text-align: right;\">7.74</td><td style = \"text-align: right;\">2.66</td><td style = \"text-align: right;\">7.895</td><td style = \"text-align: right;\">8.401</td><td style = \"text-align: right;\">7.414</td><td style = \"text-align: right;\">0.284</td><td style = \"text-align: right;\">0.407</td><td style = \"text-align: right;\">0.167</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">13653</td><td style = \"text-align: right;\">0.3714</td><td style = \"text-align: right;\">0.2463</td><td style = \"text-align: right;\">0.107888</td><td style = \"text-align: right;\">45.15</td><td style = \"text-align: right;\">47.53</td><td style = \"text-align: right;\">42.87</td><td style = \"text-align: right;\">10.92</td><td style = \"text-align: right;\">10.4</td><td style = \"text-align: right;\">11.41</td><td style = \"text-align: right;\">2.226</td><td style = \"text-align: right;\">2.494</td><td style = \"text-align: right;\">1.971</td><td style = \"text-align: right;\">27.5</td><td style = \"text-align: right;\">15.9</td><td style = \"text-align: right;\">0.4407</td><td style = \"text-align: right;\">0.4257</td><td style = \"text-align: right;\">2.529</td><td style = \"text-align: right;\">-0.011883</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">87</td><td style = \"text-align: right;\">0.0340957</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">8.02519</td><td style = \"text-align: right;\">0.005</td><td style = \"text-align: right;\">0.296437</td><td style = \"text-align: right;\">0.013615</td><td style = \"text-align: right;\">0.108</td><td style = \"text-align: right;\">0.117</td><td style = \"text-align: right;\">0.093</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.96</td><td style = \"text-align: right;\">0.53</td><td style = \"text-align: right;\">0.53</td><td style = \"text-align: right;\">0.52</td><td style = \"text-align: right;\">2.52</td><td style = \"text-align: right;\">0.039</td><td style = \"text-align: right;\">4.23266</td><td style = \"text-align: right;\">0.0083</td><td style = \"text-align: right;\">2.702</td><td style = \"text-align: right;\">0.078</td><td style = \"text-align: right;\">0.26508</td><td style = \"text-align: right;\">0.0194</td><td style = \"text-align: right;\">0.0175</td><td style = \"text-align: right;\">0.069</td><td style = \"text-align: right;\">0.1353</td><td style = \"text-align: right;\">0.1436</td><td style = \"text-align: right;\">0.05671</td><td style = \"text-align: right;\">2.11</td><td style = \"text-align: right;\">3.09</td><td style = \"text-align: right;\">1.32</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.69</td><td style = \"text-align: right;\">0.44</td><td style = \"text-align: right;\">2.068</td><td style = \"text-align: right;\">2.581</td><td style = \"text-align: right;\">1.657</td><td style = \"text-align: right;\">0.062</td><td style = \"text-align: right;\">0.096</td><td style = \"text-align: right;\">0.035</td><td style = \"text-align: right;\">51.75</td><td style = \"text-align: right;\">42.98</td><td style = \"text-align: right;\">58.77</td><td style = \"text-align: right;\">0.3</td><td style = \"text-align: right;\">9093</td><td style = \"text-align: right;\">0.407</td><td style = \"text-align: right;\">0.2712</td><td style = \"text-align: right;\">0.0987573</td><td style = \"text-align: right;\">6.17</td><td style = \"text-align: right;\">8.11</td><td style = \"text-align: right;\">4.62</td><td style = \"text-align: right;\">2.67</td><td style = \"text-align: right;\">3.58</td><td style = \"text-align: right;\">1.95</td><td style = \"text-align: right;\">0.51</td><td style = \"text-align: right;\">0.694</td><td style = \"text-align: right;\">0.362</td><td style = \"text-align: right;\">20.2</td><td style = \"text-align: right;\">15.7</td><td style = \"text-align: right;\">0.1669</td><td style = \"text-align: right;\">0.2201</td><td style = \"text-align: right;\">25.553</td><td style = \"text-align: right;\">-0.03908</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">88</td><td style = \"text-align: right;\">0.0469005</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">9.03014</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.265778</td><td style = \"text-align: right;\">0.008629</td><td style = \"text-align: right;\">0.288</td><td style = \"text-align: right;\">0.337</td><td style = \"text-align: right;\">0.237</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.95</td><td style = \"text-align: right;\">0.78</td><td style = \"text-align: right;\">0.75</td><td style = \"text-align: right;\">0.82</td><td style = \"text-align: right;\">1.78</td><td style = \"text-align: right;\">0.009</td><td style = \"text-align: right;\">4.31749</td><td style = \"text-align: right;\">0.0037</td><td style = \"text-align: right;\">1.924</td><td style = \"text-align: right;\">0.015</td><td style = \"text-align: right;\">0.26198</td><td style = \"text-align: right;\">0.0723</td><td style = \"text-align: right;\">0.0687</td><td style = \"text-align: right;\">0.036</td><td style = \"text-align: right;\">0.2272</td><td style = \"text-align: right;\">0.2563</td><td style = \"text-align: right;\">0.15135</td><td style = \"text-align: right;\">9.9</td><td style = \"text-align: right;\">10.96</td><td style = \"text-align: right;\">8.88</td><td style = \"text-align: right;\">5.61</td><td style = \"text-align: right;\">7.14</td><td style = \"text-align: right;\">4.15</td><td style = \"text-align: right;\">7.896</td><td style = \"text-align: right;\">7.854</td><td style = \"text-align: right;\">7.935</td><td style = \"text-align: right;\">0.31</td><td style = \"text-align: right;\">0.362</td><td style = \"text-align: right;\">0.26</td><td style = \"text-align: right;\">1.37</td><td style = \"text-align: right;\">1.51</td><td style = \"text-align: right;\">1.23</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">8193</td><td style = \"text-align: right;\">0.4808</td><td style = \"text-align: right;\">0.2018</td><td style = \"text-align: right;\">0.151105</td><td style = \"text-align: right;\">35.7</td><td style = \"text-align: right;\">33.26</td><td style = \"text-align: right;\">38.04</td><td style = \"text-align: right;\">24.09</td><td style = \"text-align: right;\">22.48</td><td style = \"text-align: right;\">25.64</td><td style = \"text-align: right;\">2.727</td><td style = \"text-align: right;\">2.664</td><td style = \"text-align: right;\">2.788</td><td style = \"text-align: right;\">20.4</td><td style = \"text-align: right;\">9.4</td><td style = \"text-align: right;\">0.3238</td><td style = \"text-align: right;\">0.3134</td><td style = \"text-align: right;\">4.152</td><td style = \"text-align: right;\">0.005175</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">89</td><td style = \"text-align: right;\">0.0397734</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">8.86531</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.282939</td><td style = \"text-align: right;\">0.005048</td><td style = \"text-align: right;\">0.188</td><td style = \"text-align: right;\">0.236</td><td style = \"text-align: right;\">0.139</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.83</td><td style = \"text-align: right;\">0.82</td><td style = \"text-align: right;\">0.83</td><td style = \"text-align: right;\">1.8</td><td style = \"text-align: right;\">0.016</td><td style = \"text-align: right;\">4.28221</td><td style = \"text-align: right;\">0.0026</td><td style = \"text-align: right;\">2.2</td><td style = \"text-align: right;\">0.022</td><td style = \"text-align: right;\">0.20382</td><td style = \"text-align: right;\">0.0514</td><td style = \"text-align: right;\">0.0404</td><td style = \"text-align: right;\">0.05</td><td style = \"text-align: right;\">0.181</td><td style = \"text-align: right;\">0.2101</td><td style = \"text-align: right;\">0.11971</td><td style = \"text-align: right;\">11.0</td><td style = \"text-align: right;\">14.36</td><td style = \"text-align: right;\">8.0</td><td style = \"text-align: right;\">6.24</td><td style = \"text-align: right;\">9.04</td><td style = \"text-align: right;\">3.74</td><td style = \"text-align: right;\">8.166</td><td style = \"text-align: right;\">8.28</td><td style = \"text-align: right;\">8.065</td><td style = \"text-align: right;\">0.345</td><td style = \"text-align: right;\">0.468</td><td style = \"text-align: right;\">0.235</td><td style = \"text-align: right;\">0.96</td><td style = \"text-align: right;\">2.04</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.103555</td><td style = \"text-align: right;\">56226</td><td style = \"text-align: right;\">0.4645</td><td style = \"text-align: right;\">0.2246</td><td style = \"text-align: right;\">0.139508</td><td style = \"text-align: right;\">32.57</td><td style = \"text-align: right;\">29.58</td><td style = \"text-align: right;\">35.24</td><td style = \"text-align: right;\">8.37</td><td style = \"text-align: right;\">5.7</td><td style = \"text-align: right;\">10.76</td><td style = \"text-align: right;\">1.888</td><td style = \"text-align: right;\">1.92</td><td style = \"text-align: right;\">1.86</td><td style = \"text-align: right;\">20.0</td><td style = \"text-align: right;\">16.0</td><td style = \"text-align: right;\">0.1845</td><td style = \"text-align: right;\">0.194</td><td style = \"text-align: right;\">0.452</td><td style = \"text-align: right;\">-0.029551</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">90</td><td style = \"text-align: right;\">0.0406415</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">8.91234</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.150366</td><td style = \"text-align: right;\">0.024377</td><td style = \"text-align: right;\">0.257</td><td style = \"text-align: right;\">0.338</td><td style = \"text-align: right;\">0.215</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.81</td><td style = \"text-align: right;\">0.83</td><td style = \"text-align: right;\">0.81</td><td style = \"text-align: right;\">2.33</td><td style = \"text-align: right;\">0.016</td><td style = \"text-align: right;\">4.27805</td><td style = \"text-align: right;\">0.0181</td><td style = \"text-align: right;\">2.914</td><td style = \"text-align: right;\">0.021</td><td style = \"text-align: right;\">0.23996</td><td style = \"text-align: right;\">0.0514</td><td style = \"text-align: right;\">0.042</td><td style = \"text-align: right;\">0.018</td><td style = \"text-align: right;\">0.1319</td><td style = \"text-align: right;\">0.2076</td><td style = \"text-align: right;\">0.14716</td><td style = \"text-align: right;\">20.1</td><td style = \"text-align: right;\">23.97</td><td style = \"text-align: right;\">16.4</td><td style = \"text-align: right;\">7.74</td><td style = \"text-align: right;\">9.52</td><td style = \"text-align: right;\">6.04</td><td style = \"text-align: right;\">11.158</td><td style = \"text-align: right;\">11.535</td><td style = \"text-align: right;\">10.798</td><td style = \"text-align: right;\">0.557</td><td style = \"text-align: right;\">0.67</td><td style = \"text-align: right;\">0.449</td><td style = \"text-align: right;\">0.67</td><td style = \"text-align: right;\">0.66</td><td style = \"text-align: right;\">0.67</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">3083</td><td style = \"text-align: right;\">0.3922</td><td style = \"text-align: right;\">0.2911</td><td style = \"text-align: right;\">0.0869283</td><td style = \"text-align: right;\">57.1</td><td style = \"text-align: right;\">56.37</td><td style = \"text-align: right;\">57.8</td><td style = \"text-align: right;\">24.72</td><td style = \"text-align: right;\">25.07</td><td style = \"text-align: right;\">24.4</td><td style = \"text-align: right;\">3.051</td><td style = \"text-align: right;\">3.235</td><td style = \"text-align: right;\">2.875</td><td style = \"text-align: right;\">18.5</td><td style = \"text-align: right;\">29.1</td><td style = \"text-align: right;\">0.1876</td><td style = \"text-align: right;\">0.2007</td><td style = \"text-align: right;\">0.886</td><td style = \"text-align: right;\">-0.036482</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& Outcome & intercept & gdpsh465 & bmp1l & freeop & freetar & h65 & hm65 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Int32 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & -0.0243358 & 1 & 6.59167 & 0.2837 & 0.153491 & 0.043888 & 0.007 & 0.013 & $\\dots$ \\\\\n",
       "\t2 & 0.100473 & 1 & 6.82979 & 0.6141 & 0.313509 & 0.061827 & 0.019 & 0.032 & $\\dots$ \\\\\n",
       "\t3 & 0.0670515 & 1 & 8.89508 & 0.0 & 0.204244 & 0.009186 & 0.26 & 0.325 & $\\dots$ \\\\\n",
       "\t4 & 0.0640892 & 1 & 7.56528 & 0.1997 & 0.248714 & 0.03627 & 0.061 & 0.07 & $\\dots$ \\\\\n",
       "\t5 & 0.0279295 & 1 & 7.1624 & 0.174 & 0.299252 & 0.037367 & 0.017 & 0.027 & $\\dots$ \\\\\n",
       "\t6 & 0.0464074 & 1 & 7.21891 & 0.0 & 0.258865 & 0.02088 & 0.023 & 0.038 & $\\dots$ \\\\\n",
       "\t7 & 0.0673323 & 1 & 7.8536 & 0.0 & 0.182525 & 0.014385 & 0.039 & 0.063 & $\\dots$ \\\\\n",
       "\t8 & 0.0209777 & 1 & 7.70391 & 0.2776 & 0.215275 & 0.029713 & 0.024 & 0.035 & $\\dots$ \\\\\n",
       "\t9 & 0.0335512 & 1 & 9.06346 & 0.0 & 0.109614 & 0.002171 & 0.402 & 0.488 & $\\dots$ \\\\\n",
       "\t10 & 0.0391465 & 1 & 8.15191 & 0.1484 & 0.110885 & 0.028579 & 0.145 & 0.173 & $\\dots$ \\\\\n",
       "\t11 & 0.0761265 & 1 & 6.92952 & 0.0296 & 0.165784 & 0.020115 & 0.046 & 0.066 & $\\dots$ \\\\\n",
       "\t12 & 0.127951 & 1 & 7.23778 & 0.2151 & 0.078488 & 0.011581 & 0.022 & 0.031 & $\\dots$ \\\\\n",
       "\t13 & -0.0243261 & 1 & 8.11582 & 0.4318 & 0.137482 & 0.026547 & 0.059 & 0.073 & $\\dots$ \\\\\n",
       "\t14 & 0.0782934 & 1 & 7.2717 & 0.1689 & 0.164598 & 0.044446 & 0.029 & 0.045 & $\\dots$ \\\\\n",
       "\t15 & 0.112912 & 1 & 7.12125 & 0.1832 & 0.188016 & 0.045678 & 0.033 & 0.051 & $\\dots$ \\\\\n",
       "\t16 & 0.0523082 & 1 & 6.97728 & 0.0962 & 0.204611 & 0.077852 & 0.037 & 0.043 & $\\dots$ \\\\\n",
       "\t17 & 0.0363909 & 1 & 7.64969 & 0.0227 & 0.136287 & 0.04673 & 0.081 & 0.105 & $\\dots$ \\\\\n",
       "\t18 & 0.0297382 & 1 & 8.05674 & 0.0208 & 0.197853 & 0.037224 & 0.083 & 0.097 & $\\dots$ \\\\\n",
       "\t19 & -0.0566436 & 1 & 8.78094 & 0.2654 & 0.189867 & 0.031747 & 0.068 & 0.089 & $\\dots$ \\\\\n",
       "\t20 & 0.0192048 & 1 & 6.28786 & 0.4207 & 0.130682 & 0.109921 & 0.053 & 0.039 & $\\dots$ \\\\\n",
       "\t21 & 0.085206 & 1 & 6.13773 & 0.1371 & 0.123818 & 0.015897 & 0.028 & 0.025 & $\\dots$ \\\\\n",
       "\t22 & 0.133982 & 1 & 8.12888 & 0.0 & 0.16721 & 0.003311 & 0.129 & 0.196 & $\\dots$ \\\\\n",
       "\t23 & 0.173025 & 1 & 6.68085 & 0.4713 & 0.228424 & 0.029328 & 0.062 & 0.09 & $\\dots$ \\\\\n",
       "\t24 & 0.109699 & 1 & 7.17702 & 0.0178 & 0.18524 & 0.015453 & 0.02 & 0.026 & $\\dots$ \\\\\n",
       "\t25 & 0.0159899 & 1 & 6.64898 & 0.4762 & 0.171181 & 0.058937 & 0.018 & 0.028 & $\\dots$ \\\\\n",
       "\t26 & 0.0622498 & 1 & 6.87936 & 0.2927 & 0.179508 & 0.035842 & 0.188 & 0.169 & $\\dots$ \\\\\n",
       "\t27 & 0.109871 & 1 & 7.3473 & 0.1017 & 0.247626 & 0.037392 & 0.08 & 0.133 & $\\dots$ \\\\\n",
       "\t28 & 0.0921063 & 1 & 6.72503 & 0.0266 & 0.179933 & 0.046376 & 0.015 & 0.02 & $\\dots$ \\\\\n",
       "\t29 & 0.083376 & 1 & 8.45105 & 0.0 & 0.358556 & 0.016468 & 0.09 & 0.133 & $\\dots$ \\\\\n",
       "\t30 & 0.0762335 & 1 & 8.60245 & 0.0 & 0.416234 & 0.014721 & 0.148 & 0.194 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m90Ã—63 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0mâ”‚\u001b[1m Outcome    \u001b[0m\u001b[1m intercept \u001b[0m\u001b[1m gdpsh465 \u001b[0m\u001b[1m bmp1l   \u001b[0m\u001b[1m freeop   \u001b[0m\u001b[1m freetar  \u001b[0m\u001b[1m h65     \u001b[0m\u001b[1m \u001b[0m â‹¯\n",
       "     â”‚\u001b[90m Float64    \u001b[0m\u001b[90m Int32     \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m \u001b[0m â‹¯\n",
       "â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "   1 â”‚ -0.0243358          1   6.59167   0.2837  0.153491  0.043888    0.007   â‹¯\n",
       "   2 â”‚  0.100473           1   6.82979   0.6141  0.313509  0.061827    0.019\n",
       "   3 â”‚  0.0670515          1   8.89508   0.0     0.204244  0.009186    0.26\n",
       "   4 â”‚  0.0640892          1   7.56528   0.1997  0.248714  0.03627     0.061\n",
       "   5 â”‚  0.0279295          1   7.1624    0.174   0.299252  0.037367    0.017   â‹¯\n",
       "   6 â”‚  0.0464074          1   7.21891   0.0     0.258865  0.02088     0.023\n",
       "   7 â”‚  0.0673323          1   7.8536    0.0     0.182525  0.014385    0.039\n",
       "   8 â”‚  0.0209777          1   7.70391   0.2776  0.215275  0.029713    0.024\n",
       "   9 â”‚  0.0335512          1   9.06346   0.0     0.109614  0.002171    0.402   â‹¯\n",
       "  10 â”‚  0.0391465          1   8.15191   0.1484  0.110885  0.028579    0.145\n",
       "  11 â”‚  0.0761265          1   6.92952   0.0296  0.165784  0.020115    0.046\n",
       "  â‹®  â”‚     â‹®           â‹®         â‹®         â‹®        â‹®         â‹®         â‹®      â‹±\n",
       "  81 â”‚  0.038095           1   9.03097   0.0     0.293138  0.005517    0.245\n",
       "  82 â”‚  0.034213           1   8.99554   0.0     0.30472   0.011658    0.246   â‹¯\n",
       "  83 â”‚  0.0527591          1   8.23483   0.0363  0.288405  0.011589    0.183\n",
       "  84 â”‚  0.0384156          1   8.33255   0.0     0.345485  0.006503    0.188\n",
       "  85 â”‚  0.0318948          1   8.64559   0.0     0.28844   0.005995    0.256\n",
       "  86 â”‚  0.031196           1   8.99106   0.0     0.371898  0.014586    0.255   â‹¯\n",
       "  87 â”‚  0.0340957          1   8.02519   0.005   0.296437  0.013615    0.108\n",
       "  88 â”‚  0.0469005          1   9.03014   0.0     0.265778  0.008629    0.288\n",
       "  89 â”‚  0.0397734          1   8.86531   0.0     0.282939  0.005048    0.188\n",
       "  90 â”‚  0.0406415          1   8.91234   0.0     0.150366  0.024377    0.257   â‹¯\n",
       "\u001b[36m                                                  56 columns and 69 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[!,1]\n",
    "# y= reshape(y, (length(y),1))\n",
    "d = data[!,3]\n",
    "# d= reshape(d, (length(y),1))\n",
    "x = data[!,4:end];\n",
    "# x = Matrix(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table{Union{AbstractVector{ScientificTypesBase.Continuous}, AbstractVector{Count}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scitype(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coerce!(x, Count => MLJ.Continuous);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive OLS that uses all features w/o cross-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " length of y is \n",
      "90\n",
      "\n",
      " num features x is \n",
      "60\n",
      "\n",
      " Naive OLS that uses all features w/o cross-fitting \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>DataFrameRow (7 columns)</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Name</th><th style = \"text-align: left;\">Estimate</th><th style = \"text-align: left;\">Std. Error</th><th style = \"text-align: left;\">t-stat</th><th style = \"text-align: left;\">Pr(&gt;|t|)</th><th style = \"text-align: left;\">Lower 95%</th><th style = \"text-align: left;\">Upper 95%</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">gdpsh465</td><td style = \"text-align: right;\">-0.00937799</td><td style = \"text-align: right;\">0.0298877</td><td style = \"text-align: right;\">-0.313774</td><td style = \"text-align: right;\">0.756104</td><td style = \"text-align: right;\">-0.0707025</td><td style = \"text-align: right;\">0.0519466</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& Name & Estimate & Std. Error & t-stat & Pr(>|t|) & Lower 95\\% & Upper 95\\%\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & gdpsh465 & -0.00937799 & 0.0298877 & -0.313774 & 0.756104 & -0.0707025 & 0.0519466 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1mDataFrameRow\u001b[0m\n",
       "\u001b[1m Row \u001b[0mâ”‚\u001b[1m Name     \u001b[0m\u001b[1m Estimate    \u001b[0m\u001b[1m Std. Error \u001b[0m\u001b[1m t-stat    \u001b[0m\u001b[1m Pr(>|t|) \u001b[0m\u001b[1m Lower 95%  \u001b[0m\u001b[1m Upp\u001b[0m â‹¯\n",
       "     â”‚\u001b[90m String   \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Flo\u001b[0m â‹¯\n",
       "â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "   1 â”‚ gdpsh465  -0.00937799   0.0298877  -0.313774  0.756104  -0.0707025  0.0 â‹¯\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"\\n length of y is \\n\", size(y,1) )\n",
    "println(\"\\n num features x is \\n\", size(x,2 ) )\n",
    "\n",
    "# Naive OLS\n",
    "print( \"\\n Naive OLS that uses all features w/o cross-fitting \\n\" )\n",
    "fm = term(:Outcome) ~ term(:gdpsh465) +sum(term.(Symbol.(names(data[:,4:size(data,2)]))));\n",
    "lres = reg(data, fm);\n",
    "first(DataFrame(GLM.coeftable(lres)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DML algorithm\n",
    "\n",
    "Here we perform estimation and inference of predictive coefficient $\\alpha$ in the partially linear statistical model,\n",
    "$$\n",
    "Y = D\\alpha + g(X) + U, \\quad E (U | D, X) = 0.\n",
    "$$\n",
    "For $\\tilde Y = Y- E(Y|X)$ and $\\tilde D= D- E(D|X)$, we can write\n",
    "$$\n",
    "\\tilde Y = \\alpha \\tilde D + U, \\quad E (U |\\tilde D) =0.\n",
    "$$\n",
    "Parameter $\\alpha$ is then estimated using cross-fitting approach to obtain the residuals $\\tilde D$ and $\\tilde Y$.\n",
    "The algorithm comsumes $Y, D, X$, and machine learning methods for learning the residuals $\\tilde Y$ and $\\tilde D$, where\n",
    "the residuals are obtained by cross-validation (cross-fitting).\n",
    "\n",
    "The statistical parameter $\\alpha$ has a causal interpretation of being the effect of $D$ on $Y$ in the causal DAG $$ D\\to Y, \\quad X\\to (D,Y)$$ or the counterfactual outcome model with conditionally exogenous (conditionally random) assignment of treatment $D$ given $X$:\n",
    "$$\n",
    "Y(d) = d\\alpha + g(X) + U(d),\\quad  U(d) \\text{ indep } D |X, \\quad Y = Y(D), \\quad U = U(D).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "summarize (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function training_sample_append(cv_split, test_sample_index)\n",
    "        training_indices = []\n",
    "        for vector in cv_split[Not(test_sample_index)]\n",
    "                training_indices = [training_indices; vector]\n",
    "        end\n",
    "        return training_indices, cv_split[test_sample_index]\n",
    "end\n",
    "\n",
    "function dml(x, d, y, dreg, yreg, nfold)\n",
    "        n = length(y)\n",
    "        cv = [partition(eachindex(y), fill(1/nfold, nfold-1)..., shuffle = true, rng = 1234)...]\n",
    "        machine_y = machine(yreg, x, y, scitype_check_level=0)\n",
    "        machine_d = machine(dreg, x, d, scitype_check_level=0)\n",
    "        y_hat = zeros(n)\n",
    "        d_hat = zeros(n)\n",
    "\n",
    "        for fold in 1:nfold\n",
    "                training_fold, test_fold = training_sample_append(cv, fold)\n",
    "                y_hat[test_fold] = MLJ.predict(MLJ.fit!(machine_y, rows = training_fold), x[test_fold, :])\n",
    "                d_hat[test_fold] = MLJ.predict(MLJ.fit!(machine_d, rows = training_fold), x[test_fold, :])\n",
    "        end\n",
    "\n",
    "        resy = y .- y_hat\n",
    "        resd = reshape(d .- d_hat, (n, 1))\n",
    "        estimate = lm(resd, resy)\n",
    "        coef_est = GLM.coef(estimate)[1]\n",
    "        se = GLM.coeftable(estimate).cols[2][1]\n",
    "        println(\" coef (se) = \", coef_est ,\"(\",se,\")\")\n",
    "        return coef_est, se, resy, resd;\n",
    "end\n",
    "\n",
    "function summarize(point, stderr, resy, resd, name)\n",
    "        return DataFrame(\n",
    "                model = [name],\n",
    "                estimate = [point], stderr = [stderr], \n",
    "                rmse_y = [sqrt(mean(resy .^ 2))], \n",
    "                rmse_d = [sqrt(mean(resd .^ 2))]\n",
    "        )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coef (se) = -0.002498994254548932(0.01854254771822516)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:linear_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4766449219008604e-05, tolerance: 1.2710494136569487e-05\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.148575500389438e-05, tolerance: 1.8605991417077868e-05\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.3017015504833704e-05, tolerance: 1.8540756485160367e-05\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.181902827846875e-05, tolerance: 1.8540756485160367e-05\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.654451499540771e-05, tolerance: 1.653346616488934e-05\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.3294432057670983e-05, tolerance: 1.8540756485160367e-05\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\ALBERTO TRELLES\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.7262560883020703e-05, tolerance: 1.8540756485160367e-05\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coef (se) = -0.05500048033559874(0.014826076391788765)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coef (se) = -0.043474212201961(0.011897550482897243)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestRegressor(n_estimators = 100, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:lasso_cv_regressor, â€¦).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coef (se) = -0.04976058673871041(0.013047699858061956)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], â€¦), â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:neural_network_regressor, â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMLJFlux: converting input data to Float32\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coef (se) = 0.04481648198984531(0.014483980010207394)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>1Ã—5 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">model</th><th style = \"text-align: left;\">estimate</th><th style = \"text-align: left;\">stderr</th><th style = \"text-align: left;\">rmse_y</th><th style = \"text-align: left;\">rmse_d</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">NeuralNet</td><td style = \"text-align: right;\">0.0448165</td><td style = \"text-align: right;\">0.014484</td><td style = \"text-align: right;\">0.237082</td><td style = \"text-align: right;\">1.64866</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& model & estimate & stderr & rmse\\_y & rmse\\_d\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & NeuralNet & 0.0448165 & 0.014484 & 0.237082 & 1.64866 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1Ã—5 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0mâ”‚\u001b[1m model     \u001b[0m\u001b[1m estimate  \u001b[0m\u001b[1m stderr   \u001b[0m\u001b[1m rmse_y   \u001b[0m\u001b[1m rmse_d  \u001b[0m\n",
       "     â”‚\u001b[90m String    \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\n",
       "â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "   1 â”‚ NeuralNet  0.0448165  0.014484  0.237082  1.64866"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegressor = @load LinearRegressor pkg=MLJScikitLearnInterface verbosity=0\n",
    "dreg = Standardizer() |> LinearRegressor()\n",
    "yreg = Standardizer() |> LinearRegressor()\n",
    "result_ols = dml(x, d, y, dreg, yreg, 10)\n",
    "table_ols = summarize(result_ols..., \"OLS\")\n",
    "\n",
    "LassoCVRegressor = @load LassoCVRegressor pkg=MLJScikitLearnInterface verbosity=0\n",
    "dreg = Standardizer() |> LassoCVRegressor(max_iter=200000)\n",
    "yreg = Standardizer() |> LassoCVRegressor(max_iter=200000)\n",
    "results_lasso = dml(x, d, y, dreg, yreg, 10)\n",
    "table_lasso = summarize(results_lasso..., \"LassoCV\")\n",
    "\n",
    "RandomForestRegressor = @load RandomForestRegressor pkg=MLJScikitLearnInterface verbosity=0\n",
    "dreg = RandomForestRegressor()\n",
    "yreg = RandomForestRegressor()\n",
    "results_rf = dml(x, d, y, dreg, yreg, 10)\n",
    "table_rf = summarize(results_rf..., \"RF\")\n",
    "\n",
    "dreg = Standardizer() |> LassoCVRegressor(max_iter=200000)\n",
    "results_mix = dml(x, d, y, dreg , yreg, 10)\n",
    "table_mix = summarize(results_mix..., \"RF/LassoCV\")\n",
    "\n",
    "NeuralNetworkRegressor = @load NeuralNetworkRegressor pkg=MLJFlux verbosity=0 \n",
    "nn_model = NeuralNetworkRegressor(\n",
    "    builder = MLJFlux.MLP(; hidden=(20,20), Ïƒ=relu), \n",
    "    epochs = 100,\n",
    "    batch_size = 32,\n",
    "    optimiser = Flux.ADAM(0.001),\n",
    "    rng = 1234\n",
    ")\n",
    "dreg = Standardizer() |> nn_model\n",
    "yreg = Standardizer() |> nn_model\n",
    "results_nn = dml(x, d, y, dreg, yreg, 10)\n",
    "table_nn = summarize(results_nn..., \"NeuralNet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚\u001b[1m      model \u001b[0mâ”‚\u001b[1m    estimate \u001b[0mâ”‚\u001b[1m    stderr \u001b[0mâ”‚\u001b[1m    rmse_y \u001b[0mâ”‚\u001b[1m   rmse_d \u001b[0mâ”‚\n",
      "â”‚\u001b[90m     String \u001b[0mâ”‚\u001b[90m     Float64 \u001b[0mâ”‚\u001b[90m   Float64 \u001b[0mâ”‚\u001b[90m   Float64 \u001b[0mâ”‚\u001b[90m  Float64 \u001b[0mâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚        OLS â”‚ -0.00249899 â”‚ 0.0185425 â”‚ 0.0780211 â”‚ 0.445967 â”‚\n",
      "â”‚    LassoCV â”‚  -0.0550005 â”‚ 0.0148261 â”‚ 0.0541261 â”‚ 0.360134 â”‚\n",
      "â”‚         RF â”‚  -0.0434742 â”‚ 0.0118976 â”‚ 0.0465705 â”‚ 0.386905 â”‚\n",
      "â”‚ RF/LassoCV â”‚  -0.0497606 â”‚ 0.0130477 â”‚ 0.0478148 â”‚ 0.360134 â”‚\n",
      "â”‚  NeuralNet â”‚   0.0448165 â”‚  0.014484 â”‚  0.237082 â”‚  1.64866 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "pretty_table([table_ols; table_lasso; table_rf; table_mix; table_nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5Ã—5 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">model</th><th style = \"text-align: left;\">estimate</th><th style = \"text-align: left;\">stderr</th><th style = \"text-align: left;\">rmse_y</th><th style = \"text-align: left;\">rmse_d</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">OLS</td><td style = \"text-align: right;\">-0.00249899</td><td style = \"text-align: right;\">0.0185425</td><td style = \"text-align: right;\">0.0780211</td><td style = \"text-align: right;\">0.445967</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">LassoCV</td><td style = \"text-align: right;\">-0.0550005</td><td style = \"text-align: right;\">0.0148261</td><td style = \"text-align: right;\">0.0541261</td><td style = \"text-align: right;\">0.360134</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">RF</td><td style = \"text-align: right;\">-0.0434742</td><td style = \"text-align: right;\">0.0118976</td><td style = \"text-align: right;\">0.0465705</td><td style = \"text-align: right;\">0.386905</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">RF/LassoCV</td><td style = \"text-align: right;\">-0.0497606</td><td style = \"text-align: right;\">0.0130477</td><td style = \"text-align: right;\">0.0478148</td><td style = \"text-align: right;\">0.360134</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">NeuralNet</td><td style = \"text-align: right;\">0.0448165</td><td style = \"text-align: right;\">0.014484</td><td style = \"text-align: right;\">0.237082</td><td style = \"text-align: right;\">1.64866</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& model & estimate & stderr & rmse\\_y & rmse\\_d\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & OLS & -0.00249899 & 0.0185425 & 0.0780211 & 0.445967 \\\\\n",
       "\t2 & LassoCV & -0.0550005 & 0.0148261 & 0.0541261 & 0.360134 \\\\\n",
       "\t3 & RF & -0.0434742 & 0.0118976 & 0.0465705 & 0.386905 \\\\\n",
       "\t4 & RF/LassoCV & -0.0497606 & 0.0130477 & 0.0478148 & 0.360134 \\\\\n",
       "\t5 & NeuralNet & 0.0448165 & 0.014484 & 0.237082 & 1.64866 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5Ã—5 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0mâ”‚\u001b[1m model      \u001b[0m\u001b[1m estimate    \u001b[0m\u001b[1m stderr    \u001b[0m\u001b[1m rmse_y    \u001b[0m\u001b[1m rmse_d   \u001b[0m\n",
       "     â”‚\u001b[90m String     \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64  \u001b[0m\n",
       "â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "   1 â”‚ OLS         -0.00249899  0.0185425  0.0780211  0.445967\n",
       "   2 â”‚ LassoCV     -0.0550005   0.0148261  0.0541261  0.360134\n",
       "   3 â”‚ RF          -0.0434742   0.0118976  0.0465705  0.386905\n",
       "   4 â”‚ RF/LassoCV  -0.0497606   0.0130477  0.0478148  0.360134\n",
       "   5 â”‚ NeuralNet    0.0448165   0.014484   0.237082   1.64866"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcat(table_ols, table_lasso, table_rf, table_mix, table_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Julia on Colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Julia 1.12",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
