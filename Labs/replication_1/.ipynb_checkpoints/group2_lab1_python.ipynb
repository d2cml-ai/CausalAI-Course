{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Grupo 2:\r\n",
    "- Diego Gomez \r\n",
    "- Kiara Hugo \r\n",
    "- Alexander Pacheco \r\n",
    "- Claudia Vivas "
   ],
   "metadata": {
    "papermill": {
     "duration": 0.020568,
     "end_time": "2021-02-21T17:17:47.770707",
     "exception": false,
     "start_time": "2021-02-21T17:17:47.750139",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# An inferential problem: The Gender Wage Gap"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.018579,
     "end_time": "2021-02-21T17:17:47.809138",
     "exception": false,
     "start_time": "2021-02-21T17:17:47.790559",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is the difference in predicted wages between men and women with the same job-relevant characteristics?\r\n",
    "\r\n",
    "Thus, we analyze if there is a difference in the payment of men and women (*gender wage gap*). The gender wage gap may partly reflect *discrimination* against women in the labor market or may partly reflect a *selection effect*, namely that women are relatively more likely to take on occupations that pay somewhat less (for example, school teaching)."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.019386,
     "end_time": "2021-02-21T17:17:47.847419",
     "exception": false,
     "start_time": "2021-02-21T17:17:47.828033",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To investigate the gender wage gap, we consider the following log-linear regression model\r\n",
    "\r\n",
    "\\begin{align}\r\n",
    "\\log(Y) &= \\beta'X + \\epsilon\\\\\r\n",
    "&= \\beta_1 D  + \\beta_2' W + \\epsilon,\r\n",
    "\\end{align}\r\n",
    "\r\n",
    "where $D$ is the indicator of being female ($1$ if female and $0$ otherwise) and the\r\n",
    "$W$'s are controls explaining variation in wages. Considering transformed wages by the logarithm, we are analyzing the relative difference in the payment of men and women."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.018623,
     "end_time": "2021-02-21T17:17:47.884840",
     "exception": false,
     "start_time": "2021-02-21T17:17:47.866217",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data analysis"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.018169,
     "end_time": "2021-02-21T17:17:47.921363",
     "exception": false,
     "start_time": "2021-02-21T17:17:47.903194",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We consider the same subsample of the U.S. Current Population Survey (2015) as in the previous lab. Let us load the data set."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.018446,
     "end_time": "2021-02-21T17:17:47.958377",
     "exception": false,
     "start_time": "2021-02-21T17:17:47.939931",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import pyreadr\r\n",
    "import math"
   ],
   "outputs": [],
   "metadata": {
    "hide_input": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "rdata_read = pyreadr.read_r(\"../data/wage2015_subsample_inference.Rdata\")\r\n",
    "\r\n",
    "# Extracting the data frame from rdata_read\r\n",
    "data = rdata_read[ 'data' ]\r\n",
    "\r\n",
    "data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5150, 20)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To start our (causal) analysis, we compare the sample means given gender:"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.020145,
     "end_time": "2021-02-21T17:17:48.235598",
     "exception": false,
     "start_time": "2021-02-21T17:17:48.215453",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "Z = data[ [\"lwage\",\"sex\",\"shs\",\"hsg\",\"scl\",\"clg\",\"ad\",\"ne\",\"mw\",\"so\",\"we\",\"exp1\"] ]\r\n",
    "\r\n",
    "data_female = data[data[ 'sex' ] == 1 ]\r\n",
    "Z_female = data_female[ [\"lwage\",\"sex\",\"shs\",\"hsg\",\"scl\",\"clg\",\"ad\",\"ne\",\"mw\",\"so\",\"we\",\"exp1\"] ]\r\n",
    "\r\n",
    "data_male = data[ data[ 'sex' ] == 0 ]\r\n",
    "Z_male = data_male[ [ \"lwage\",\"sex\",\"shs\",\"hsg\",\"scl\",\"clg\",\"ad\",\"ne\",\"mw\",\"so\",\"we\",\"exp1\" ] ]\r\n",
    "\r\n",
    "\r\n",
    "table = np.zeros( (12, 3) )\r\n",
    "table[:, 0] = Z.mean().values\r\n",
    "table[:, 1] = Z_male.mean().values\r\n",
    "table[:, 2] = Z_female.mean().values\r\n",
    "table_pandas = pd.DataFrame( table, columns = [ 'All', 'Men', 'Women'])\r\n",
    "table_pandas.index = [\"Log Wage\",\"Sex\",\"Less then High School\",\"High School Graduate\",\"Some College\",\"Gollage Graduate\",\"Advanced Degree\", \"Northeast\",\"Midwest\",\"South\",\"West\",\"Experience\"]\r\n",
    "table_html = table_pandas.to_html()\r\n",
    "\r\n",
    "table_pandas"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Log Wage</th>\n",
       "      <td>2.970787</td>\n",
       "      <td>2.987830</td>\n",
       "      <td>2.949485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.444466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Less then High School</th>\n",
       "      <td>0.023301</td>\n",
       "      <td>0.031807</td>\n",
       "      <td>0.012669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High School Graduate</th>\n",
       "      <td>0.243883</td>\n",
       "      <td>0.294303</td>\n",
       "      <td>0.180865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some College</th>\n",
       "      <td>0.278058</td>\n",
       "      <td>0.273331</td>\n",
       "      <td>0.283967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gollage Graduate</th>\n",
       "      <td>0.317670</td>\n",
       "      <td>0.293953</td>\n",
       "      <td>0.347313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Advanced Degree</th>\n",
       "      <td>0.137087</td>\n",
       "      <td>0.106606</td>\n",
       "      <td>0.175186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northeast</th>\n",
       "      <td>0.227767</td>\n",
       "      <td>0.221950</td>\n",
       "      <td>0.235037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Midwest</th>\n",
       "      <td>0.259612</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.260376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>0.296505</td>\n",
       "      <td>0.298148</td>\n",
       "      <td>0.294452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>0.216117</td>\n",
       "      <td>0.220902</td>\n",
       "      <td>0.210135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experience</th>\n",
       "      <td>13.760583</td>\n",
       "      <td>13.783992</td>\n",
       "      <td>13.731324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             All        Men      Women\n",
       "Log Wage                2.970787   2.987830   2.949485\n",
       "Sex                     0.444466   0.000000   1.000000\n",
       "Less then High School   0.023301   0.031807   0.012669\n",
       "High School Graduate    0.243883   0.294303   0.180865\n",
       "Some College            0.278058   0.273331   0.283967\n",
       "Gollage Graduate        0.317670   0.293953   0.347313\n",
       "Advanced Degree         0.137087   0.106606   0.175186\n",
       "Northeast               0.227767   0.221950   0.235037\n",
       "Midwest                 0.259612   0.259000   0.260376\n",
       "South                   0.296505   0.298148   0.294452\n",
       "West                    0.216117   0.220902   0.210135\n",
       "Experience             13.760583  13.783992  13.731324"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In particular, the table above shows that the difference in average *logwage* between men and women is equal to $0,038$"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.020634,
     "end_time": "2021-02-21T17:17:48.532828",
     "exception": false,
     "start_time": "2021-02-21T17:17:48.512194",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data_female['lwage'].mean() - data_male['lwage'].mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.03834473367441493"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus, the unconditional gender wage gap is about $3,8$\\% for the group of never married workers (women get paid less on average in our sample). We also observe that never married working women are relatively more educated than working men and have lower working experience."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.022161,
     "end_time": "2021-02-21T17:17:48.635417",
     "exception": false,
     "start_time": "2021-02-21T17:17:48.613256",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This unconditional (predictive) effect of gender equals the coefficient $\\beta$ in the univariate ols regression of $Y$ on $D$:\n",
    "\n",
    "\\begin{align}\n",
    "\\log(Y) &=\\beta D + \\epsilon.\n",
    "\\end{align}"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.02073,
     "end_time": "2021-02-21T17:17:48.677447",
     "exception": false,
     "start_time": "2021-02-21T17:17:48.656717",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We verify this by running an ols regression in R."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.020929,
     "end_time": "2021-02-21T17:17:48.718630",
     "exception": false,
     "start_time": "2021-02-21T17:17:48.697701",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import statsmodels.api as sm\r\n",
    "import statsmodels.formula.api as smf"
   ],
   "outputs": [],
   "metadata": {
    "hide_input": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "nocontrol_model = smf.ols( formula = 'lwage ~ sex', data = data )\r\n",
    "nocontrol_est = nocontrol_model.fit().summary2().tables[1]['Coef.']['sex']\r\n",
    "HCV_coefs = nocontrol_model.fit().cov_HC0\r\n",
    "nocontrol_se = np.power( HCV_coefs.diagonal() , 0.5)[1]\r\n",
    "\r\n",
    "# print unconditional effect of gender and the corresponding standard error\r\n",
    "print( f'The estimated gender coefficient is {nocontrol_est} and the corresponding robust standard error is {nocontrol_se}' )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The estimated gender coefficient is -0.038344733674415696 and the corresponding robust standard error is 0.015901935079095802\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the standard error is computed with the *R* package *sandwich* to be robust to heteroskedasticity. \n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.02196,
     "end_time": "2021-02-21T17:17:48.991015",
     "exception": false,
     "start_time": "2021-02-21T17:17:48.969055",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we run an ols regression of $Y$ on $(D,W)$ to control for the effect of covariates summarized in $W$:\n",
    "\n",
    "\\begin{align}\n",
    "\\log(Y) &=\\beta_1 D  + \\beta_2' W + \\epsilon.\n",
    "\\end{align}\n",
    "\n",
    "Here, we are considering the flexible model from the previous lab. Hence, $W$ controls for experience, education, region, and occupation and industry indicators plus transformations and two-way interactions."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.021605,
     "end_time": "2021-02-21T17:17:49.034485",
     "exception": false,
     "start_time": "2021-02-21T17:17:49.012880",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us run the ols regression with controls."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.021109,
     "end_time": "2021-02-21T17:17:49.076809",
     "exception": false,
     "start_time": "2021-02-21T17:17:49.055700",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ols regression with controls"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "flex = 'lwage ~ sex + (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)'\r\n",
    "\r\n",
    "# The smf api replicates R script when it transform data\r\n",
    "control_model = smf.ols( formula = flex, data = data )\r\n",
    "control_est = control_model.fit().summary2().tables[1]['Coef.']['sex']\r\n",
    "\r\n",
    "print(control_model.fit().summary2().tables[1])\r\n",
    "print( f\"Coefficient for OLS with controls {control_est}\" )\r\n",
    "\r\n",
    "HCV_coefs = control_model.fit().cov_HC0\r\n",
    "control_se = np.power( HCV_coefs.diagonal() , 0.5)[1]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "               Coef.  Std.Err.          t         P>|t|    [0.025    0.975]\n",
      "Intercept   3.279677  0.284196  11.540202  2.037819e-30  2.722526  3.836828\n",
      "occ2[T.10]  0.020954  0.156498   0.133896  8.934903e-01 -0.285852  0.327761\n",
      "occ2[T.11] -0.642418  0.309090  -2.078417  3.772286e-02 -1.248372 -0.036463\n",
      "occ2[T.12] -0.067477  0.252049  -0.267716  7.889294e-01 -0.561605  0.426651\n",
      "occ2[T.13] -0.232978  0.231538  -1.006220  3.143593e-01 -0.686896  0.220940\n",
      "...              ...       ...        ...           ...       ...       ...\n",
      "exp4:scl    0.021076  0.024529   0.859230  3.902557e-01 -0.027012  0.069164\n",
      "exp4:clg    0.007869  0.022753   0.345868  7.294565e-01 -0.036736  0.052475\n",
      "exp4:mw     0.006244  0.015870   0.393446  6.940073e-01 -0.024868  0.037356\n",
      "exp4:so     0.000314  0.013628   0.023075  9.815913e-01 -0.026402  0.027031\n",
      "exp4:we     0.001768  0.015960   0.110804  9.117763e-01 -0.029521  0.033058\n",
      "\n",
      "[246 rows x 6 columns]\n",
      "Coefficient for OLS with controls -0.06955320329684715\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The estimated regression coefficient $\\beta_1\\approx-0.0696$ measures how our linear prediction of wage changes if we set the gender variable $D$ from 0 to 1, holding the controls $W$ fixed.\n",
    "We can call this the *predictive effect* (PE), as it measures the impact of a variable on the prediction we make. Overall, we see that the unconditional wage gap of size $4$\\% for women increases to about $7$\\% after controlling for worker characteristics.  \n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.040523,
     "end_time": "2021-02-21T17:17:49.873210",
     "exception": false,
     "start_time": "2021-02-21T17:17:49.832687",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we are using the Frisch-Waugh-Lovell theorem from the lecture partialling-out the linear effect of the controls via ols."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.023222,
     "end_time": "2021-02-21T17:17:49.931749",
     "exception": false,
     "start_time": "2021-02-21T17:17:49.908527",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Partialling-Out using ols"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# models\r\n",
    "# model for Y\r\n",
    "flex_y = 'lwage ~  (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)'\r\n",
    "# model for D\r\n",
    "flex_d = 'sex ~ (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)' \r\n",
    "\r\n",
    "# partialling-out the linear effect of W from Y\r\n",
    "t_Y = smf.ols( formula = flex_y , data = data ).fit().resid\r\n",
    "\r\n",
    "# partialling-out the linear effect of W from D\r\n",
    "t_D = smf.ols( formula = flex_d , data = data ).fit().resid\r\n",
    "\r\n",
    "data_res = pd.DataFrame( np.vstack(( t_Y.values , t_D.values )).T , columns = [ 't_Y', 't_D' ] )\r\n",
    "# regression of Y on D after partialling-out the effect of W\r\n",
    "partial_fit =  smf.ols( formula = 't_Y ~ t_D' , data = data_res ).fit()\r\n",
    "partial_est = partial_fit.summary2().tables[1]['Coef.']['t_D']\r\n",
    "\r\n",
    "print(\"Coefficient for D via partialling-out\", partial_est)\r\n",
    "\r\n",
    "# standard error\r\n",
    "HCV_coefs = partial_fit.cov_HC0\r\n",
    "partial_se = np.power( HCV_coefs.diagonal() , 0.5)[1]\r\n",
    "\r\n",
    "# confidence interval\r\n",
    "partial_fit.conf_int( alpha=0.05 ).iloc[1, :]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Coefficient for D via partialling-out -0.06955320329684608\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0   -0.098671\n",
       "1   -0.040435\n",
       "Name: t_D, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again, the estimated coefficient measures the linear predictive effect (PE) of $D$ on $Y$ after taking out the linear effect of $W$ on both of these variables. This coefficient equals the estimated coefficient from the ols regression with controls."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.023907,
     "end_time": "2021-02-21T17:17:50.458203",
     "exception": false,
     "start_time": "2021-02-21T17:17:50.434296",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Frisch-Waugh-Lovell\r\n",
    "\r\n",
    "In the linear least squares regression of vector y on two sets of variables, $X_1$ and $X_2$, the subvector $b_2$ is the set of coefficients obtained when the residuals from a regression of y on $X_1$ alone are regressed on the set of residuals obtained when each\r\n",
    "column of $X_2$ is regressed on $X_1$.\r\n",
    "\r\n",
    "Suppose that the regression involves two sets of variables, $X_1$ and $X_2$. Thus,\r\n",
    "\r\n",
    "$$y = X\\beta + \\varepsilon = X_1\\beta_1 + X_2\\beta_2 + \\varepsilon $$\r\n",
    "\r\n",
    "We want to know $\\beta_2$. Nevertheless, the two sets of variables $X_1$ and $X_2$ are not orthogonal, then Frisch-Waugh-Lovell theorem is needed. \r\n",
    "What is the algebraic solution for $\\beta_2$? A solution can be obtained by using the partitioned inverse matrix.\r\n",
    "\r\n",
    "$$\r\n",
    "\\left(\\begin{array}{cc} \r\n",
    "X_1'X_1 & X_1'X_2\\\\\r\n",
    "X_2'X_1 & X_2'X_2\r\n",
    "\\end{array}\\right)\r\n",
    "\\left(\\begin{array}{cc} \r\n",
    "b_1 \\\\ \r\n",
    "b_2 \r\n",
    "\\end{array}\\right)\r\n",
    "=\r\n",
    "\\left(\\begin{array}{cc} \r\n",
    "X_1'y \\\\ \r\n",
    "X_2'y\r\n",
    "\\end{array}\\right)\r\n",
    "$$ \r\n",
    "\r\n",
    "First, we solve $\\beta_1$, where $\\beta_1$ is the set of coefficientes of $y$ on $X_1$.\r\n",
    "$$ X_1'X_1b_1 + X_1'X_2b_2=X_1'y $$\r\n",
    "$$b_1 = (X_1'X_1)^-1X'_1y - (X'_1X_1)^-1X'_1X_2b_2 $$\r\n",
    "\r\n",
    "Then, use the second equation of the partitioned inverse matrix.\r\n",
    "$$ X_2'X_1b_1 + X_2'X_2b_2=X_2'y $$\r\n",
    "\r\n",
    "Now, insert the result for $\\beta_1$. This produces:\r\n",
    "$$X_2'X_1(X_1'X_1)^-1X'_1y-X'_2X_1(X'_1X_1)^-1X'_1X_2b_2+X'_2X_2b_2=X'_2y$$\r\n",
    "$$X_2'(I-X_1(X_1'X_1)^-1y=X_2'(I-X_1(X_1'X_1)^-1)X_2b_2$$\r\n",
    "$$b_2 =[X_2'(I-X_1(X_1'X_1)^-1)X_2]^-1[X_2'(I-X_1(X_1'X_1)^-1)y]$$\r\n",
    "\r\n",
    "The $M_1$ matrix is the residual maker:\r\n",
    "$$M_1=I-X_1(X_1'X_1)^-1$$\r\n",
    "\r\n",
    "Insert $M_1$ in the equiation below:\r\n",
    "$$b_2 =[X_2'M_1X_2]^-1[X_2'M_1y]$$\r\n",
    "\r\n",
    "Thus, $M_1X_2$ is a matrix of residuals in the regression of $X_2$ on $X_1$, and $M_1y$  is a matrix of residuals in the regression of $y$ in $X_1$. By exploiting the fact that $M_1$ is symmetric and idempotent, we can rewrite the equation as:\r\n",
    "\r\n",
    "$X_2*=M_1X_2$ and $y*=M_1y$ \r\n",
    "$$b_2=(X'_2*X_2*)^-1X'_2*y*$$\r\n",
    "â€‹ \r\n",
    "This process is commonly called partialing out or netting out the effect of $X_1$.\r\n",
    "\r\n",
    "On the other hand, If we follow the algorithm seen in class we can reach the same result. In essence, the demonstration above follows the same algorithm, however, the following demonstration may be easier to understand.\r\n",
    "\r\n",
    "Suppose that the regression involves two sets of variables, $X_1$ and $X_2$. Thus,\r\n",
    "\r\n",
    "$$y = X\\beta + \\varepsilon = X_1\\beta_1 + X_2\\beta_2 + \\varepsilon $$\r\n",
    "\r\n",
    "To find $\\beta_2$ follow the next algorithm:\r\n",
    "\r\n",
    "1. Regress $y$ on $X_2$, obtain residual $u_1$\r\n",
    "2. Regress $X_1$ on $X_2$, obtain residual $u_2$\r\n",
    "3. Regress $u_1$ on $u_2$, obtain OLS estimates $b_1$\r\n",
    "\r\n",
    "$$y=X_1\\beta_1+u_1$$    \r\n",
    "$$\\beta_1=(X'_1X_1)^-1(X'_1y)$$\r\n",
    "$$X_2=X_1\\beta_2+u_2$$\r\n",
    "$$\\beta_2=(X'_1X_1)^-1(X'_1X_2)$$\r\n",
    "\r\n",
    "$$y-X_1\\beta_1=u_1$$\r\n",
    "\r\n",
    "Insert $D_1$:\r\n",
    "$$y-[X_1(X'_1X_1)^-1(X'_1y)]=e_1$$\r\n",
    "$$[I-(X'_1X_1)^-1(X'_1)]y= e_1$$\r\n",
    "$$M_1y=e_1$$\r\n",
    "\r\n",
    "Remember the $M_1=I-X_1(X_1'X_1)^-1$ matrix is the residual maker. Then, the estimated residuals are:\r\n",
    "$$e_1=M_1y$$\r\n",
    "$$e_2=M_2X_2$$\r\n",
    "\r\n",
    "Now, we regress $e_1$ on $e_2$:\r\n",
    "\r\n",
    "$$e_1=e_2\\beta_1+\\varepsilon$$\r\n",
    "$$b_1=(e_2'e_2)^-1(e_2'e_1)$$\r\n",
    "\r\n",
    "Insert estimated residual $e_1$ and $e_2$:\r\n",
    "$$b_1=(M_2X_2)'(M_2X_2)^-1[(M_2X_2)'(M_1X_1)]$$\r\n",
    "$$b_1=(X_2'M_2'M_2X_2)^-1(X_2'M_2'M_1y) $$\r\n",
    "\r\n",
    "Regarding, $M_2$ is symmetric and idempotent. \r\n",
    "$X_2*=M_1X_2$ and $y*=M_1y$ \r\n",
    "$$b_2=(X'_2*X_2*)^-1X'_2*y*$$\r\n",
    "\r\n",
    "This theorem shows the pure effect of the exogenous variables that are of interest, this result is the same that would have been obtained if the model had been regressed with all the variables."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}