{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d92f507",
   "metadata": {},
   "source": [
    "# 1. Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "37e22508",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "### Python port of help_functions.R\n",
    "### https://github.com/cran/hdm/blob/master/R/help_functions.R\n",
    "################################################################################\n",
    "\n",
    "################################################################################\n",
    "### 1: Load modules\n",
    "################################################################################\n",
    "\n",
    "# Standard Python modules\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression as lm\n",
    "\n",
    "################################################################################\n",
    "### 2: Define functions\n",
    "################################################################################\n",
    "\n",
    "################################################################################\n",
    "### 2.1: Functions which are not in the original R package\n",
    "###      These are generally helper functions to allow an implementation which\n",
    "###      reads as closely to the original R code as possible, and to ease a\n",
    "###      Python implementation\n",
    "################################################################################\n",
    "\n",
    "\n",
    "# Define a function which turn a list or vector-like object into a proper two\n",
    "# dimensional column vector\n",
    "def cvec(a):\n",
    "    \"\"\" Turn a list or vector-like object into a proper column vector\n",
    "\n",
    "    Input\n",
    "    a: List or vector-like object, has to be a potential input for np.array()\n",
    "\n",
    "    Output\n",
    "    vec: two dimensional NumPy array, with the first dimension weakly greater\n",
    "         than the second (resulting in a column vector for a vector-like input)\n",
    "    \"\"\"\n",
    "    # Conver input into a two dimensional NumPy array\n",
    "    vec = np.array(a, ndmin=2)\n",
    "\n",
    "    # Check whether the second dimension is strictly greater than the first\n",
    "    # (remembering Python's zero indexing)\n",
    "    if vec.shape[0] < vec.shape[1]:\n",
    "        # If so, transpose the input vector\n",
    "        vec = vec.T\n",
    "\n",
    "    # Return the column vector\n",
    "    return vec\n",
    "\n",
    "\n",
    "# Define a function to mimic R's cor() function, which can take two matrices and\n",
    "# return the correlation coefficients between the columns of the first and the\n",
    "# columns of the second matrix\n",
    "def cor(y, X):\n",
    "    \"\"\" Return correlation coefficients between columns of matrices\n",
    "\n",
    "    Inputs\n",
    "    y: n by 1 NumPy array\n",
    "    X: n by k NumPy array\n",
    "\n",
    "    Outputs\n",
    "    corr: list of length k, where the k-th element is the correlation\n",
    "          coefficient between y and the k-th column of X\n",
    "    \"\"\"\n",
    "    # Concatenate y and X into a single NumPy array\n",
    "    yX = np.concatenate([y, X], axis=1)\n",
    "\n",
    "    # Get the correlation coefficients between all columns of that array\n",
    "    corr = np.corrcoef(yX, rowvar=False)\n",
    "\n",
    "    # Get the first row, starting at the first off-diagonal element (these are\n",
    "    # the correlation coefficients between y and each column of X\n",
    "    corr = corr[0,1:]\n",
    "\n",
    "    # Return the result\n",
    "    return corr\n",
    "\n",
    "################################################################################\n",
    "### 2.2: Functions which are in the original R package\n",
    "################################################################################\n",
    "\n",
    "\n",
    "# Define a function which returns initial parameter guesses\n",
    "def init_values(X, y, number=5, intercept=True):\n",
    "    \"\"\" Return an initial parameter guess for a LASSO model\n",
    "\n",
    "    Inputs\n",
    "    y: n by 1 NumPy array, outcome variable\n",
    "    X: n by k NumPy array, RHS variables\n",
    "\n",
    "    Outputs\n",
    "    residuals: n ny 1 NumPy array, residuals for initial parameter guess\n",
    "    coefficients: k by 1 NumPy array, initial coefficient values\n",
    "    \"\"\"\n",
    "    # Make sure y is a proper column vector\n",
    "    y = cvec(y)\n",
    "\n",
    "    # Get the absolute value of correlations between y and X\n",
    "    corr = np.abs(cor(y, X))\n",
    "\n",
    "    # Get the number of columns of X\n",
    "    kx = X.shape[1]\n",
    "\n",
    "    # Make an index selecting the five columns of X which are most correlated\n",
    "    # with y (since .argsort() always sorts in increasing order, selecting from\n",
    "    # the back gets the most highly correlated columns)\n",
    "    index = corr.argsort()[-np.amin([number, kx]):]\n",
    "\n",
    "    # Set up an array of coefficient guesses\n",
    "    coefficients = np.zeros(shape=(kx, 1))\n",
    "\n",
    "    # Regress y on the five most correlated columns of X, including an intercept\n",
    "    # if desired\n",
    "    reg = lm(fit_intercept=intercept).fit(X[:, index], y)\n",
    "\n",
    "    # Replace the guesses for the estimated coefficients (note that .coef_ does\n",
    "    # not return the estimated intercept, if one was included in the model)\n",
    "    coefficients[index, :] = reg.coef_.T\n",
    "\n",
    "    # Replace any NANs as zeros\n",
    "    coefficients[np.isnan(coefficients)] = 0\n",
    "\n",
    "    # Get the regression residuals\n",
    "    residuals = y - reg.predict(X[:, index])\n",
    "\n",
    "    # Return the residuals and coefficients\n",
    "    return {'residuals': residuals, 'coefficients': coefficients}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2807dcdd",
   "metadata": {},
   "source": [
    "# 2. LassoShooting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6749049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "### Python port of LassoShooting.fit.R\n",
    "### https://github.com/cran/hdm/blob/master/R/LassoShooting.fit.R\n",
    "################################################################################\n",
    "\n",
    "################################################################################\n",
    "### 1: Load modules\n",
    "################################################################################\n",
    "\n",
    "# Standard Python modules\n",
    "import numpy as np\n",
    "\n",
    "# Other parts of hdmpy\n",
    "from hdmpy.help_functions import cvec, init_values\n",
    "\n",
    "################################################################################\n",
    "### 2: Define function\n",
    "################################################################################\n",
    "\n",
    "# Define shooting LASSO with variable dependent penalty terms\n",
    "def LassoShooting_fit(x, y, lmbda, maxIter=1000, optTol=10**(-5),\n",
    "                      zeroThreshold=10**(-6), XX=None, Xy=None,\n",
    "                      beta_start=None):\n",
    "    \"\"\" Shooting LASSO algorithm with variable dependent penalty weights\n",
    "\n",
    "    Inputs\n",
    "    x: n by p NumPy array, RHS variables\n",
    "    y: n by 1 NumPy array, outcome variable\n",
    "    lmbda: p by 1 NumPy array, variable dependent penalty terms. The j-th\n",
    "           element is the penalty term for the j-th RHS variable.\n",
    "    maxIter: integer, maximum number of shooting LASSO updated\n",
    "    optTol: scalar, algorithm terminated once the sum of absolute differences\n",
    "            between the updated and current weights is below optTol\n",
    "    zeroThreshold: scalar, if any final weights are below zeroThreshold, they\n",
    "                   will be set to zero instead\n",
    "    XX: k by k NumPy array, pre-calculated version of x'x\n",
    "    Xy: k by 1 NumPy array, pre-calculated version of x'y\n",
    "    beta_start: k by 1 NumPy array, initial weights\n",
    "\n",
    "    Outputs\n",
    "    w: k by 1 NumPy array, final weights\n",
    "    wp: k by m + 1 NumPy array, where m is the number of iterations the\n",
    "        algorithm took. History of weight updates, starting with the initial\n",
    "        weights.\n",
    "    m: integer, number of iterations the algorithm took\n",
    "    \"\"\"\n",
    "    # Make sure that y and lmbda are proper column vectors\n",
    "    y = cvec(y)\n",
    "    lmbda = cvec(lmbda)\n",
    "\n",
    "    # Get number of observations n and number of variables p\n",
    "    n, p = x.shape\n",
    "\n",
    "    # Check whether XX and Xy were provided, calculate them if not\n",
    "    if XX is None:\n",
    "        XX = x.T @ x\n",
    "    if Xy is None:\n",
    "        Xy = x.T @ y\n",
    "\n",
    "    # Check whether an initial value for the intercept was provided\n",
    "    if beta_start is None:\n",
    "        # If not, use init_values from help_functions, which will return\n",
    "        # regression estimates for the five variables in x which are most\n",
    "        # correlated with y, and initialize all other coefficients as zero\n",
    "        beta = init_values(x, y, intercept=False)['coefficients']\n",
    "    else:\n",
    "        # Otherwise, use the provided initial weights\n",
    "        beta = beta_start\n",
    "\n",
    "    # Set up a history of weights over time, starting with the initial ones\n",
    "    wp = beta\n",
    "\n",
    "    # Keep track of the number of iterations\n",
    "    m = 1\n",
    "\n",
    "    # Create versions of XX and Xy which are just those matrices times two\n",
    "    XX2 = XX * 2\n",
    "    Xy2 = Xy * 2\n",
    "\n",
    "    # Go through all iterations\n",
    "    while m < maxIter:\n",
    "        # Save the last set of weights (the .copy() is important, otherwise\n",
    "        # beta_old will be updated every time beta is changed during the\n",
    "        # following loop)\n",
    "        beta_old = beta.copy()\n",
    "\n",
    "        # Go through all parameters\n",
    "        for j in np.arange(p):\n",
    "            # Calculate the shoot\n",
    "            S0 = XX2[j,:] @ beta - XX2[j,j] * beta[j,0] - Xy2[j,0]\n",
    "\n",
    "            # Update the weights\n",
    "            if np.isnan(S0).sum() >= 1:\n",
    "                beta[j] = 0\n",
    "            elif S0 > lmbda[j]:\n",
    "                beta[j] = (lmbda[j] - S0) / XX2[j,j]\n",
    "            elif S0 < -lmbda[j]:\n",
    "                beta[j] = (-lmbda[j] - S0) / XX2[j,j]\n",
    "            elif np.abs(S0) <= lmbda[j]:\n",
    "                beta[j] = 0\n",
    "\n",
    "        # Add the updated weights to the history of weights\n",
    "        wp = np.concatenate([wp, beta], axis=1)\n",
    "\n",
    "        # Check whether the weights are within tolerance\n",
    "        if np.abs(beta - beta_old).sum() < optTol:\n",
    "            # If so, break the while loop\n",
    "            break\n",
    "\n",
    "        # Increase the iteration counter\n",
    "        m = m + 1\n",
    "\n",
    "    # Set the final weights to the last updated weights\n",
    "    w = beta\n",
    "\n",
    "    # Set weights which are within zeroThreshold to zero\n",
    "    w[np.abs(w) < zeroThreshold] = 0\n",
    "\n",
    "    # Return the weights, history of weights, and iteration counter\n",
    "    return {'coefficients': w, 'coef.list': wp, 'num.it': m}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8bd53980",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "### Python port of rlasso.R\n",
    "### https://github.com/cran/hdm/blob/master/R/rlasso.R\n",
    "################################################################################\n",
    "\n",
    "################################################################################\n",
    "### 1: Load modules\n",
    "################################################################################\n",
    "\n",
    "# Standard Python modules\n",
    "import joblib as jbl\n",
    "import multiprocess as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LinearRegression as lm\n",
    "\n",
    "# Other parts of hdmpy\n",
    "from hdmpy.help_functions import cvec, init_values\n",
    "from hdmpy.LassoShooting_fit import LassoShooting_fit\n",
    "\n",
    "################################################################################\n",
    "### 2: Define functions\n",
    "################################################################################\n",
    "\n",
    "################################################################################\n",
    "### 2.1: Functions which are not in the original R package\n",
    "###      These are generally helper functions to allow an implementation which\n",
    "###      reads as closely to the original R code as possible, and to ease a\n",
    "###      Python implementation, including parallelizing the code\n",
    "################################################################################\n",
    "\n",
    "\n",
    "# Define a function to simulate distributions needed for calculating X-dependent\n",
    "# penalty terms\n",
    "def simul_pen(n, p, W, seed=0, fix_seed=True):\n",
    "    # Check whether the seed needs to be fixed\n",
    "    if fix_seed:\n",
    "        # Simulate with provided seed\n",
    "        g = norm.rvs(size=(n,1), random_state=seed) @ np.ones(shape=(1,p))\n",
    "    else:\n",
    "        # Simulate using whatever state the RNG is currently in\n",
    "        g = norm.rvs(size=(n,1)) @ np.ones(shape=(1,p))\n",
    "\n",
    "    # Calculate element of the distribution for the current draw of g\n",
    "    s = n * np.amax(2 * np.abs(np.mean(W * g, axis=0)))\n",
    "\n",
    "    # Return the result\n",
    "    return s\n",
    "\n",
    "################################################################################\n",
    "### 2.2: Functions which are in the original R package\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def lambdaCalculation(homoskedastic=False, X_dependent_lambda=False,\n",
    "                      lambda_start=None, c=1.1, gamma=0.1, numSim=5000, y=None,\n",
    "                      x=None, par=True, corecap=np.inf, fix_seed=True):\n",
    "    # Get number of observations n and number of variables p\n",
    "    n, p = x.shape\n",
    "\n",
    "    # Get number of simulations to use (if simulations are necessary)\n",
    "    R = numSim\n",
    "\n",
    "    # Go through all possible combinations of homoskedasticy/heteroskedasticity\n",
    "    # and X-dependent or independent error terms. The first two cases are\n",
    "    # special cases: Handling the case there homoskedastic was set to None, and\n",
    "    # where lambda_start was provided.\n",
    "    #\n",
    "    # 1) If homoskedastic was set to None (special case)\n",
    "    if homoskedastic is None:\n",
    "        # Initialize lambda\n",
    "        lmbda0 = lambda_start\n",
    "\n",
    "        Ups0 = (1 / np.sqrt(n)) * np.sqrt((y**2).T @ (x**2)).T\n",
    "\n",
    "        # Calculate the final vector of penalty terms\n",
    "        lmbda = lmbda0 * Ups0\n",
    "\n",
    "    # 2) If lambda_start was provided (special case)\n",
    "    elif lambda_start is not None:\n",
    "        # Check whether a homogeneous penalty term was provided (a scalar)\n",
    "        if np.amax(cvec(lambda_start).shape) == 1:\n",
    "            # If so, repeat that p times as the penalty term\n",
    "            lmbda = np.ones(shape=(p,1)) * lambda_start\n",
    "        else:\n",
    "            # Otherwise, use the provided vector of penalty terms as is\n",
    "            lmbda = lambda_start\n",
    "\n",
    "    # 3) Homoskedastic and X-independent\n",
    "    elif (homoskedastic == True) and (X_dependent_lambda == False):\n",
    "        # Initilaize lambda\n",
    "        lmbda0 = 2 * c * np.sqrt(n) * norm.ppf(1 - gamma/(2*p))\n",
    "\n",
    "        # Use ddof=1 to be consistent with R's var() function\n",
    "        Ups0 = np.sqrt(np.var(y, axis=0, ddof=1))\n",
    "\n",
    "        # Calculate the final vector of penalty terms\n",
    "        lmbda = np.zeros(shape=(p,1)) + lmbda0 * Ups0\n",
    "\n",
    "    # 4) Homoskedastic and X-dependent\n",
    "    elif (homoskedastic == True) and (X_dependent_lambda == True):\n",
    "        psi = cvec((x**2).mean(axis=0))\n",
    "\n",
    "        tXtpsi = (x.T / np.sqrt(psi)).T\n",
    "\n",
    "        # Check whether to use parallel processing\n",
    "        if par == True:\n",
    "            # If so, get the number of cores to use\n",
    "            cores = np.int(np.amin([mp.cpu_count(), corecap]))\n",
    "        else:\n",
    "            # Otherwise, use only one core (i.e. run sequentially)\n",
    "            cores = 1\n",
    "\n",
    "        # Get simulated distribution\n",
    "        sim = jbl.Parallel(n_jobs=cores)(\n",
    "            jbl.delayed(simul_pen)(\n",
    "                n, p, tXtpsi, seed=l*20, fix_seed=fix_seed\n",
    "            ) for l in np.arange(R)\n",
    "        )\n",
    "\n",
    "        # Convert it to a proper column vector\n",
    "        sim = cvec(sim)\n",
    "\n",
    "        # Initialize lambda based on the simulated quantiles\n",
    "        lmbda0 = c * np.quantile(sim, q=1-gamma, axis=0)\n",
    "\n",
    "        Ups0 = np.sqrt(np.var(y, axis=0, ddof=1))\n",
    "\n",
    "        # Calculate the final vector of penalty terms\n",
    "        lmbda = np.zeros(shape=(p,1)) + lmbda0 * Ups0\n",
    "\n",
    "    # 5) Heteroskedastic and X-independent\n",
    "    elif (homoskedastic == False) and (X_dependent_lambda == False):\n",
    "        # The original includes the comment, \"1=num endogenous variables\"\n",
    "        lmbda0 = 2 * c * np.sqrt(n) * norm.ppf(1 - gamma/(2*p*1))\n",
    "\n",
    "        Ups0 = (1 / np.sqrt(n)) * np.sqrt((y**2).T @ (x**2)).T\n",
    "\n",
    "        lmbda = lmbda0 * Ups0\n",
    "\n",
    "    # 6) Heteroskedastic and X-dependent\n",
    "    elif (homoskedastic == False) and (X_dependent_lambda == True):\n",
    "        eh = y\n",
    "\n",
    "        ehat = eh @ np.ones(shape=(1,p))\n",
    "\n",
    "        xehat = x * ehat\n",
    "\n",
    "        psi = cvec((xehat**2).mean(axis=0)).T\n",
    "\n",
    "        tXehattpsi = (xehat / ( np.ones(shape=(n,1)) @ np.sqrt(psi) ))\n",
    "\n",
    "        # Check whether to use parallel processing\n",
    "        if par == True:\n",
    "            # If so, get the number of cores to use\n",
    "            cores = np.int(np.amin([mp.cpu_count(), corecap]))\n",
    "        else:\n",
    "            # Otherwise, use only one core (i.e. run sequentially)\n",
    "            cores = 1\n",
    "\n",
    "        # Get simulated distribution\n",
    "        sim = jbl.Parallel(n_jobs=cores)(\n",
    "            jbl.delayed(simul_pen)(\n",
    "                n, p, tXehattpsi, seed=l*20, fix_seed=fix_seed\n",
    "            ) for l in np.arange(R)\n",
    "        )\n",
    "\n",
    "        # Convert it to a proper column vector\n",
    "        sim = cvec(sim)\n",
    "\n",
    "        # Initialize lambda based on the simulated quantiles\n",
    "        lmbda0 = c * np.quantile(sim, q=1-gamma, axis=0)\n",
    "\n",
    "        Ups0 = (1 / np.sqrt(n)) * np.sqrt((y**2).T @ (x**2)).T\n",
    "\n",
    "        # Calculate the final vector of penalty terms\n",
    "        lmbda = lmbda0 * Ups0\n",
    "\n",
    "    # Return results\n",
    "    return {'lambda0': lmbda0, 'lambda': lmbda, 'Ups0': Ups0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "15039a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdmpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# I downloaded the data that the author used\n",
    "growth_read = pyreadr.read_r(\"../../data/GrowthData.RData\")\n",
    "\n",
    "# Extracting the data frame from rdata_read\n",
    "growth = growth_read[ 'GrowthData' ]\n",
    "#growth = growth.apply(pd.to_numeric)\n",
    "#print(growth.dtypes)\n",
    "growth['pop65'] = growth['pop65'].astype(\"int64\")\n",
    "#growth.astype('int64').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "83821b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>intercept</th>\n",
       "      <th>gdpsh465</th>\n",
       "      <th>bmp1l</th>\n",
       "      <th>freeop</th>\n",
       "      <th>freetar</th>\n",
       "      <th>h65</th>\n",
       "      <th>hm65</th>\n",
       "      <th>hf65</th>\n",
       "      <th>p65</th>\n",
       "      <th>...</th>\n",
       "      <th>seccf65</th>\n",
       "      <th>syr65</th>\n",
       "      <th>syrm65</th>\n",
       "      <th>syrf65</th>\n",
       "      <th>teapri65</th>\n",
       "      <th>teasec65</th>\n",
       "      <th>ex1</th>\n",
       "      <th>im1</th>\n",
       "      <th>xr65</th>\n",
       "      <th>tot1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.024336</td>\n",
       "      <td>1</td>\n",
       "      <td>6.591674</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.153491</td>\n",
       "      <td>0.043888</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.010</td>\n",
       "      <td>47.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.348</td>\n",
       "      <td>-0.014727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100473</td>\n",
       "      <td>1</td>\n",
       "      <td>6.829794</td>\n",
       "      <td>0.6141</td>\n",
       "      <td>0.313509</td>\n",
       "      <td>0.061827</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.067</td>\n",
       "      <td>57.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.005750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067051</td>\n",
       "      <td>1</td>\n",
       "      <td>8.895082</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.204244</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.201</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>18.14</td>\n",
       "      <td>2.573</td>\n",
       "      <td>2.478</td>\n",
       "      <td>2.667</td>\n",
       "      <td>26.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>1.082</td>\n",
       "      <td>-0.010040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064089</td>\n",
       "      <td>1</td>\n",
       "      <td>7.565275</td>\n",
       "      <td>0.1997</td>\n",
       "      <td>0.248714</td>\n",
       "      <td>0.036270</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.051</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.424</td>\n",
       "      <td>27.8</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>6.625</td>\n",
       "      <td>-0.002195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027930</td>\n",
       "      <td>1</td>\n",
       "      <td>7.162397</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.299252</td>\n",
       "      <td>0.037367</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.229</td>\n",
       "      <td>34.5</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.003283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.031196</td>\n",
       "      <td>1</td>\n",
       "      <td>8.991064</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.371898</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.98</td>\n",
       "      <td>...</td>\n",
       "      <td>11.41</td>\n",
       "      <td>2.226</td>\n",
       "      <td>2.494</td>\n",
       "      <td>1.971</td>\n",
       "      <td>27.5</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.4407</td>\n",
       "      <td>0.4257</td>\n",
       "      <td>2.529</td>\n",
       "      <td>-0.011883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.034096</td>\n",
       "      <td>1</td>\n",
       "      <td>8.025189</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.296437</td>\n",
       "      <td>0.013615</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.362</td>\n",
       "      <td>20.2</td>\n",
       "      <td>15.7</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.2201</td>\n",
       "      <td>25.553</td>\n",
       "      <td>-0.039080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.046900</td>\n",
       "      <td>1</td>\n",
       "      <td>9.030137</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.265778</td>\n",
       "      <td>0.008629</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.237</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>25.64</td>\n",
       "      <td>2.727</td>\n",
       "      <td>2.664</td>\n",
       "      <td>2.788</td>\n",
       "      <td>20.4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.3238</td>\n",
       "      <td>0.3134</td>\n",
       "      <td>4.152</td>\n",
       "      <td>0.005175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.039773</td>\n",
       "      <td>1</td>\n",
       "      <td>8.865312</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.282939</td>\n",
       "      <td>0.005048</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.139</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10.76</td>\n",
       "      <td>1.888</td>\n",
       "      <td>1.920</td>\n",
       "      <td>1.860</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1845</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.029551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.040642</td>\n",
       "      <td>1</td>\n",
       "      <td>8.912339</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.150366</td>\n",
       "      <td>0.024377</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>24.40</td>\n",
       "      <td>3.051</td>\n",
       "      <td>3.235</td>\n",
       "      <td>2.875</td>\n",
       "      <td>18.5</td>\n",
       "      <td>29.1</td>\n",
       "      <td>0.1876</td>\n",
       "      <td>0.2007</td>\n",
       "      <td>0.886</td>\n",
       "      <td>-0.036482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outcome  intercept  gdpsh465   bmp1l    freeop   freetar    h65   hm65  \\\n",
       "0  -0.024336          1  6.591674  0.2837  0.153491  0.043888  0.007  0.013   \n",
       "1   0.100473          1  6.829794  0.6141  0.313509  0.061827  0.019  0.032   \n",
       "2   0.067051          1  8.895082  0.0000  0.204244  0.009186  0.260  0.325   \n",
       "3   0.064089          1  7.565275  0.1997  0.248714  0.036270  0.061  0.070   \n",
       "4   0.027930          1  7.162397  0.1740  0.299252  0.037367  0.017  0.027   \n",
       "..       ...        ...       ...     ...       ...       ...    ...    ...   \n",
       "85  0.031196          1  8.991064  0.0000  0.371898  0.014586  0.255  0.336   \n",
       "86  0.034096          1  8.025189  0.0050  0.296437  0.013615  0.108  0.117   \n",
       "87  0.046900          1  9.030137  0.0000  0.265778  0.008629  0.288  0.337   \n",
       "88  0.039773          1  8.865312  0.0000  0.282939  0.005048  0.188  0.236   \n",
       "89  0.040642          1  8.912339  0.0000  0.150366  0.024377  0.257  0.338   \n",
       "\n",
       "     hf65   p65  ...  seccf65  syr65  syrm65  syrf65  teapri65  teasec65  \\\n",
       "0   0.001  0.29  ...     0.04  0.033   0.057   0.010      47.6      17.3   \n",
       "1   0.007  0.91  ...     0.64  0.173   0.274   0.067      57.1      18.0   \n",
       "2   0.201  1.00  ...    18.14  2.573   2.478   2.667      26.5      20.7   \n",
       "3   0.051  1.00  ...     2.63  0.438   0.453   0.424      27.8      22.7   \n",
       "4   0.007  0.82  ...     2.11  0.257   0.287   0.229      34.5      17.6   \n",
       "..    ...   ...  ...      ...    ...     ...     ...       ...       ...   \n",
       "85  0.170  0.98  ...    11.41  2.226   2.494   1.971      27.5      15.9   \n",
       "86  0.093  1.00  ...     1.95  0.510   0.694   0.362      20.2      15.7   \n",
       "87  0.237  1.00  ...    25.64  2.727   2.664   2.788      20.4       9.4   \n",
       "88  0.139  1.00  ...    10.76  1.888   1.920   1.860      20.0      16.0   \n",
       "89  0.215  1.00  ...    24.40  3.051   3.235   2.875      18.5      29.1   \n",
       "\n",
       "       ex1     im1    xr65      tot1  \n",
       "0   0.0729  0.0667   0.348 -0.014727  \n",
       "1   0.0940  0.1438   0.525  0.005750  \n",
       "2   0.1741  0.1750   1.082 -0.010040  \n",
       "3   0.1265  0.1496   6.625 -0.002195  \n",
       "4   0.1211  0.1308   2.500  0.003283  \n",
       "..     ...     ...     ...       ...  \n",
       "85  0.4407  0.4257   2.529 -0.011883  \n",
       "86  0.1669  0.2201  25.553 -0.039080  \n",
       "87  0.3238  0.3134   4.152  0.005175  \n",
       "88  0.1845  0.1940   0.452 -0.029551  \n",
       "89  0.1876  0.2007   0.886 -0.036482  \n",
       "\n",
       "[90 rows x 63 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e99378d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "growth[\"pop65\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2a7fd033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALEXAN~1\\AppData\\Local\\Temp/ipykernel_33736/3518213529.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X = growth.drop('Outcome', 1)\n",
      "C:\\Users\\ALEXAN~1\\AppData\\Local\\Temp/ipykernel_33736/3518213529.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  W = growth.drop(['Outcome','intercept', 'gdpsh465'], 1 )\n"
     ]
    }
   ],
   "source": [
    "# We create the main variables\n",
    "y = growth['Outcome']\n",
    "X = growth.drop('Outcome', 1)\n",
    "\n",
    "# Create main variables\n",
    "Y = growth['Outcome']\n",
    "W = growth.drop(['Outcome','intercept', 'gdpsh465'], 1 )\n",
    "D = growth['gdpsh465']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "464e8cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p = W.shape\n",
    "gamma=0.1\n",
    "c=1.1\n",
    "x = W\n",
    "y = Y\n",
    "\n",
    "\n",
    "lmbda0 = 2 * c * np.sqrt(n) * norm.ppf(1 - gamma/(2*p*1))\n",
    "\n",
    "Ups0 = (1 / np.sqrt(n)) * np.sqrt((y**2).T @ (x**2)).T\n",
    "\n",
    "lmbda = lmbda0 * Ups0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b921eac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     12359\n",
       "1      4630\n",
       "2     19678\n",
       "3      1482\n",
       "4      3006\n",
       "      ...  \n",
       "85    13653\n",
       "86     9093\n",
       "87     8193\n",
       "88    56226\n",
       "89     3083\n",
       "Name: pop65, Length: 90, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"pop65\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7bff5fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4769.7559732148475"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fc78ddc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286185.3583928907"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmbda.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "41768878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda0': 61.26064367633269,\n",
       " 'lambda': bmp1l            1.261436\n",
       " freeop           1.016037\n",
       " freetar          0.127779\n",
       " h65              0.495713\n",
       " hm65             0.623903\n",
       " hf65             0.377776\n",
       " p65              3.943929\n",
       " pm65             3.997176\n",
       " pf65             3.768832\n",
       " s65              1.937176\n",
       " sm65             2.113608\n",
       " sf65             1.851259\n",
       " fert65          20.104149\n",
       " mort65           0.311725\n",
       " lifee065        17.262366\n",
       " gpop1            0.097370\n",
       " fert1           21.085899\n",
       " mort1            0.373935\n",
       " invsh41          0.968080\n",
       " geetot1          0.153429\n",
       " geerec1          0.127346\n",
       " gde1             0.196848\n",
       " govwb1           0.522444\n",
       " govsh41          0.626674\n",
       " gvxdxe41         0.387331\n",
       " high65          21.602240\n",
       " highm65         28.684280\n",
       " highf65         16.269815\n",
       " highc65         11.911608\n",
       " highcm65        17.940494\n",
       " highcf65         7.030120\n",
       " human65         19.354445\n",
       " humanm65        21.930770\n",
       " humanf65        17.164104\n",
       " hyr65            0.660064\n",
       " hyrm65           0.923516\n",
       " hyrf65           0.455374\n",
       " no65           181.002959\n",
       " nom65          146.983094\n",
       " nof65          217.002430\n",
       " pinstab1         0.883381\n",
       " pop65       265054.024201\n",
       " worker65         1.565892\n",
       " pop1565          1.589539\n",
       " pop6565          0.263009\n",
       " sec65           79.159419\n",
       " secm65          88.757839\n",
       " secf65          72.486423\n",
       " secc65          34.248341\n",
       " seccm65         38.575435\n",
       " seccf65         31.964448\n",
       " syr65            4.691169\n",
       " syrm65           5.577810\n",
       " syrf65           3.988267\n",
       " teapri65       154.510973\n",
       " teasec65        94.442981\n",
       " ex1              1.097518\n",
       " im1              1.203090\n",
       " xr65           718.851861\n",
       " tot1             0.252956\n",
       " Name: Outcome, dtype: float64,\n",
       " 'Ups0': bmp1l          0.020591\n",
       " freeop         0.016585\n",
       " freetar        0.002086\n",
       " h65            0.008092\n",
       " hm65           0.010184\n",
       " hf65           0.006167\n",
       " p65            0.064379\n",
       " pm65           0.065249\n",
       " pf65           0.061521\n",
       " s65            0.031622\n",
       " sm65           0.034502\n",
       " sf65           0.030219\n",
       " fert65         0.328174\n",
       " mort65         0.005089\n",
       " lifee065       0.281786\n",
       " gpop1          0.001589\n",
       " fert1          0.344200\n",
       " mort1          0.006104\n",
       " invsh41        0.015803\n",
       " geetot1        0.002505\n",
       " geerec1        0.002079\n",
       " gde1           0.003213\n",
       " govwb1         0.008528\n",
       " govsh41        0.010230\n",
       " gvxdxe41       0.006323\n",
       " high65         0.352628\n",
       " highm65        0.468233\n",
       " highf65        0.265583\n",
       " highc65        0.194441\n",
       " highcm65       0.292855\n",
       " highcf65       0.114758\n",
       " human65        0.315936\n",
       " humanm65       0.357991\n",
       " humanf65       0.280182\n",
       " hyr65          0.010775\n",
       " hyrm65         0.015075\n",
       " hyrf65         0.007433\n",
       " no65           2.954637\n",
       " nom65          2.399307\n",
       " nof65          3.542281\n",
       " pinstab1       0.014420\n",
       " pop65       4326.660778\n",
       " worker65       0.025561\n",
       " pop1565        0.025947\n",
       " pop6565        0.004293\n",
       " sec65          1.292174\n",
       " secm65         1.448856\n",
       " secf65         1.183246\n",
       " secc65         0.559059\n",
       " seccm65        0.629694\n",
       " seccf65        0.521778\n",
       " syr65          0.076577\n",
       " syrm65         0.091050\n",
       " syrf65         0.065103\n",
       " teapri65       2.522190\n",
       " teasec65       1.541658\n",
       " ex1            0.017916\n",
       " im1            0.019639\n",
       " xr65          11.734318\n",
       " tot1           0.004129\n",
       " Name: Outcome, dtype: float64}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdaCalculation(homoskedastic=False, X_dependent_lambda=False,\n",
    "                      lambda_start=None, c=1.1, gamma=0.2, numSim=5000, y=Y,\n",
    "                      x=W, par=True, corecap=np.inf, fix_seed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a071954",
   "metadata": {},
   "source": [
    "# 3. rlasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0aa33846",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "### 3: Define classes\n",
    "################################################################################\n",
    "\n",
    "class rlasso:\n",
    "    # Initialize gamma to None to get gamma=.1/log(n)\n",
    "    def __init__(self, x, y, colnames=None, post=True, intercept=True,\n",
    "                 model=True, homoskedastic=False, X_dependent_lambda=False,\n",
    "                 lambda_start=None, c=1.1, gamma=None, numSim=5000, numIter=15,\n",
    "                 tol=10**(-5), threshold=-np.inf, par=True, corecap=np.inf,\n",
    "                 fix_seed=True):\n",
    "        # Initialize internal variables\n",
    "        if isinstance(x, pd.DataFrame) and colnames is None:\n",
    "            colnames = x.columns\n",
    "\n",
    "        self.x = np.array(x).astype(np.float32)\n",
    "        self.y = cvec(y).astype(np.float32)\n",
    "\n",
    "        self.n, self.p = self.x.shape\n",
    "\n",
    "        if colnames is None:\n",
    "            self.colnames = ['V' + str(i+1) for i in np.arange(self.p)]\n",
    "        else:\n",
    "            self.colnames = colnames\n",
    "\n",
    "        # Unused line in the original code\n",
    "        # ind_names = np.arange(self.p) + 1\n",
    "\n",
    "        self.post = post\n",
    "        self.intercept = intercept\n",
    "        self.model = model\n",
    "        self.homoskedastic = homoskedastic\n",
    "        self.X_dependent_lambda = X_dependent_lambda\n",
    "        self.lambda_start = lambda_start\n",
    "        self.c = c\n",
    "\n",
    "        if gamma is None:\n",
    "            self.gamma = .1 / np.log(self.n)\n",
    "        else:\n",
    "            self.gamma = gamma\n",
    "\n",
    "        self.numSim = numSim\n",
    "        self.numIter = numIter\n",
    "        self.tol = tol\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.par = par\n",
    "        self.corecap = corecap\n",
    "        self.fix_seed = fix_seed\n",
    "\n",
    "        if (self.post == False) and (self.c is None):\n",
    "            self.c = .5\n",
    "\n",
    "        if (\n",
    "                (self.post == False) and (self.homoskedastic == False)\n",
    "                and (self.X_dependent_lambda == False)\n",
    "                and (self.lambda_start == None) and (self.c == 1.1)\n",
    "                and (self.gamma == .1 / np.log(self.n))\n",
    "        ):\n",
    "            self.c = .5\n",
    "\n",
    "        # For now, instantiate estimate as None\n",
    "        self.est = None\n",
    "\n",
    "        # Calculate robust LASSO coefficients\n",
    "        if self.intercept == True:\n",
    "            meanx = cvec(self.x.mean(axis=0))\n",
    "\n",
    "            self.x = self.x - np.ones(shape=(self.n,1)) @ meanx.T\n",
    "\n",
    "            mu = self.y.mean()\n",
    "\n",
    "            self.y = self.y - mu\n",
    "        else:\n",
    "            meanx = np.zeros(shape=(self.p,1))\n",
    "\n",
    "            mu = 0\n",
    "\n",
    "        normx = np.sqrt(np.var(self.x, axis=1, ddof=1))\n",
    "\n",
    "        Psi = cvec(np.mean(self.x**2, axis=0))\n",
    "\n",
    "        ind = np.zeros(shape=(self.p,1)).astype(bool)\n",
    "\n",
    "        XX = self.x.T @ self.x\n",
    "\n",
    "        Xy = self.x.T @ self.y\n",
    "\n",
    "        startingval = init_values(self.x, self.y)['residuals']\n",
    "\n",
    "        pen = lambdaCalculation(homoskedastic=self.homoskedastic,\n",
    "                                X_dependent_lambda=self.X_dependent_lambda,\n",
    "                                lambda_start=self.lambda_start, c=self.c,\n",
    "                                gamma=self.gamma, numSim=self.numSim,\n",
    "                                y=startingval, x=self.x, par=self.par,\n",
    "                                corecap=self.corecap, fix_seed=self.fix_seed)\n",
    "\n",
    "        lmbda = pen['lambda']\n",
    "        Ups0 = Ups1 = pen['Ups0']\n",
    "        lmbda0 = pen['lambda0']\n",
    "\n",
    "        mm = 1\n",
    "        s0 = np.sqrt(np.var(y, axis=0, ddof=1))\n",
    "\n",
    "        while mm <= self.numIter:\n",
    "            if (mm == 1) and self.post:\n",
    "                coefTemp = (\n",
    "                    LassoShooting_fit(self.x, self.y, lmbda/2, XX=XX,\n",
    "                                      Xy=Xy)['coefficients']\n",
    "                )\n",
    "            else:\n",
    "                coefTemp = (\n",
    "                    LassoShooting_fit(self.x, self.y, lmbda, XX=XX,\n",
    "                                      Xy=Xy)['coefficients']\n",
    "                )\n",
    "\n",
    "            coefTemp[np.isnan(coefTemp)] = 0\n",
    "\n",
    "            ind1 = (np.abs(coefTemp) > 0)\n",
    "\n",
    "            x1 = self.x[:, ind1[:,0]]\n",
    "\n",
    "            if x1.shape[1] == 0:\n",
    "                if self.intercept:\n",
    "                    intercept_value = np.mean(self.y + mu)\n",
    "\n",
    "                    coef = np.zeros(shape=(self.p+1,1))\n",
    "\n",
    "                    coef = (\n",
    "                        pd.DataFrame(coef,\n",
    "                                     index=['(Intercept)']+list(self.colnames))\n",
    "                    )\n",
    "                else:\n",
    "                    intercept_value = np.mean(self.y)\n",
    "\n",
    "                    coef = np.zeros(shape=(self.p,1))\n",
    "\n",
    "                    coef = pd.DataFrame(coef, index=self.colnames)\n",
    "\n",
    "                self.est = {\n",
    "                    'coefficients': coef,\n",
    "                    'beta': np.zeros(shape=(self.p,1)),\n",
    "                    'intercept': intercept_value,\n",
    "                    'index': pd.DataFrame(np.zeros(shape=(self.p,1)).astype(\n",
    "                        bool),\n",
    "                                          index=self.colnames),\n",
    "                    'lambda': lmbda,\n",
    "                    'lambda0': lmbda0,\n",
    "                    'loadings': Ups0,\n",
    "                    'residuals': self.y - np.mean(self.y),\n",
    "                    'sigma': np.var(self.y, axis=0, ddof=1),\n",
    "                    'iter': mm,\n",
    "                    #'call': Not a Python option\n",
    "                    'options': {'post': self.post, 'intercept': self.intercept,\n",
    "                                'ind.scale': ind, 'mu': mu, 'meanx': meanx}\n",
    "                }\n",
    "\n",
    "                if self.model:\n",
    "                    self.est['model'] = self.x\n",
    "                else:\n",
    "                    self.est['model'] = None\n",
    "\n",
    "                self.est['tss'] = self.est['rss'] = (\n",
    "                    ((self.y - np.mean(self.y))**2).sum()\n",
    "                )\n",
    "\n",
    "                self.est['dev']: self.y - np.mean(self.y)\n",
    "                # In R, return() breaks while loops\n",
    "                return\n",
    "\n",
    "            # Refinement variance estimation\n",
    "            if self.post:\n",
    "                reg = lm(fit_intercept=False).fit(x1, self.y)\n",
    "\n",
    "                coefT = reg.coef_.T\n",
    "\n",
    "                coefT[np.isnan(coefT)] = 0\n",
    "\n",
    "                e1 = self.y - x1 @ coefT\n",
    "\n",
    "                coefTemp[ind1[:,0]] = coefT\n",
    "            else:\n",
    "                e1 = self.y - x1@ coefTemp[ind1[:,0]]\n",
    "\n",
    "            s1 = np.sqrt(np.var(e1, ddof=1))\n",
    "\n",
    "            # Homoskedastic and X-independent\n",
    "            if (\n",
    "                    (self.homoskedastic == True)\n",
    "                    and (self.X_dependent_lambda == False)\n",
    "            ):\n",
    "                Ups1 = s1 * Psi\n",
    "\n",
    "                lmbda = pen['lambda0'] * Ups1\n",
    "\n",
    "            # Homoskedastic and X-dependent\n",
    "            elif (\n",
    "                    (self.homoskedastic == True)\n",
    "                    and (self.X_dependent_lambda == True)\n",
    "            ):\n",
    "                Ups1 = s1 * Psi\n",
    "\n",
    "                lmbda = pen['lambda0'] * Ups1\n",
    "\n",
    "            # Heteroskedastic and X-independent\n",
    "            elif (\n",
    "                    (self.homoskedastic == False)\n",
    "                    and (self.X_dependent_lambda == False)\n",
    "            ):\n",
    "                Ups1 = (\n",
    "                    (1/np.sqrt(self.n)) * np.sqrt((e1**2).T @ self.x**2).T\n",
    "                )\n",
    "\n",
    "                lmbda = pen['lambda0'] * Ups1\n",
    "\n",
    "            # Heteroskedastic and X-dependent\n",
    "            elif (\n",
    "                    (self.homoskedastic == False)\n",
    "                    and (self.X_dependent_lambda == True)\n",
    "            ):\n",
    "                lc = lambdaCalculation(homoskedastic=self.homoskedastic,\n",
    "                                       X_dependent_lambda=\n",
    "                                       self.X_dependent_lambda,\n",
    "                                       lambda_start=self.lambda_start,\n",
    "                                       c=self.c, gamma=self.gamma,\n",
    "                                       numSim=self.numSim, y=e1, x=self.x,\n",
    "                                       par=self.par, corecap=self.corecap,\n",
    "                                       fix_seed=self.fix_seed)\n",
    "\n",
    "                Ups1 = lc['Ups0']\n",
    "\n",
    "                lmbda = lc['lambda']\n",
    "\n",
    "            # If homoskedastic is set to None\n",
    "            elif self.homoskedastic is None:\n",
    "                Ups1 = (\n",
    "                    (1/np.sqrt(self.n)) * np.sqrt((e1**2).T @ self.x**2).T\n",
    "                )\n",
    "\n",
    "                lmbda = pen['lambda0'] * Ups1\n",
    "\n",
    "            mm = mm + 1\n",
    "\n",
    "            if np.abs(s0 - s1) < self.tol:\n",
    "                break\n",
    "\n",
    "            s0 = s1\n",
    "\n",
    "        if x1.shape[1] == 0:\n",
    "            #coefTemp = None\n",
    "            ind1 = np.zeros(shape=(self.p,1))\n",
    "\n",
    "        coefTemp = cvec(coefTemp)\n",
    "\n",
    "        coefTemp[np.abs(coefTemp) < self.threshold] = 0\n",
    "\n",
    "        coefTemp = pd.DataFrame(coefTemp, index=self.colnames)\n",
    "\n",
    "        ind1 = cvec(ind1)\n",
    "\n",
    "        ind1 = pd.DataFrame(ind1, index=self.colnames)\n",
    "\n",
    "        if self.intercept:\n",
    "            if mu is None:\n",
    "                mu = 0\n",
    "            if meanx is None:\n",
    "                meanx = np.zeros(shape=(coefTemp.shape[0],1))\n",
    "            if ind.sum() == 0:\n",
    "                intercept_value = mu - (meanx * coefTemp).sum()\n",
    "            else:\n",
    "                intercept_value = mu - (meanx * coefTemp).sum()\n",
    "        else:\n",
    "            intercept_value = np.nan\n",
    "\n",
    "        if self.intercept:\n",
    "            beta = (\n",
    "                np.concatenate([cvec(intercept_value), coefTemp.values], axis=0)\n",
    "            )\n",
    "\n",
    "            beta = pd.DataFrame(beta, index=['(Intercept)']+list(self.colnames))\n",
    "        else:\n",
    "            beta = coefTemp\n",
    "\n",
    "        s1 = np.sqrt(np.var(e1, ddof=1))\n",
    "\n",
    "        self.est = {\n",
    "            'coefficients': beta,\n",
    "            'beta': pd.DataFrame(coefTemp, index=self.colnames),\n",
    "            'intercept': intercept_value,\n",
    "            'index': ind1,\n",
    "            'lambda': pd.DataFrame(lmbda, index=self.colnames),\n",
    "            'lambda0': lmbda0,\n",
    "            'loadings': Ups1,\n",
    "            'residuals': cvec(e1),\n",
    "            'sigma': s1,\n",
    "            'iter': mm,\n",
    "            #'call': Not a Python option\n",
    "            'options': {'post': self.post, 'intercept': self.intercept,\n",
    "                        'ind.scale': ind, 'mu': mu, 'meanx': meanx},\n",
    "            'model': model\n",
    "        }\n",
    "\n",
    "        if model:\n",
    "            self.x = self.x + np.ones(shape=(self.n,1)) @ meanx.T\n",
    "\n",
    "            self.est['model'] = self.x\n",
    "        else:\n",
    "            self.est['model'] = None\n",
    "\n",
    "        self.est['tss'] = ((self.y - np.mean(self.y))**2).sum()\n",
    "        self.est['rss'] = (self.est['residuals']**2).sum()\n",
    "        self.est['dev'] = self.y - np.mean(self.y)\n",
    "        self.est['Xy'] = Xy        \n",
    "        self.est['startingval'] = startingval\n",
    "        self.est['pen'] = pen\n",
    "        self.est['ind1'] = ind1 \n",
    "        \n",
    "        self.est['x1'] = x1        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4130dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "51d08d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06099874],\n",
       "       [ 0.08877641],\n",
       "       [ 0.00895057],\n",
       "       [ 0.02107867],\n",
       "       [-0.01702298],\n",
       "       [-0.01169348],\n",
       "       [ 0.00923142],\n",
       "       [-0.01614626],\n",
       "       [-0.02454968],\n",
       "       [-0.00774048],\n",
       "       [ 0.02026233],\n",
       "       [ 0.08610442],\n",
       "       [-0.04979783],\n",
       "       [ 0.03295552],\n",
       "       [ 0.06865422],\n",
       "       [ 0.00147667],\n",
       "       [-0.01999469],\n",
       "       [-0.02679093],\n",
       "       [-0.09468942],\n",
       "       [-0.00710572],\n",
       "       [ 0.03746511],\n",
       "       [ 0.07588129],\n",
       "       [ 0.15053784],\n",
       "       [ 0.05294329],\n",
       "       [-0.00612673],\n",
       "       [ 0.02626686],\n",
       "       [ 0.05945478],\n",
       "       [ 0.0360154 ],\n",
       "       [ 0.02527513],\n",
       "       [ 0.01813254],\n",
       "       [ 0.02592292],\n",
       "       [-0.00516014],\n",
       "       [ 0.05941767],\n",
       "       [ 0.0097508 ],\n",
       "       [ 0.01580399],\n",
       "       [ 0.01596973],\n",
       "       [ 0.00773677],\n",
       "       [ 0.03675017],\n",
       "       [-0.00539555],\n",
       "       [-0.01092044],\n",
       "       [-0.01907675],\n",
       "       [-0.00973178],\n",
       "       [ 0.00194517],\n",
       "       [ 0.05472925],\n",
       "       [-0.09396082],\n",
       "       [-0.03849701],\n",
       "       [ 0.00608245],\n",
       "       [-0.00891093],\n",
       "       [-0.06609867],\n",
       "       [ 0.01175351],\n",
       "       [ 0.04339751],\n",
       "       [-0.0354067 ],\n",
       "       [-0.00734366],\n",
       "       [-0.03557493],\n",
       "       [-0.06153224],\n",
       "       [-0.07645746],\n",
       "       [-0.06688164],\n",
       "       [-0.04384487],\n",
       "       [-0.03293433],\n",
       "       [-0.02392849],\n",
       "       [-0.06797291],\n",
       "       [-0.0682326 ],\n",
       "       [ 0.02104806],\n",
       "       [-0.01606537],\n",
       "       [-0.00192731],\n",
       "       [ 0.01528296],\n",
       "       [-0.0326092 ],\n",
       "       [-0.15901524],\n",
       "       [ 0.05375479],\n",
       "       [ 0.03651725],\n",
       "       [ 0.01448545],\n",
       "       [ 0.00739019],\n",
       "       [-0.03295523],\n",
       "       [ 0.0913016 ],\n",
       "       [ 0.03909314],\n",
       "       [ 0.02920832],\n",
       "       [-0.04176953],\n",
       "       [ 0.1278034 ],\n",
       "       [ 0.04302905],\n",
       "       [ 0.00712764],\n",
       "       [-0.02000589],\n",
       "       [-0.02388791],\n",
       "       [-0.00259875],\n",
       "       [-0.01968528],\n",
       "       [-0.02620613],\n",
       "       [-0.02690493],\n",
       "       [-0.02362743],\n",
       "       [-0.01120045],\n",
       "       [-0.01832755],\n",
       "       [-0.01745938]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlasso( W, Y, post=True ).est['residuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d41a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "rlasso.default <- function(x, y, post = TRUE, intercept = TRUE, model = TRUE, \n",
    "                           penalty = list(homoscedastic = FALSE, X.dependent.lambda = FALSE, lambda.start = NULL, c = 1.1, gamma = .1/log(n)),\n",
    "                           control = list(numIter = 15, tol = 10^-5, threshold = NULL),...) {\n",
    "  x <- as.matrix(x)\n",
    "  y <- as.matrix(y)\n",
    "  \n",
    "  n <- dim(x)[1]\n",
    "  p <- dim(x)[2]\n",
    "  \n",
    "  if (is.null(colnames(x)))\n",
    "    colnames(x) <- paste(\"V\", 1:p, sep = \"\")\n",
    "  ind.names <- 1:p\n",
    "  # set options to default values if missing\n",
    "  if (!exists(\"homoscedastic\", where = penalty))  penalty$homoscedastic = \"FALSE\"\n",
    "  if (!exists(\"X.dependent.lambda\", where = penalty))  penalty$X.dependent.lambda = \"FALSE\"\n",
    "  if (!exists(\"gamma\", where = penalty))  penalty$gamma = 0.1/log(n)\n",
    "  \n",
    "  if (penalty$homoscedastic==\"none\" & !exists(\"lambda.start\", where=penalty)) stop(\"lambda.start must be provided!\")\n",
    "  # checking input numIter, tol\n",
    "  if (!exists(\"numIter\", where = control)) {\n",
    "    control$numIter = 15\n",
    "  }\n",
    "  \n",
    "  if (!exists(\"tol\", where = control)) {\n",
    "    control$tol = 10^-5\n",
    "  }\n",
    "  \n",
    "  #if (post==FALSE & (!exists(\"c\", where = penalty) | is.na(match(\"penalty\", names(as.list(match.call)))))) {\n",
    "  if (post==FALSE & (!exists(\"c\", where = penalty))) {  \n",
    "    penalty$c = 0.5\n",
    "  }\n",
    "  \n",
    "  default_pen <-  list(homoscedastic = FALSE, X.dependent.lambda = FALSE, lambda.start = NULL, c = 1.1, gamma = .1/log(n))\n",
    "  if (post==FALSE &  isTRUE(all.equal(penalty, default_pen))) {  \n",
    "    penalty$c = 0.5\n",
    "  }\n",
    "  \n",
    "  # Intercept handling and scaling\n",
    "  if (intercept) {\n",
    "    meanx <- colMeans(x)\n",
    "    x <- scale(x, meanx, FALSE)\n",
    "    mu <- mean(y)\n",
    "    y <- y - mu\n",
    "  } else {\n",
    "    meanx <- rep(0, p)\n",
    "    mu <- 0\n",
    "  }\n",
    "  \n",
    "  normx <- sqrt(apply(x, 2, var))\n",
    "  Psi <- apply(x, 2, function(x) mean(x^2)) \n",
    "  ind <- rep(FALSE, p) #\n",
    "  \n",
    "  # variables with low variation are taken out, because normalization is not reliable\n",
    "  # eps <- 10^-9  # precision for scaling\n",
    "  #ind <- which(normx < eps)\n",
    "  #if (length(ind) != 0) {\n",
    "  #  x <- x[, -ind]\n",
    "  #  normx <- normx[-ind]\n",
    "  #  ind.names <- ind.names[-ind]\n",
    "  #  p <- dim(x)[2]\n",
    "  #  if (!is.null(penalty$lambda.start)) {\n",
    "  #    penalty$lambda.start <- penalty$lambda.start[-ind]\n",
    "  #  }\n",
    "  #}\n",
    "  \n",
    "  #\n",
    "  \n",
    "  XX <- crossprod(x)\n",
    "  Xy <- crossprod(x, y)\n",
    "  \n",
    "  startingval <- init_values(x,y)$residuals\n",
    "  pen <- lambdaCalculation(penalty = penalty, y = startingval, x = x)\n",
    "  lambda <- pen$lambda\n",
    "  Ups0 <- Ups1 <- pen$Ups0\n",
    "  lambda0 <- pen$lambda0\n",
    "  \n",
    "  mm <- 1\n",
    "  s0 <- sqrt(var(y))\n",
    "  \n",
    "  while (mm <= control$numIter) {\n",
    "    # calculation parameters\n",
    "    #coefTemp <- LassoShooting.fit(x, y, lambda, XX = XX, Xy = Xy)$coefficients\n",
    "    #xn <- t(t(x)/as.vector(Ups1))\n",
    "    if (mm==1 && post) {\n",
    "      coefTemp <- LassoShooting.fit(x, y, lambda/2, XX = XX, Xy = Xy)$coefficients\n",
    "      #lasso.reg <- glmnet::glmnet(xn, y, family = c(\"gaussian\"), alpha = 1,\n",
    "      #                            lambda = lambda0/(2*n)/2, standardize = FALSE, intercept = FALSE)\n",
    "      #lasso.reg <- glmnet::glmnet(x, y, family = c(\"gaussian\"), alpha = 1,\n",
    "      #                           lambda = lambda0/(2*n)/2, standardize = FALSE, intercept = FALSE,  penalty.factor = Ups1)\n",
    "    } else {\n",
    "      coefTemp <- LassoShooting.fit(x, y, lambda, XX = XX, Xy = Xy)$coefficients\n",
    "      #lasso.reg <- glmnet::glmnet(xn, y, family = c(\"gaussian\"), alpha = 1,\n",
    "      #                           lambda = lambda0/(2*n), standardize = FALSE, intercept = FALSE)\n",
    "      #lasso.reg <- glmnet::glmnet(x, y, family = c(\"gaussian\"), alpha = 1,\n",
    "      #                           lambda = lambda0/(2*n), standardize = FALSE, intercept = FALSE,  penalty.factor = Ups1)\n",
    "    }\n",
    "    #coefTemp <- as.vector(lasso.reg$beta)\n",
    "    #names(coefTemp) <- colnames(x)\n",
    "    coefTemp[is.na(coefTemp)] <- 0\n",
    "    ind1 <- (abs(coefTemp) > 0)\n",
    "    x1 <- as.matrix(x[, ind1, drop = FALSE])\n",
    "    if (dim(x1)[2] == 0) {\n",
    "      if (intercept) {\n",
    "        intercept.value <- mean(y + mu)\n",
    "        coef <- rep(0,p+1)\n",
    "        names(coef) <- c(\"intercept\", colnames(x)) #c(\"intercept\", names(coefTemp))\n",
    "      } else {\n",
    "        intercept.value <- mean(y)\n",
    "        coef <- rep(0,p)\n",
    "        names(coef) <- colnames(x) #names(coefTemp)\n",
    "      }\n",
    "      est <- list(coefficients = coef, beta=rep(0,p), intercept=intercept.value, index = rep(FALSE, p),\n",
    "                  lambda = lambda, lambda0 = lambda0, loadings = Ups0, residuals = y -\n",
    "                    mean(y), sigma = var(y), iter = mm, call = match.call(),\n",
    "                  options = list(post = post, intercept = intercept, ind.scale=ind, \n",
    "                                 control = control, mu = mu, meanx = meanx))\n",
    "      if (model) {\n",
    "        est$model <- x\n",
    "      } else {\n",
    "        est$model <- NULL\n",
    "      }\n",
    "      est$tss <- est$rss <- sum((y - mean(y))^2)\n",
    "      est$dev <- y - mean(y)\n",
    "      class(est) <- \"rlasso\"\n",
    "      return(est)\n",
    "    }\n",
    "    \n",
    "    # refinement variance estimation\n",
    "    if (post) {\n",
    "      reg <- lm(y ~ -1 + x1)\n",
    "      coefT <- coef(reg)\n",
    "      coefT[is.na(coefT)] <- 0\n",
    "      e1 <- y - x1 %*% coefT\n",
    "      coefTemp[ind1] <- coefT\n",
    "    }\n",
    "    if (!post) {\n",
    "      e1 <- y - x1 %*% coefTemp[ind1]\n",
    "    }\n",
    "    s1 <- sqrt(var(e1))\n",
    "    \n",
    "    # homoscedatic and X-independent\n",
    "    if (penalty$homoscedastic == TRUE && penalty$X.dependent.lambda == FALSE) {\n",
    "      Ups1 <- c(s1)*Psi\n",
    "      #lambda <- rep(pen$lambda0 * s1, p)\n",
    "      lambda <- pen$lambda0*Ups1\n",
    "    }\n",
    "    # homoscedatic and X-dependent\n",
    "    if (penalty$homoscedastic == TRUE && penalty$X.dependent.lambda == TRUE) {\n",
    "      Ups1 <- c(s1)*Psi\n",
    "      #lambda <- rep(pen$lambda0 * s1, p)\n",
    "      lambda <- pen$lambda0 * Ups1\n",
    "    }\n",
    "    # heteroscedastic and X-independent\n",
    "    if (penalty$homoscedastic == FALSE && penalty$X.dependent.lambda == FALSE) {\n",
    "      Ups1 <- 1/sqrt(n) * sqrt(t(t(e1^2) %*% (x^2)))\n",
    "      lambda <- pen$lambda0 * Ups1\n",
    "    }\n",
    "    \n",
    "    # heteroscedastic and X-dependent\n",
    "    if (penalty$homoscedastic == FALSE && penalty$X.dependent.lambda == TRUE) {\n",
    "      lc <- lambdaCalculation(penalty, y=e1, x=x)\n",
    "      Ups1 <- lc$Ups0\n",
    "      lambda <- lc$lambda\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    # none\n",
    "    if (penalty$homoscedastic == \"none\") {\n",
    "      if (is.null(penalty$lambda.start)) stop(\"Argument lambda.start required!\")\n",
    "      Ups1 <- 1/sqrt(n) * sqrt(t(t(e1^2) %*% (x^2)))\n",
    "      lambda <- pen$lambda0 * Ups1\n",
    "    }\n",
    "    \n",
    "    mm <- mm + 1\n",
    "    if (abs(s0 - s1) < control$tol) {\n",
    "      break\n",
    "    }\n",
    "    s0 <- s1\n",
    "  }\n",
    "  \n",
    "  if (dim(x1)[2] == 0) {\n",
    "    coefTemp = NULL\n",
    "    ind1 <- rep(0, p)\n",
    "  }\n",
    "  coefTemp <- as.vector(coefTemp)\n",
    "  coefTemp[abs(coefTemp) < control$threshold] <- 0\n",
    "  ind1 <- as.vector(ind1)\n",
    "  coefTemp <- as.vector(as.vector(coefTemp))\n",
    "  names(coefTemp) <- names(ind1) <- colnames(x)\n",
    "  if (intercept) {\n",
    "    if (is.null(mu)) mu <-0\n",
    "    if (is.null(meanx))  meanx <-  rep(0, length(coefTemp))  #<- 0\n",
    "    if (sum(ind)==0) {\n",
    "      intercept.value <- mu - sum(meanx*coefTemp)\n",
    "    } else {\n",
    "      intercept.value <- mu - sum(meanx*coefTemp) #sum(meanx[-ind]*coefTemp)\n",
    "    }\n",
    "  } else {\n",
    "    intercept.value <- NA\n",
    "  }\n",
    "  \n",
    "  #if (intercept) {\n",
    "  #  e1 <- y - x1 %*% coefTemp[ind1] - intercept.value \n",
    "  #} else {\n",
    "  #  e1 <- y - x1 %*% coefTemp[ind1]\n",
    "  #}\n",
    "  if (intercept) {\n",
    "    beta <- c(intercept.value, coefTemp)\n",
    "    names(beta)[1] <- \"(Intercept)\"\n",
    "  } else {\n",
    "    beta <- coefTemp\n",
    "  }\n",
    "  \n",
    "  s1 <- sqrt(var(e1))\n",
    "  est <- list(coefficients = beta, beta=coefTemp, intercept=intercept.value, index = ind1, lambda = lambda,\n",
    "              lambda0 = lambda0, loadings = Ups1, residuals = as.vector(e1), sigma = s1,\n",
    "              iter = mm, call = match.call(), options = list(post = post, intercept = intercept,\n",
    "                                                             control = control, penalty = penalty, ind.scale=ind,\n",
    "                                                             mu = mu, meanx = meanx), model=model)\n",
    "  if (model) {\n",
    "    x <- scale(x, -meanx, FALSE)\n",
    "    est$model <- x\n",
    "  } else {\n",
    "    est$model <- NULL\n",
    "  }\n",
    "  est$tss <- sum((y - mean(y))^2)\n",
    "  est$rss <- sum(est$residuals^2)\n",
    "  est$dev <- y - mean(y)\n",
    "  class(est) <- \"rlasso\"\n",
    "  return(est)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
